"""
Test du workflow d'analyse des cas d'usage IA
"""

import os
import json
import logging
from dotenv import load_dotenv
from use_case_analysis.use_case_analysis_agent import UseCaseAnalysisAgent

# Configuration du logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

def test_use_case_analysis():
    """
    Test de l'agent d'analyse des cas d'usage IA.
    """
    logger.info("="*80)
    logger.info("DÃ‰BUT DU TEST - Analyse des cas d'usage IA")
    logger.info("="*80)
    
    # Chargement de la clÃ© API
    load_dotenv()
    api_key = os.getenv("OPENAI_API_KEY")
    
    if not api_key:
        logger.error("âŒ ClÃ© API OpenAI non trouvÃ©e dans .env")
        return
    
    logger.info("âœ… ClÃ© API OpenAI chargÃ©e")
    
    # Initialisation de l'agent
    logger.info("\nğŸ“¦ Initialisation de l'agent d'analyse des cas d'usage...")
    agent = UseCaseAnalysisAgent(api_key)
    logger.info("âœ… Agent initialisÃ© avec succÃ¨s")
    
    # Charger les besoins validÃ©s depuis le fichier de rÃ©sultats
    logger.info("\nğŸ“‚ Chargement des besoins validÃ©s...")
    try:
        with open('/home/addeche/aiko/aikoGPT/outputs/need_analysis_results.json', 'r', encoding='utf-8') as f:
            need_results = json.load(f)
        
        validated_needs = need_results.get("final_needs", [])
        
        if not validated_needs:
            logger.error("âŒ Aucun besoin validÃ© trouvÃ© dans need_analysis_results.json")
            return
        
        logger.info(f"âœ… {len(validated_needs)} besoins validÃ©s chargÃ©s")
        logger.info("\nğŸ“‹ Besoins validÃ©s:")
        for i, need in enumerate(validated_needs, 1):
            logger.info(f"   {i}. {need.get('theme', 'N/A')}")
    
    except FileNotFoundError:
        logger.error("âŒ Fichier need_analysis_results.json non trouvÃ©")
        logger.info("ğŸ’¡ ExÃ©cutez d'abord test_need_analysis_workflow.py pour gÃ©nÃ©rer les besoins")
        return
    except Exception as e:
        logger.error(f"âŒ Erreur lors du chargement des besoins: {str(e)}")
        return
    
    # Test 1 : GÃ©nÃ©ration initiale des cas d'usage
    logger.info("\n" + "="*80)
    logger.info("TEST 1 : GÃ©nÃ©ration initiale des cas d'usage")
    logger.info("="*80)
    
    try:
        result = agent.analyze_use_cases(
            validated_needs=validated_needs,
            iteration=1
        )
        
        if "error" in result:
            logger.error(f"âŒ Erreur lors de la gÃ©nÃ©ration: {result['error']}")
            return
        
        quick_wins = result.get("quick_wins", [])
        structuration_ia = result.get("structuration_ia", [])
        summary = result.get("summary", {})
        
        logger.info(f"\nâœ… Cas d'usage gÃ©nÃ©rÃ©s avec succÃ¨s!")
        logger.info(f"ğŸ“Š Quick Wins: {len(quick_wins)}")
        logger.info(f"ğŸ“Š Structuration IA: {len(structuration_ia)}")
        logger.info(f"ğŸ“Š Total: {summary.get('total_use_cases', 0)}")
        
        # Afficher les Quick Wins
        logger.info("\nâš¡ QUICK WINS:")
        for i, uc in enumerate(quick_wins, 1):
            logger.info(f"\n   {i}. {uc.get('titre', 'N/A')}")
            logger.info(f"      ğŸ’¡ IA: {uc.get('ia_utilisee', 'N/A')}")
            description = uc.get('description', 'N/A')
            if len(description) > 150:
                description = description[:150] + "..."
            logger.info(f"      ğŸ“ {description}")
        
        # Afficher les Structuration IA
        logger.info("\nğŸ§  STRUCTURATION IA:")
        for i, uc in enumerate(structuration_ia, 1):
            logger.info(f"\n   {i}. {uc.get('titre', 'N/A')}")
            logger.info(f"      ğŸ’¡ IA: {uc.get('ia_utilisee', 'N/A')}")
            description = uc.get('description', 'N/A')
            if len(description) > 150:
                description = description[:150] + "..."
            logger.info(f"      ğŸ“ {description}")
        
        # Sauvegarder les rÃ©sultats
        output_path = "/home/addeche/aiko/aikoGPT/outputs/use_case_analysis_test_results.json"
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(result, f, ensure_ascii=False, indent=2)
        
        logger.info(f"\nğŸ’¾ RÃ©sultats sauvegardÃ©s dans {output_path}")
        
    except Exception as e:
        logger.error(f"âŒ Erreur lors du test: {str(e)}")
        import traceback
        traceback.print_exc()
        return
    
    # Test 2 : VÃ©rification de la validation
    logger.info("\n" + "="*80)
    logger.info("TEST 2 : VÃ©rification de la validation")
    logger.info("="*80)
    
    # Simuler une validation partielle
    validated_qw_count = 3
    validated_sia_count = 4
    
    logger.info(f"ğŸ“Š Simulation: {validated_qw_count} Quick Wins validÃ©s, {validated_sia_count} Structuration IA validÃ©s")
    
    success = agent.check_validation_success(validated_qw_count, validated_sia_count)
    
    if success:
        logger.info("âœ… Validation rÃ©ussie (au moins 5 dans chaque famille)")
    else:
        logger.info("âš ï¸ Validation insuffisante (minimum 5 requis dans chaque famille)")
        logger.info(f"   - Quick Wins: {validated_qw_count}/5")
        logger.info(f"   - Structuration IA: {validated_sia_count}/5")
    
    # Test avec validation complÃ¨te
    validated_qw_count = 5
    validated_sia_count = 5
    
    logger.info(f"\nğŸ“Š Simulation: {validated_qw_count} Quick Wins validÃ©s, {validated_sia_count} Structuration IA validÃ©s")
    
    success = agent.check_validation_success(validated_qw_count, validated_sia_count)
    
    if success:
        logger.info("âœ… Validation rÃ©ussie (au moins 5 dans chaque famille)")
    else:
        logger.info("âš ï¸ Validation insuffisante")
    
    # Test 3 : RÃ©gÃ©nÃ©ration avec feedback
    logger.info("\n" + "="*80)
    logger.info("TEST 3 : RÃ©gÃ©nÃ©ration avec feedback")
    logger.info("="*80)
    
    try:
        # Simuler une rÃ©gÃ©nÃ©ration
        previous_use_cases = {
            "quick_wins": quick_wins,
            "structuration_ia": structuration_ia
        }
        
        logger.info("ğŸ“Š Simulation d'une rÃ©gÃ©nÃ©ration (itÃ©ration 2)")
        logger.info(f"   - Quick Wins validÃ©s: 3/5")
        logger.info(f"   - Structuration IA validÃ©s: 4/5")
        
        result2 = agent.analyze_use_cases(
            validated_needs=validated_needs,
            iteration=2,
            previous_use_cases=previous_use_cases,
            validated_quick_wins_count=3,
            validated_structuration_ia_count=4
        )
        
        if "error" in result2:
            logger.error(f"âŒ Erreur lors de la rÃ©gÃ©nÃ©ration: {result2['error']}")
            return
        
        quick_wins2 = result2.get("quick_wins", [])
        structuration_ia2 = result2.get("structuration_ia", [])
        
        logger.info(f"\nâœ… Cas d'usage rÃ©gÃ©nÃ©rÃ©s avec succÃ¨s!")
        logger.info(f"ğŸ“Š Quick Wins: {len(quick_wins2)}")
        logger.info(f"ğŸ“Š Structuration IA: {len(structuration_ia2)}")
        
        # Sauvegarder les rÃ©sultats de rÃ©gÃ©nÃ©ration
        output_path2 = "/home/addeche/aiko/aikoGPT/outputs/use_case_analysis_test_iteration2.json"
        with open(output_path2, 'w', encoding='utf-8') as f:
            json.dump(result2, f, ensure_ascii=False, indent=2)
        
        logger.info(f"ğŸ’¾ RÃ©sultats de l'itÃ©ration 2 sauvegardÃ©s dans {output_path2}")
        
    except Exception as e:
        logger.error(f"âŒ Erreur lors du test de rÃ©gÃ©nÃ©ration: {str(e)}")
        import traceback
        traceback.print_exc()
    
    logger.info("\n" + "="*80)
    logger.info("FIN DU TEST - Analyse des cas d'usage IA")
    logger.info("="*80)
    logger.info("\nâœ… Tous les tests sont terminÃ©s avec succÃ¨s!")
    logger.info("\nğŸ“‚ Fichiers gÃ©nÃ©rÃ©s:")
    logger.info("   - outputs/use_case_analysis_test_results.json")
    logger.info("   - outputs/use_case_analysis_test_iteration2.json")


if __name__ == "__main__":
    test_use_case_analysis()

