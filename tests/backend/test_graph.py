"""
Script de test du graphe LangGraph

FR: Test rapide du workflow d'analyse de besoins
"""

import os
import sys
import logging
from pathlib import Path

# FR: Ajouter le backend au path Python
backend_path = Path(__file__).parent.parent.parent / "backend"
sys.path.insert(0, str(backend_path))

from dotenv import load_dotenv

# FR: Charger les variables d'environnement
load_dotenv()

# FR: Activer le checkpointer pour les tests directs
os.environ["USE_CHECKPOINTER"] = "true"

# FR: Configuration du logging
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)


def test_graph_creation():
    """FR: Test de crÃ©ation du graphe"""
    logger.info("=" * 60)
    logger.info("ğŸ§ª Test 1 : CrÃ©ation du graphe LangGraph")
    logger.info("=" * 60)
    
    try:
        from graph_factory import need_analysis
        
        logger.info("âœ… Graphe crÃ©Ã© avec succÃ¨s")
        logger.info(f"ğŸ“Š Type: {type(need_analysis)}")
        
        # FR: Afficher les nodes du graphe
        if hasattr(need_analysis, 'get_graph'):
            graph_def = need_analysis.get_graph()
            logger.info(f"ğŸ“ Nodes: {list(graph_def.nodes.keys())}")
        
        return True
    except Exception as e:
        logger.error(f"âŒ Erreur lors de la crÃ©ation du graphe: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_graph_execution():
    """FR: Test d'exÃ©cution du graphe avec des donnÃ©es de test"""
    logger.info("\n" + "=" * 60)
    logger.info("ğŸ§ª Test 2 : ExÃ©cution du graphe avec donnÃ©es de test")
    logger.info("=" * 60)
    
    try:
        from graph_factory import need_analysis
        
        # FR: Ã‰tat initial de test
        root_path = Path(__file__).parent.parent.parent
        initial_state = {
            "excel_file_path": str(root_path / "documents/atelier_exemple.xlsx"),
            "pdf_json_file_paths": [
                str(root_path / "documents/040425-Cousin-Biotech-x-aiko-Echange-IA-Booster-RH-DAF-4e7c7d16-b8f6.pdf")
            ],
            "company_name": "Cousin Biotech",
            "action": "generate_needs"
        }
        
        logger.info("ğŸš€ Lancement du workflow...")
        logger.info(f"ğŸ“„ Excel: {initial_state['excel_file_path']}")
        logger.info(f"ğŸ“š PDF/JSON: {len(initial_state['pdf_json_file_paths'])} fichiers")
        logger.info(f"ğŸ¢ Entreprise: {initial_state['company_name']}")
        
        # FR: Configuration avec thread_id (requis par le checkpointer)
        config = {"configurable": {"thread_id": "test-run-001"}}
        
        # FR: ExÃ©cuter le graphe
        result = need_analysis.invoke(initial_state, config)
        
        logger.info("\nâœ… Workflow terminÃ© avec succÃ¨s !")
        logger.info(f"ğŸ“Š Ã‰tape finale: {result.get('current_step', 'N/A')}")
        logger.info(f"ğŸ’¡ Besoins gÃ©nÃ©rÃ©s: {len(result.get('needs', []))}")
        logger.info(f"ğŸ¯ Quick Wins: {len(result.get('quick_wins', []))}")
        logger.info(f"ğŸ—ï¸ Structuration IA: {len(result.get('structuration_ia', []))}")
        
        # FR: Afficher le premier besoin gÃ©nÃ©rÃ©
        if result.get('needs'):
            logger.info("\nğŸ“ Premier besoin gÃ©nÃ©rÃ©:")
            first_need = result['needs'][0]
            logger.info(f"   Titre: {first_need.get('title', 'N/A')}")
            logger.info(f"   Citations: {len(first_need.get('citations', []))}")
        
        return True
    except Exception as e:
        logger.error(f"âŒ Erreur lors de l'exÃ©cution du graphe: {e}")
        import traceback
        traceback.print_exc()
        return False


def main():
    """FR: Fonction principale de test"""
    logger.info("ğŸš€ DÃ©but des tests du graphe LangGraph")
    logger.info(f"ğŸ”‘ OpenAI Model: {os.getenv('OPENAI_MODEL', 'Non configurÃ©')}")
    
    # FR: Test 1 - CrÃ©ation
    success_creation = test_graph_creation()
    
    if not success_creation:
        logger.error("âŒ Ã‰chec du test de crÃ©ation, arrÃªt des tests")
        return False
    
    # FR: Test 2 - ExÃ©cution
    success_execution = test_graph_execution()
    
    # FR: RÃ©sumÃ©
    logger.info("\n" + "=" * 60)
    logger.info("ğŸ“Š RÃ‰SUMÃ‰ DES TESTS")
    logger.info("=" * 60)
    logger.info(f"âœ… CrÃ©ation du graphe: {'OK' if success_creation else 'Ã‰CHEC'}")
    logger.info(f"âœ… ExÃ©cution du graphe: {'OK' if success_execution else 'Ã‰CHEC'}")
    
    if success_creation and success_execution:
        logger.info("\nğŸ‰ Tous les tests sont passÃ©s !")
        return True
    else:
        logger.error("\nâŒ Certains tests ont Ã©chouÃ©")
        return False


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)

