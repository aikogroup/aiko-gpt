"""
Workflow LangGraph pour l'analyse des besoins
"""

import os
import json
from typing import Dict, List, Any, TypedDict, Annotated
from concurrent.futures import ThreadPoolExecutor, as_completed
from langgraph.graph import StateGraph, END
from langgraph.graph.message import add_messages
from langchain_core.messages import BaseMessage, HumanMessage, AIMessage
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langgraph.checkpoint.memory import MemorySaver
import streamlit as st

# Import des agents
import sys
sys.path.append('/home/addeche/aiko/aikoGPT')
import config as project_config
from need_analysis.need_analysis_agent import NeedAnalysisAgent
from process_atelier.workshop_agent import WorkshopAgent
from process_transcript.transcript_agent import TranscriptAgent
from web_search.web_search_agent import WebSearchAgent
from human_in_the_loop.streamlit_validation_interface import StreamlitValidationInterface
from use_case_analysis.use_case_analysis_agent import UseCaseAnalysisAgent
from use_case_analysis.streamlit_use_case_validation import StreamlitUseCaseValidation
from utils.token_tracker import TokenTracker


class WorkflowState(TypedDict):
    """Ã‰tat du workflow LangGraph"""
    messages: Annotated[List[BaseMessage], add_messages]
    # IDs de documents dans la BDD
    workshop_document_ids: List[int]
    transcript_document_ids: List[int]
    company_info: Dict[str, Any]
    # Informations supplÃ©mentaires fournies par l'utilisateur
    additional_context: str
    # ParamÃ¨tres de gÃ©nÃ©ration
    num_needs: int
    num_quotes_per_need: int
    # RÃ©sultats des agents
    workshop_results: Dict[str, Any]
    transcript_results: List[Dict[str, Any]]
    web_search_results: Dict[str, Any]
    # Flag pour skip agents si rÃ©sultats prÃ©-calculÃ©s
    skip_agents: bool
    # DonnÃ©es agrÃ©gÃ©es pour l'analyse (seulement transcript_data car il contient une transformation utile)
    transcript_data: List[Dict[str, Any]]
    # RÃ©sultats de l'analyse des besoins
    identified_needs: List[Dict[str, Any]]
    # Validation humaine des besoins
    validated_needs: List[Dict[str, Any]]
    rejected_needs: List[Dict[str, Any]]
    user_feedback: str
    validation_result: Dict[str, Any]
    # Ã‰tat du workflow des besoins
    final_needs: List[Dict[str, Any]]
    workflow_paused: bool
    # Action demandÃ©e par l'utilisateur (pour les boutons)
    user_action: str  # "continue_needs" ou "continue_to_use_cases"
    # RÃ©sultats de l'analyse des use cases
    proposed_use_cases: List[Dict[str, Any]]
    # Contexte additionnel pour la gÃ©nÃ©ration des use cases
    use_case_additional_context: str
    use_case_famille: str
    # Validation humaine des use cases
    validated_use_cases: List[Dict[str, Any]]
    rejected_use_cases: List[Dict[str, Any]]
    use_case_user_feedback: str
    use_case_validation_result: Dict[str, Any]
    # Action demandÃ©e par l'utilisateur pour les use cases (pour les boutons)
    use_case_user_action: str  # "continue_use_cases" ou "finalize_use_cases"
    # Ã‰tat du workflow des use cases
    final_use_cases: List[Dict[str, Any]]
    use_case_workflow_paused: bool


class NeedAnalysisWorkflow:
    """
    Workflow LangGraph pour l'analyse des besoins mÃ©tier
    """
    
    def __init__(self, api_key: str, dev_mode: bool = False):
        """
        Initialise le workflow avec la clÃ© API OpenAI.
        
        Args:
            api_key: ClÃ© API OpenAI
            dev_mode: Mode dÃ©veloppement (utilise les donnÃ©es mockÃ©es)
        """
        self.api_key = api_key
        self.dev_mode = dev_mode
        model = os.getenv('OPENAI_MODEL', 'gpt-5-nano')
        self.llm = ChatOpenAI(
            model=model,
            api_key=api_key
        )
        
        # Initialisation du tracker de tokens et coÃ»ts
        self.tracker = TokenTracker(output_dir="outputs/token_tracking")
        print("ğŸ“Š Token Tracker initialisÃ© - Suivi des coÃ»ts activÃ©\n")
        
        # Initialisation des agents AVEC le tracker pour ceux qui le supportent
        self.workshop_agent = WorkshopAgent(api_key)
        self.transcript_agent = TranscriptAgent(api_key)
        self.web_search_agent = WebSearchAgent()  # Pas de paramÃ¨tre
        self.need_analysis_agent = NeedAnalysisAgent(api_key, tracker=self.tracker)
        self.human_interface = StreamlitValidationInterface()
        # Nouveaux agents pour l'analyse des use cases
        self.use_case_analysis_agent = UseCaseAnalysisAgent(api_key, tracker=self.tracker)
        self.use_case_validation_interface = StreamlitUseCaseValidation()
        
        # Configuration du checkpointer pour le debugging
        self.checkpointer = self._setup_checkpointer()
        
        # CrÃ©ation du graphe
        self.graph = self._create_graph()
    
    def _print_tracker_stats(self, agent_name: str = None):
        """
        Affiche les statistiques de tokens du tracker.
        
        Args:
            agent_name: Nom de l'agent qui vient de s'exÃ©cuter (optionnel)
        """
        if not self.tracker:
            return
        
        summary = self.tracker.get_session_summary()
        
        print("\n" + "â”€"*70)
        if agent_name:
            print(f"ğŸ“Š TOKENS APRÃˆS {agent_name.upper()}")
        else:
            print("ğŸ“Š TOKENS CUMULÃ‰S")
        print("â”€"*70)
        
        # Tokens cumulÃ©s
        total_tokens = summary['total_tokens']
        input_tokens = summary['total_input_tokens']
        output_tokens = summary['total_output_tokens']
        
        print(f"ğŸ”¤ Tokens cumulÃ©s: {total_tokens:,}")
        print(f"   â”œâ”€ Input:  {input_tokens:,}")
        print(f"   â””â”€ Output: {output_tokens:,}")
        
        # DÃ©tails par agent
        if summary['calls_by_agent']:
            print(f"\nğŸ“Š DÃ©tails par agent:")
            for name, stats in summary['calls_by_agent'].items():
                print(f"   â€¢ {name}:")
                print(f"     â”œâ”€ Total: {stats['total_tokens']:,} tokens")
                print(f"     â”œâ”€ Input: {stats['input_tokens']:,}")
                print(f"     â””â”€ Output: {stats['output_tokens']:,}")
        
        print("â”€"*70 + "\n")
    
    def _setup_checkpointer(self):
        """
        Configure le checkpointer pour le debugging avec LangGraph Studio.
        
        Returns:
            Checkpointer configurÃ©
        """
        # Toujours utiliser MemorySaver pour gÃ©rer les interrupts
        return MemorySaver()
    
    def _create_graph(self) -> StateGraph:
        """
        CrÃ©e le graphe LangGraph pour le workflow d'analyse des besoins.
        NOUVELLE VERSION: Avec parallÃ©lisation des agents.
        
        Returns:
            StateGraph configurÃ©
        """
        # CrÃ©ation du graphe
        workflow = StateGraph(WorkflowState)
        
        # Ajout des nÅ“uds - Phase 1 : Analyse des besoins
        # NOUVEAU: Dispatcher et agents parallÃ¨les
        workflow.add_node("dispatcher", self._dispatcher_node)
        workflow.add_node("workshop_agent", self._workshop_agent_node)
        workflow.add_node("transcript_agent", self._transcript_agent_node)
        workflow.add_node("web_search_agent", self._web_search_agent_node)
        workflow.add_node("collect_data", self._collect_data_node)
        workflow.add_node("analyze_needs", self._analyze_needs_node)
        workflow.add_node("human_validation", self._human_validation_node)
        workflow.add_node("finalize_results", self._finalize_results_node)
        
        # Ajout des nÅ“uds - Phase 2 : Analyse des use cases
        workflow.add_node("pre_use_case_interrupt", self._pre_use_case_interrupt_node)
        workflow.add_node("analyze_use_cases", self._analyze_use_cases_node)
        workflow.add_node("validate_use_cases", self._validate_use_cases_node)
        workflow.add_node("finalize_use_cases", self._finalize_use_cases_node)
        
        # DÃ©finition du flux - toujours commencer par dispatcher
        workflow.set_entry_point("dispatcher")
        
        # NOUVEAU: Flux parallÃ¨le - Phase 1 : Collecte de donnÃ©es
        # Dispatcher â†’ 3 agents en parallÃ¨le â†’ collect_data
        workflow.add_edge("dispatcher", "workshop_agent")
        workflow.add_edge("dispatcher", "transcript_agent")
        workflow.add_edge("dispatcher", "web_search_agent")
        workflow.add_edge("workshop_agent", "collect_data")
        workflow.add_edge("transcript_agent", "collect_data")
        workflow.add_edge("web_search_agent", "collect_data")
        
        # Flux sÃ©quentiel - Phase 1 : Analyse des besoins
        workflow.add_edge("collect_data", "analyze_needs")
        workflow.add_edge("analyze_needs", "human_validation")
        
        # Conditions de branchement - Phase 1 (basÃ© sur l'action utilisateur)
        workflow.add_conditional_edges(
            "human_validation",
            self._should_continue_needs,
            {
                "continue_needs": "analyze_needs",
                "continue_to_use_cases": "finalize_results"
            }
        )
        
        # Transition vers Phase 2 : Analyse des use cases
        workflow.add_edge("finalize_results", "pre_use_case_interrupt")
        workflow.add_edge("pre_use_case_interrupt", "analyze_use_cases")
        workflow.add_edge("analyze_use_cases", "validate_use_cases")
        
        # Conditions de branchement - Phase 2 (basÃ© sur l'action utilisateur)
        workflow.add_conditional_edges(
            "validate_use_cases",
            self._should_continue_use_cases,
            {
                "continue_use_cases": "analyze_use_cases",
                "finalize_use_cases": "finalize_use_cases"
            }
        )
        
        workflow.add_edge("finalize_use_cases", END)
        
        # Configuration avec checkpointer et interrupts
        # NOUVEAU: Toujours utiliser checkpointer et interrupts (pas seulement en debug)
        compile_kwargs = {
            "checkpointer": MemorySaver(),  # Toujours actif pour gÃ©rer les interrupts
            "interrupt_before": ["human_validation", "pre_use_case_interrupt", "validate_use_cases"]  # Points d'arrÃªt pour validation humaine
        }
        
        # Pas d'options supplÃ©mentaires en mode dev
        
        return workflow.compile(**compile_kwargs)
    
    # ==================== NOUVEAUX NÅ’UDS POUR LA PARALLÃ‰LISATION ====================
    
    def _dispatcher_node(self, state: WorkflowState) -> WorkflowState:
        """
        NÅ“ud dispatcher qui prÃ©pare et distribue le travail aux 3 agents en parallÃ¨le.
        
        Args:
            state: Ã‰tat actuel du workflow
            
        Returns:
            Ã‰tat mis Ã  jour
        """
        print(f"\nğŸš€ [PARALLÃ‰LISATION] dispatcher_node - DÃ‰BUT")
        print(f"ğŸ“Š Ã‰tat d'entrÃ©e:")
        print(f"   - workshop_document_ids: {len(state.get('workshop_document_ids', []))}")
        print(f"   - transcript_document_ids: {len(state.get('transcript_document_ids', []))}")
        print(f"   - company_info: {bool(state.get('company_info', {}))}")
        print(f"   - RÃ©sultats prÃ©-calculÃ©s:")
        print(f"     â€¢ workshop_results: {bool(state.get('workshop_results', {}))}")
        print(f"     â€¢ transcript_results: {bool(state.get('transcript_results', []))}")
        print(f"     â€¢ web_search_results: {bool(state.get('web_search_results', {}))}")
        
        try:
            # VÃ©rifier si les rÃ©sultats sont dÃ©jÃ  prÃ©sents (calculÃ©s dans Streamlit)
            if state.get("workshop_results") or state.get("transcript_results") or state.get("web_search_results"):
                print(f"âœ… [PARALLÃ‰LISATION] RÃ©sultats prÃ©-calculÃ©s dÃ©tectÃ©s - skip des agents")
                # Marquer que nous n'avons pas besoin d'exÃ©cuter les agents
                state["skip_agents"] = True
            else:
                print(f"ğŸ”„ [PARALLÃ‰LISATION] Aucun rÃ©sultat prÃ©-calculÃ© - les 3 agents vont s'exÃ©cuter en PARALLÃˆLE")
                state["skip_agents"] = False
            
            print(f"âœ… [PARALLÃ‰LISATION] dispatcher_node - FIN")
            return state
            
        except Exception as e:
            print(f"âŒ [PARALLÃ‰LISATION] Erreur dans dispatcher_node: {str(e)}")
            state["messages"] = state.get("messages", []) + [HumanMessage(content=f"Erreur dispatcher: {str(e)}")]
            return state
    
    def _workshop_agent_node(self, state: WorkflowState) -> Dict[str, Any]:
        """
        NÅ“ud workshop agent - s'exÃ©cute en PARALLÃˆLE avec les autres agents.
        
        Args:
            state: Ã‰tat actuel du workflow
            
        Returns:
            Dictionnaire partiel avec seulement workshop_results (pour Ã©viter les conflits de fusion)
        """
        print(f"\nğŸ“ [PARALLÃˆLE-1/3] workshop_agent_node - DÃ‰BUT")
        
        try:
            # Si les rÃ©sultats sont prÃ©-calculÃ©s, skip
            if state.get("skip_agents", False):
                print(f"â© [PARALLÃˆLE-1/3] RÃ©sultats prÃ©-calculÃ©s - skip")
                return {}
            
            # MODE DEV: Charger les donnÃ©es mockÃ©es depuis le fichier JSON
            if project_config.is_agent_dev_mode("workshop"):
                print(f"ğŸ”§ [PARALLÃˆLE-1/3] Mode dev WORKSHOP_DEV_MODE activÃ© - chargement des donnÃ©es mockÃ©es")
                try:
                    mock_data = project_config.load_mock_data()
                    workshop_data = mock_data.get("workshop", {})
                    print(f"âœ… [PARALLÃˆLE-1/3] DonnÃ©es mockÃ©es chargÃ©es: {len(workshop_data.get('workshops', []))} workshops")
                    return {"workshop_results": workshop_data}
                except Exception as e:
                    print(f"âš ï¸ [PARALLÃˆLE-1/3] Erreur lors du chargement des donnÃ©es mockÃ©es: {str(e)}")
                    return {"workshop_results": {"workshops": []}}
            
            # Fallback sur dev_mode global pour compatibilitÃ©
            if self.dev_mode:
                print(f"ğŸ”§ [PARALLÃˆLE-1/3] Mode dev global - retour de donnÃ©es mockÃ©es vides")
                return {"workshop_results": {"workshops": []}}
            
            workshop_document_ids = state.get("workshop_document_ids", [])
            
            if workshop_document_ids:
                print(f"ğŸ”„ [PARALLÃˆLE-1/3] Traitement de {len(workshop_document_ids)} workshops depuis la BDD...")
                all_results = []
                for document_id in workshop_document_ids:
                    file_results = self.workshop_agent.process_workshop_from_db(document_id)
                    all_results.extend(file_results)
                print(f"âœ… [PARALLÃˆLE-1/3] {len(all_results)} workshops traitÃ©s")
                print(f"âœ… [PARALLÃˆLE-1/3] workshop_agent_node - FIN")
                return {"workshop_results": {"workshops": all_results}}
            else:
                print(f"âš ï¸ [PARALLÃˆLE-1/3] Aucun workshop fourni")
                print(f"âœ… [PARALLÃˆLE-1/3] workshop_agent_node - FIN")
                return {"workshop_results": {}}
            
        except Exception as e:
            print(f"âŒ [PARALLÃˆLE-1/3] Erreur dans workshop_agent_node: {str(e)}")
            return {
                "workshop_results": {},
                "messages": [HumanMessage(content=f"Erreur workshop agent: {str(e)}")]
            }
    
    def _transcript_agent_node(self, state: WorkflowState) -> Dict[str, Any]:
        """
        NÅ“ud transcript agent - s'exÃ©cute en PARALLÃˆLE avec les autres agents.
        
        Args:
            state: Ã‰tat actuel du workflow
            
        Returns:
            Dictionnaire partiel avec seulement transcript_results (pour Ã©viter les conflits de fusion)
        """
        print(f"\nğŸ“„ [PARALLÃˆLE-2/3] transcript_agent_node - DÃ‰BUT")
        
        try:
            # Si les rÃ©sultats sont prÃ©-calculÃ©s, skip
            if state.get("skip_agents", False):
                print(f"â© [PARALLÃˆLE-2/3] RÃ©sultats prÃ©-calculÃ©s - skip")
                return {}
            
            # MODE DEV: Charger les donnÃ©es mockÃ©es depuis le fichier JSON
            if project_config.is_agent_dev_mode("transcript"):
                print(f"ğŸ”§ [PARALLÃˆLE-2/3] Mode dev TRANSCRIPT_DEV_MODE activÃ© - chargement des donnÃ©es mockÃ©es")
                try:
                    mock_data = project_config.load_mock_data()
                    transcript_data = mock_data.get("transcript", {})
                    print(f"âœ… [PARALLÃˆLE-2/3] DonnÃ©es mockÃ©es chargÃ©es: {len(transcript_data.get('results', []))} transcripts")
                    return {"transcript_results": transcript_data}
                except Exception as e:
                    print(f"âš ï¸ [PARALLÃˆLE-2/3] Erreur lors du chargement des donnÃ©es mockÃ©es: {str(e)}")
                    return {"transcript_results": {"results": []}}
            
            # Fallback sur dev_mode global pour compatibilitÃ©
            if self.dev_mode:
                print(f"ğŸ”§ [PARALLÃˆLE-2/3] Mode dev global - retour de donnÃ©es mockÃ©es vides")
                return {"transcript_results": {"results": []}}
            
            transcript_document_ids = state.get("transcript_document_ids", [])
            
            if transcript_document_ids:
                print(f"ğŸ”„ [PARALLÃˆLE-2/3] Traitement de {len(transcript_document_ids)} transcripts depuis la BDD...")
                
                # ğŸš€ PARALLÃ‰LISATION : Traiter tous les transcripts en mÃªme temps
                results = []
                max_workers = min(len(transcript_document_ids), 10)  # Maximum 10 threads en parallÃ¨le
                print(f"ğŸš€ [PARALLÃˆLE-2/3] ParallÃ©lisation avec {max_workers} workers pour {len(transcript_document_ids)} transcripts")
                
                with ThreadPoolExecutor(max_workers=max_workers) as executor:
                    # Soumettre tous les transcripts pour traitement parallÃ¨le
                    future_to_doc = {
                        executor.submit(self.transcript_agent.process_from_db, document_id): document_id
                        for document_id in transcript_document_ids
                    }
                    
                    # RÃ©cupÃ©rer les rÃ©sultats au fur et Ã  mesure
                    for future in as_completed(future_to_doc):
                        document_id = future_to_doc[future]
                        try:
                            result = future.result()
                            results.append(result)
                            print(f"âœ… [PARALLÃˆLE-2/3] Transcript document_id={document_id} terminÃ©")
                        except Exception as e:
                            print(f"âŒ [PARALLÃˆLE-2/3] Erreur lors du traitement du transcript document_id={document_id}: {e}")
                            # CrÃ©er un rÃ©sultat fallback pour Ã©viter de bloquer le workflow
                            results.append({
                                "document_id": document_id,
                                "status": "error",
                                "error": str(e)
                            })
                
                print(f"âœ… [PARALLÃˆLE-2/3] {len(results)} transcripts traitÃ©s")
                print(f"âœ… [PARALLÃˆLE-2/3] transcript_agent_node - FIN")
                return {"transcript_results": {"results": results}}
            else:
                print(f"âš ï¸ [PARALLÃˆLE-2/3] Aucun transcript fourni")
                print(f"âœ… [PARALLÃˆLE-2/3] transcript_agent_node - FIN")
                return {"transcript_results": []}
            
        except Exception as e:
            print(f"âŒ [PARALLÃˆLE-2/3] Erreur dans transcript_agent_node: {str(e)}")
            return {
                "transcript_results": [],
                "messages": [HumanMessage(content=f"Erreur transcript agent: {str(e)}")]
            }
    
    def _web_search_agent_node(self, state: WorkflowState) -> Dict[str, Any]:
        """
        NÅ“ud web search agent - s'exÃ©cute en PARALLÃˆLE avec les autres agents.
        
        Args:
            state: Ã‰tat actuel du workflow
            
        Returns:
            Dictionnaire partiel avec seulement web_search_results (pour Ã©viter les conflits de fusion)
        """
        print(f"\nğŸŒ [PARALLÃˆLE-3/3] web_search_agent_node - DÃ‰BUT")
        
        try:
            # Si les rÃ©sultats sont prÃ©-calculÃ©s, skip
            if state.get("skip_agents", False):
                print(f"â© [PARALLÃˆLE-3/3] RÃ©sultats prÃ©-calculÃ©s - skip")
                return {}
            
            # MODE DEV: Charger les donnÃ©es mockÃ©es depuis le fichier JSON
            if project_config.is_agent_dev_mode("web_search"):
                print(f"ğŸ”§ [PARALLÃˆLE-3/3] Mode dev WEB_SEARCH_DEV_MODE activÃ© - chargement des donnÃ©es mockÃ©es")
                try:
                    mock_data = project_config.load_mock_data()
                    web_search_data = mock_data.get("web_search", {})
                    print(f"âœ… [PARALLÃˆLE-3/3] DonnÃ©es mockÃ©es chargÃ©es pour: {web_search_data.get('nom', 'N/A')}")
                    return {"web_search_results": web_search_data}
                except Exception as e:
                    print(f"âš ï¸ [PARALLÃˆLE-3/3] Erreur lors du chargement des donnÃ©es mockÃ©es: {str(e)}")
                    return {"web_search_results": {}}
            
            # Fallback sur dev_mode global pour compatibilitÃ©
            if self.dev_mode:
                print(f"ğŸ”§ [PARALLÃˆLE-3/3] Mode dev global - retour de donnÃ©es mockÃ©es vides")
                return {"web_search_results": {}}
            
            company_info = state.get("company_info", {})
            
            if company_info:
                # VÃ©rifier si company_info contient dÃ©jÃ  les clÃ©s de CompanyInfo (validated_company_info)
                # Les clÃ©s de CompanyInfo sont: nom, secteur, chiffre_affaires, nombre_employes, description
                if "nom" in company_info or "secteur" in company_info:
                    # C'est un validated_company_info, l'utiliser directement
                    print(f"âœ… [PARALLÃˆLE-3/3] Utilisation des informations validÃ©es (validated_company_info)")
                    print(f"âœ… [PARALLÃˆLE-3/3] web_search_agent_node - FIN")
                    return {"web_search_results": company_info}
                
                # Sinon, c'est l'ancien format avec company_name, company_url, etc.
                company_name = company_info.get("company_name", "")
                if company_name:
                    company_url = company_info.get("company_url")
                    company_description = company_info.get("company_description")
                    print(f"ğŸ”„ [PARALLÃˆLE-3/3] Recherche web pour: {company_name}")
                    results = self.web_search_agent.search_company_info(
                        company_name,
                        company_url=company_url,
                        company_description=company_description
                    )
                    print(f"âœ… [PARALLÃˆLE-3/3] Recherche web terminÃ©e")
                    print(f"âœ… [PARALLÃˆLE-3/3] web_search_agent_node - FIN")
                    return {"web_search_results": results}
                else:
                    print(f"âš ï¸ [PARALLÃˆLE-3/3] Nom d'entreprise non fourni")
                    print(f"âœ… [PARALLÃˆLE-3/3] web_search_agent_node - FIN")
                    return {"web_search_results": {}}
            else:
                print(f"âš ï¸ [PARALLÃˆLE-3/3] Aucune information entreprise fournie")
                print(f"âœ… [PARALLÃˆLE-3/3] web_search_agent_node - FIN")
                return {"web_search_results": {}}
            
        except Exception as e:
            print(f"âŒ [PARALLÃˆLE-3/3] Erreur dans web_search_agent_node: {str(e)}")
            return {
                "web_search_results": {},
                "messages": [HumanMessage(content=f"Erreur web search agent: {str(e)}")]
            }
    
    # ==================== ANCIEN NÅ’UD (LEGACY - conservÃ© pour compatibilitÃ©) ====================
    
    def _start_agents_node(self, state: WorkflowState) -> WorkflowState:
        """
        NÅ“ud de dÃ©marrage qui utilise les rÃ©sultats prÃ©-calculÃ©s ou lance les agents si nÃ©cessaire.
        NOUVELLE APPROCHE: Les rÃ©sultats sont calculÃ©s dans Streamlit et passÃ©s directement.
        
        Args:
            state: Ã‰tat actuel du workflow
            
        Returns:
            Ã‰tat mis Ã  jour
        """
        print(f"\nğŸš€ [DEBUG] _start_agents_node - DÃ‰BUT")
        print(f"ğŸ“Š Ã‰tat d'entrÃ©e: workshop_results={len(state.get('workshop_results', {}).get('workshops', []))}, transcript_results={len(state.get('transcript_results', []))}, web_search_results prÃ©sent={bool(state.get('web_search_results', {}))}")
        
        try:
            # VÃ‰RIFIER SI LES RÃ‰SULTATS SONT DÃ‰JÃ€ PRÃ‰SENTS (calculÃ©s dans Streamlit)
            if state.get("workshop_results") or state.get("transcript_results") or state.get("web_search_results"):
                print(f"âœ… [DEBUG] RÃ©sultats prÃ©-calculÃ©s dÃ©tectÃ©s - utilisation directe")
                print(f"ğŸ“Š workshop_results: {len(state.get('workshop_results', {}).get('workshops', []))} workshops")
                print(f"ğŸ“Š transcript_results: {len(state.get('transcript_results', []))} transcripts")
                print(f"ğŸ“Š web_search_results: {len(state.get('web_search_results', {}))} recherches")
                
                # Les rÃ©sultats sont dÃ©jÃ  dans l'Ã©tat, on les utilise directement
                # Pas besoin de relancer les agents
                print(f"âœ… [DEBUG] _start_agents_node - FIN (rÃ©sultats prÃ©-calculÃ©s utilisÃ©s)")
                return state
            
            # SINON, lancer les agents depuis la BDD
            print(f"âš ï¸ [DEBUG] Aucun rÃ©sultat prÃ©-calculÃ© - lancement des agents depuis la BDD")
            workshop_document_ids = state.get("workshop_document_ids", [])
            transcript_document_ids = state.get("transcript_document_ids", [])
            company_info = state.get("company_info", {})
            
            # Workshop Agent
            if workshop_document_ids:
                all_results = []
                for document_id in workshop_document_ids:
                    file_results = self.workshop_agent.process_workshop_from_db(document_id)
                    all_results.extend(file_results)
                state["workshop_results"] = {"workshops": all_results}
            else:
                state["workshop_results"] = {}
                state["messages"] = state.get("messages", []) + [HumanMessage(content="Aucun document workshop fourni")]
            
            # Transcript Agent
            if transcript_document_ids:
                results = []
                for document_id in transcript_document_ids:
                    result = self.transcript_agent.process_from_db(document_id)
                    results.append(result)
                state["transcript_results"] = {"results": results}
            else:
                state["transcript_results"] = []
                state["messages"] = state.get("messages", []) + [HumanMessage(content="Aucun document transcript fourni")]
            
            # Web Search Agent
            if company_info:
                company_name = company_info.get("company_name", "")
                if company_name:
                    company_url = company_info.get("company_url")
                    company_description = company_info.get("company_description")
                    results = self.web_search_agent.search_company_info(
                        company_name,
                        company_url=company_url,
                        company_description=company_description
                    )
                    state["web_search_results"] = results
                else:
                    state["web_search_results"] = {}
                    state["messages"] = state.get("messages", []) + [HumanMessage(content="Nom d'entreprise non fourni")]
            else:
                state["web_search_results"] = {}
                state["messages"] = state.get("messages", []) + [HumanMessage(content="Aucune information entreprise fournie")]
            
            print(f"âœ… [DEBUG] _start_agents_node - FIN")
            print(f"ğŸ“Š RÃ©sultats: {len(state.get('workshop_results', {}).get('workshops', []))} workshops, {len(state.get('transcript_results', []))} transcripts, {len(state.get('web_search_results', {}))} recherches web")
            return state
            
        except Exception as e:
            print(f"âŒ [DEBUG] Erreur dans _start_agents_node: {str(e)}")
            state["messages"] = state.get("messages", []) + [HumanMessage(content=f"Erreur dÃ©marrage agents: {str(e)}")]
            return state
    
    
    def _collect_data_node(self, state: WorkflowState) -> WorkflowState:
        """
        NÅ“ud d'agrÃ©gation des donnÃ©es des 3 agents.
        NOUVEAU: Attend que les 3 agents parallÃ¨les aient terminÃ©.
        
        Args:
            state: Ã‰tat actuel du workflow
            
        Returns:
            Ã‰tat mis Ã  jour
        """
        print(f"\nğŸ“Š [CONVERGENCE] collect_data_node - DÃ‰BUT")
        print(f"ğŸ”„ Mode dev: {self.dev_mode}")
        print(f"ğŸ“Š RÃ©sultats des agents parallÃ¨les:")
        print(f"   â€¢ workshop_results: {len(state.get('workshop_results', {}).get('workshops', []))} workshops")
        print(f"   â€¢ transcript_results: {len(state.get('transcript_results', {}).get('results', []) if isinstance(state.get('transcript_results', {}), dict) else state.get('transcript_results', []))} transcripts")
        print(f"   â€¢ web_search_results: {bool(state.get('web_search_results', {}))}")
        
        try:
            # MODE DEV: Les agents ont dÃ©jÃ  retournÃ© des donnÃ©es mockÃ©es, on utilise directement les rÃ©sultats
            if self.dev_mode:
                print(f"ğŸ”§ [CONVERGENCE] Mode dev - utilisation des rÃ©sultats mockÃ©s des agents")
                # Les agents ont dÃ©jÃ  retournÃ© des donnÃ©es mockÃ©es vides
                # On prÃ©pare juste transcript_data pour la suite
                transcript_results_raw = state.get("transcript_results", {})
                if isinstance(transcript_results_raw, dict) and "results" in transcript_results_raw:
                    transcript_results = transcript_results_raw.get("results", [])
                elif isinstance(transcript_results_raw, list):
                    transcript_results = transcript_results_raw
                else:
                    transcript_results = []
                
                filtered_transcripts = []
                for transcript in transcript_results:
                    if isinstance(transcript, dict):
                        filtered_transcript = {
                            "pdf_path": transcript.get("pdf_path"),
                            "status": transcript.get("status"),
                            "semantic_analysis": transcript.get("semantic_analysis", {})
                        }
                        filtered_transcripts.append(filtered_transcript)
                
                state["transcript_data"] = filtered_transcripts
                print(f"ğŸ” [CONVERGENCE] Transcripts filtrÃ©s: {len(filtered_transcripts)} transcripts")
            else:
                # Mode normal - agrÃ©gation des rÃ©sultats des 3 agents PARALLÃˆLES
                print(f"ğŸ“Š [CONVERGENCE] AgrÃ©gation des rÃ©sultats des agents parallÃ¨les")
                
                # SIMPLIFICATION: Utiliser directement workshop_results et web_search_results
                # Seule transformation nÃ©cessaire : filtrer transcript_data pour garder seulement semantic_analysis
                
                # OPTIMISATION: Ne garder que semantic_analysis dans transcript_data
                transcript_results_raw = state.get("transcript_results", {})
                
                print(f"ğŸ” [CONVERGENCE] Type de transcript_results_raw: {type(transcript_results_raw)}")
                if isinstance(transcript_results_raw, dict):
                    print(f"ğŸ” [CONVERGENCE] ClÃ©s du dictionnaire: {list(transcript_results_raw.keys())}")
                
                # Extraire la liste "results" si c'est un dictionnaire avec cette clÃ©
                if isinstance(transcript_results_raw, dict) and "results" in transcript_results_raw:
                    transcript_results = transcript_results_raw.get("results", [])
                    print(f"âœ… [CONVERGENCE] Extraction de la clÃ© 'results': {len(transcript_results)} transcripts")
                elif isinstance(transcript_results_raw, list):
                    transcript_results = transcript_results_raw
                    print(f"âœ… [CONVERGENCE] transcript_results est dÃ©jÃ  une liste: {len(transcript_results)} Ã©lÃ©ments")
                else:
                    transcript_results = []
                    print(f"âš ï¸ [CONVERGENCE] Format inattendu, utilisation d'une liste vide")
                
                filtered_transcripts = []
                for transcript in transcript_results:
                    # VÃ©rifier que transcript est bien un dictionnaire
                    if not isinstance(transcript, dict):
                        print(f"âš ï¸ [CONVERGENCE] Transcript ignorÃ© (type incorrect): {type(transcript)}")
                        continue
                    
                    filtered_transcript = {
                        "pdf_path": transcript.get("pdf_path"),
                        "status": transcript.get("status"),
                        "semantic_analysis": transcript.get("semantic_analysis", {})
                    }
                    filtered_transcripts.append(filtered_transcript)
                
                state["transcript_data"] = filtered_transcripts
                
                print(f"ğŸ” [CONVERGENCE] Transcripts filtrÃ©s: {len(filtered_transcripts)} transcripts (semantic_analysis uniquement)")
            
            # Initialisation des compteurs
            state["iteration_count"] = 0
            state["max_iterations"] = 3
            
            print(f"âœ… [CONVERGENCE] collect_data_node - FIN")
            print(f"ğŸ“Š DonnÃ©es agrÃ©gÃ©es: {len(state.get('workshop_results', {}).get('workshops', []))} workshops, {len(state.get('transcript_data', []))} transcripts, recherche web={bool(state.get('web_search_results', {}))}")
            print(f"ğŸ¯ [CONVERGENCE] Les 3 agents parallÃ¨les ont terminÃ© avec succÃ¨s")
            
            return state
            
        except Exception as e:
            print(f"âŒ [CONVERGENCE] Erreur dans collect_data_node: {str(e)}")
            state["messages"] = state.get("messages", []) + [HumanMessage(content=f"Erreur collecte donnÃ©es: {str(e)}")]
            return state
    
    def _analyze_needs_node(self, state: WorkflowState) -> WorkflowState:
        """
        NÅ“ud d'analyse des besoins.
        MODE DEV: Charge les besoins depuis un JSON au lieu de les gÃ©nÃ©rer.
        
        Args:
            state: Ã‰tat actuel du workflow
            
        Returns:
            Ã‰tat mis Ã  jour
        """
        print(f"\nğŸ” [DEBUG] _analyze_needs_node - DÃ‰BUT")
        print(f"ğŸ“Š Besoins dÃ©jÃ  validÃ©s: {len(state.get('validated_needs', []))}")
        print(f"ğŸ”„ ItÃ©ration: {state.get('iteration_count', 0)}/{state.get('max_iterations', 3)}")
        print(f"ğŸ”§ Mode dev: {self.dev_mode}")
        
        try:
            # VÃ©rifier s'il y a des besoins dÃ©jÃ  validÃ©s
            validated_count = len(state.get("validated_needs", []))
            
            # MODE DEV: Charger les donnÃ©es mockÃ©es depuis le fichier JSON
            if project_config.is_agent_dev_mode("need_analysis"):
                print(f"ğŸ”§ [DEBUG] Mode dev NEED_ANALYSIS_DEV_MODE activÃ© - chargement des donnÃ©es mockÃ©es")
                try:
                    mock_data = project_config.load_mock_data()
                    need_analysis_data = mock_data.get("need_analysis", {})
                    identified_needs = need_analysis_data.get("identified_needs", [])
                    state["identified_needs"] = identified_needs
                    print(f"âœ… [DEBUG] Besoins mockÃ©s chargÃ©s: {len(identified_needs)}")
                    print(f"ğŸ“Š [DEBUG] Besoins identifiÃ©s: {len(identified_needs)}")
                    print(f"ğŸ¯ [DEBUG] Besoins validÃ©s total: {len(state.get('validated_needs', []))}")
                    return state
                except Exception as e:
                    print(f"âš ï¸ [DEBUG] Erreur lors du chargement des donnÃ©es mockÃ©es: {str(e)}")
                    # Continuer en mode normal si le chargement Ã©choue
            
            # Fallback sur dev_mode global pour compatibilitÃ©
            if self.dev_mode:
                print(f"ğŸ”§ [DEBUG] Mode dev global activÃ© - utilisation de debug_needs")
                # DÃ©finir les besoins de debug (mÃªme structure que dans app_api.py)
                debug_needs = [
                    {
                        "theme": "Automatisation & EfficacitÃ© OpÃ©rationnelle",
                        "quotes": [
                            "Nous passons trop de temps sur les tÃ¢ches administratives rÃ©pÃ©titives",
                            "L'automatisation nous ferait gagner beaucoup de temps"
                        ]
                    },
                    {
                        "theme": "Analyse de DonnÃ©es & AmÃ©lioration de la Performance",
                        "quotes": [
                            "Nous avons besoin de mieux suivre nos performances commerciales",
                            "Un dashboard en temps rÃ©el serait trÃ¨s utile"
                        ]
                    },
                    {
                        "theme": "Optimisation de la Gestion des Stocks",
                        "quotes": [
                            "Nous avons souvent des ruptures de stock",
                            "Une meilleure prÃ©vision nous aiderait"
                        ]
                    },
                    {
                        "theme": "AmÃ©lioration du Recrutement",
                        "quotes": [
                            "La formation de nos Ã©quipes est un enjeu majeur",
                            "Nous avons besoin d'un systÃ¨me de suivi des compÃ©tences"
                        ]
                    },
                    {
                        "theme": "SystÃ¨me d'Alerte pour Non-ConformitÃ©",
                        "quotes": [
                            "La conformitÃ© rÃ©glementaire est complexe",
                            "Nous devons amÃ©liorer notre traÃ§abilitÃ©"
                        ]
                    }
                ]
                
                state["identified_needs"] = debug_needs
                
                print(f"âœ… [DEBUG] Besoins debug utilisÃ©s: {len(debug_needs)}")
                print(f"ğŸ“Š [DEBUG] Besoins identifiÃ©s: {len(debug_needs)}")
                print(f"ğŸ¯ [DEBUG] Besoins validÃ©s total: {len(state.get('validated_needs', []))}")
                
                return state
            
            # MODE NORMAL: GÃ©nÃ©ration des besoins avec l'IA
            print(f"ğŸ¤– [DEBUG] Mode normal - gÃ©nÃ©ration des besoins avec l'IA")
            
            # Analyse des besoins avec feedback si disponible
            user_feedback = state.get("user_feedback", "")
            rejected_needs = state.get("rejected_needs", [])
            previous_needs = state.get("identified_needs", [])
            
            if user_feedback or rejected_needs:
                print(f"\nğŸ”„ GÃ©nÃ©ration de nouvelles propositions...")
                if user_feedback:
                    print(f"ğŸ’¬ En tenant compte du feedback: {user_feedback}")
                if rejected_needs:
                    print(f"ğŸš« Besoins rejetÃ©s Ã  Ã©viter: {len(rejected_needs)}")
            
            # ğŸ’° OPTIMISATION: Filtrer les quotes des previous_needs et rejected_needs pour Ã©conomiser les tokens
            # Les quotes sont dÃ©jÃ  dans workshop/transcript, pas besoin de les dupliquer au LLM
            previous_needs_light = None
            rejected_needs_light = None
            
            if previous_needs:
                previous_needs_light = [
                    {"id": need.get("id"), "theme": need.get("theme")}
                    for need in previous_needs
                ]
                print(f"ğŸ’° [OPTIMISATION] Previous needs allÃ©gÃ©s: {len(previous_needs)} besoins sans quotes")
            
            if rejected_needs:
                rejected_needs_light = [
                    {"id": need.get("id"), "theme": need.get("theme")}
                    for need in rejected_needs
                ]
                print(f"ğŸ’° [OPTIMISATION] Rejected needs allÃ©gÃ©s: {len(rejected_needs)} besoins sans quotes")
            
            # AllÃ©ger aussi les besoins validÃ©s pour Ã©conomiser les tokens
            validated_needs = state.get("validated_needs", [])
            validated_needs_light = None
            if validated_needs:
                validated_needs_light = [
                    {"id": need.get("id"), "theme": need.get("theme")}
                    for need in validated_needs
                ]
                print(f"ğŸ’° [OPTIMISATION] Validated needs allÃ©gÃ©s: {len(validated_needs)} besoins sans quotes")
            
            analysis_result = self.need_analysis_agent.analyze_needs(
                workshop_data=state["workshop_results"],  # SIMPLIFICATION: utiliser directement workshop_results
                transcript_data=state["transcript_data"],
                web_search_data=state["web_search_results"],  # SIMPLIFICATION: utiliser directement web_search_results
                previous_needs=previous_needs_light,
                rejected_needs=rejected_needs_light,
                user_feedback=user_feedback,
                validated_needs_count=validated_count,
                validated_needs=validated_needs_light,
                additional_context=state.get("additional_context", ""),
                num_needs=state.get("num_needs", 10),
                num_quotes_per_need=state.get("num_quotes_per_need", 4)
            )
            
            if "error" in analysis_result:
                state["messages"] = state.get("messages", []) + [HumanMessage(content=f"Erreur analyse: {analysis_result['error']}")]
                return state
            
            # RÃ©cupÃ©rer tous les besoins identifiÃ©s (pas de limite)
            identified_needs = analysis_result.get("identified_needs", [])
            
            state["identified_needs"] = identified_needs
            
            print(f"âœ… [DEBUG] _analyze_needs_node - FIN")
            print(f"ğŸ“Š Besoins identifiÃ©s: {len(identified_needs)}")
            print(f"ğŸ¯ Besoins validÃ©s total: {len(state.get('validated_needs', []))}")
            
            # Affichage des coÃ»ts aprÃ¨s l'analyse des besoins
            self._print_tracker_stats(agent_name="need_analysis")
            
            return state
            
        except Exception as e:
            print(f"âŒ [DEBUG] Erreur dans _analyze_needs_node: {str(e)}")
            state["messages"] = state.get("messages", []) + [HumanMessage(content=f"Erreur analyse besoins: {str(e)}")]
            return state
    
    def _human_validation_node(self, state: WorkflowState) -> WorkflowState:
        """
        NÅ“ud de validation humaine SIMPLIFIÃ‰.
        
        NOUVELLE ARCHITECTURE avec interrupts natifs :
        - Le workflow s'arrÃªte AVANT ce nÅ“ud (interrupt_before)
        - L'API/Streamlit dÃ©tecte que le workflow est en pause
        - Streamlit affiche l'interface de validation
        - L'utilisateur valide et renvoie le feedback
        - Le feedback est injectÃ© dans l'Ã©tat via l'API
        - Le workflow reprend et ce nÅ“ud traite le feedback
        
        Args:
            state: Ã‰tat actuel du workflow
            
        Returns:
            Ã‰tat mis Ã  jour avec les besoins validÃ©s/rejetÃ©s
        """
        print(f"\nğŸ›‘ [INTERRUPT] human_validation_node - DÃ‰BUT")
        print(f"ğŸ“Š identified_needs: {len(state.get('identified_needs', []))}")
        print(f"ğŸ“Š validated_needs existants: {len(state.get('validated_needs', []))}")
        
        try:
            # VÃ©rifier si on a reÃ§u le feedback (injectÃ© par l'API)
            if "validation_result" in state and state["validation_result"]:
                print(f"âœ… [RESUME] Feedback reÃ§u via API")
                validation_data = state["validation_result"]
                
                # Traiter les rÃ©sultats de validation
                existing_validated = state.get("validated_needs", [])
                newly_validated = validation_data.get("validated_needs", [])
                
                # Ã‰viter les doublons
                existing_ids = [need.get("theme", "") for need in existing_validated]
                unique_newly_validated = [need for need in newly_validated if need.get("theme", "") not in existing_ids]
                
                state["validated_needs"] = existing_validated + unique_newly_validated
                
                # MÃªme logique pour les rejets
                existing_rejected = state.get("rejected_needs", [])
                newly_rejected = validation_data.get("rejected_needs", [])
                
                existing_rejected_ids = [need.get("theme", "") for need in existing_rejected]
                unique_newly_rejected = [need for need in newly_rejected if need.get("theme", "") not in existing_rejected_ids]
                
                state["rejected_needs"] = existing_rejected + unique_newly_rejected
                state["user_feedback"] = validation_data.get("user_feedback", "")
                
                # IncrÃ©menter le compteur d'itÃ©ration
                state["iteration_count"] = state.get("iteration_count", 0) + 1
                print(f"ğŸ”„ [DEBUG] iteration_count incrÃ©mentÃ© Ã  {state['iteration_count']}")
                
                # Nettoyer le flag
                state["validation_result"] = {}
                
                print(f"ğŸ“Š [RESUME] Besoins nouvellement validÃ©s: {len(unique_newly_validated)}")
                print(f"ğŸ“Š [RESUME] Total besoins validÃ©s: {len(state['validated_needs'])}")
                print(f"â–¶ï¸ [RESUME] Workflow continue...")
                
                return state
            else:
                # PremiÃ¨re fois : le workflow va s'arrÃªter ici (interrupt_before)
                print(f"â¸ï¸ [INTERRUPT] Aucun feedback - le workflow va s'arrÃªter")
                print(f"ğŸ’¡ [INTERRUPT] L'API dÃ©tectera cet arrÃªt et Streamlit affichera l'interface")
                
                # Juste retourner l'Ã©tat
                # Le workflow s'arrÃªte automatiquement car interrupt_before
                return state
            
        except Exception as e:
            print(f"âŒ [ERROR] Erreur dans human_validation_node: {str(e)}")
            state["messages"] = state.get("messages", []) + [HumanMessage(content=f"Erreur validation: {str(e)}")]
            return state
    
    
    def _finalize_results_node(self, state: WorkflowState) -> WorkflowState:
        """
        NÅ“ud de finalisation des rÃ©sultats.
        VERSION CORRIGÃ‰E: Utilise directement les besoins validÃ©s.
        MODE DEV: Charge les besoins depuis need_analysis_results.json si disponible.
        
        Args:
            state: Ã‰tat actuel du workflow
            
        Returns:
            Ã‰tat mis Ã  jour
        """
        try:
            print(f"\nğŸ” [DEBUG] _finalize_results_node - DÃ‰BUT")
            print(f"ğŸ”§ [DEBUG] Mode dev: {self.dev_mode}")
            print(f"ğŸ“Š [DEBUG] validation_result prÃ©sent: {'validation_result' in state}")
            print(f"ğŸ“Š [DEBUG] validated_needs dans state: {len(state.get('validated_needs', []))}")
            
            # MODE DEV: Charger les besoins depuis le JSON si disponible
            if self.dev_mode:
                try:
                    print(f"ğŸ”§ [DEBUG] Mode dev activÃ© - tentative de chargement depuis need_analysis_results.json")
                    with open('/home/addeche/aiko/aikoGPT/need_analysis_results.json', 'r', encoding='utf-8') as f:
                        need_data = json.load(f)
                    
                    final_needs = need_data.get("final_needs", [])
                    if final_needs:
                        state["final_needs"] = final_needs
                        print(f"âœ… [DEBUG] Besoins chargÃ©s depuis le JSON: {len(final_needs)}")
                        
                        # Debug: Afficher les thÃ¨mes des besoins
                        print(f"ğŸ“‹ [DEBUG] ThÃ¨mes des besoins validÃ©s:")
                        for i, need in enumerate(final_needs, 1):
                            print(f"   {i}. {need.get('theme', 'N/A')}")
                        
                        # Sauvegarde des rÃ©sultats
                        self._save_results(state)
                        
                        print(f"âœ… [DEBUG] _finalize_results_node - FIN")
                        return state
                except Exception as e:
                    print(f"âš ï¸ [DEBUG] Erreur lors du chargement du JSON: {str(e)}")
                    # Continuer en mode normal si le chargement Ã©choue
            
            # MODE NORMAL: Utiliser directement les besoins validÃ©s depuis l'Ã©tat
            validated_needs = state.get("validated_needs", [])
            
            # Si pas de besoins validÃ©s dans l'Ã©tat, essayer depuis validation_result
            if not validated_needs and "validation_result" in state and state["validation_result"]:
                validation_result = state["validation_result"]
                validated_needs = validation_result.get("validated_needs", [])
                print(f"ğŸ“Š [DEBUG] Besoins rÃ©cupÃ©rÃ©s depuis validation_result: {len(validated_needs)}")
            
            # Si toujours pas de besoins, utiliser tous les besoins identifiÃ©s
            if not validated_needs:
                validated_needs = state.get("identified_needs", [])
                print(f"ğŸ“Š [DEBUG] Utilisation de tous les besoins identifiÃ©s: {len(validated_needs)}")
            
            state["final_needs"] = validated_needs
            print(f"ğŸ“Š [DEBUG] Final needs dÃ©finis: {len(validated_needs)}")
            
            # Debug: Afficher les thÃ¨mes des besoins
            if validated_needs:
                print(f"ğŸ“‹ [DEBUG] ThÃ¨mes des besoins validÃ©s:")
                for i, need in enumerate(validated_needs, 1):
                    print(f"   {i}. {need.get('theme', 'N/A')}")
            
            # Sauvegarde des rÃ©sultats
            self._save_results(state)
            
            # Initialiser le compteur d'itÃ©ration pour les use cases
            state["use_case_iteration_count"] = 0
            print(f"ğŸ”„ [DEBUG] use_case_iteration_count initialisÃ© Ã  0")
            
            print(f"âœ… [DEBUG] _finalize_results_node - FIN")
            return state
            
        except Exception as e:
            print(f"âŒ [DEBUG] Erreur dans _finalize_results_node: {str(e)}")
            state["messages"] = state.get("messages", []) + [HumanMessage(content=f"Erreur finalisation: {str(e)}")]
            return state
    
    def _should_continue_needs(self, state: WorkflowState) -> str:
        """
        DÃ©termine la direction du workflow basÃ©e sur l'action de l'utilisateur.
        
        Args:
            state: Ã‰tat actuel du workflow
            
        Returns:
            Direction Ã  prendre : "continue_needs" ou "continue_to_use_cases"
        """
        user_action = state.get("user_action", "")
        
        if user_action == "continue_to_use_cases":
            return "continue_to_use_cases"
        else:
            # Par dÃ©faut, continuer avec les besoins
            return "continue_needs"
    
    def _should_continue_use_cases(self, state: WorkflowState) -> str:
        """
        DÃ©termine la direction du workflow des use cases basÃ©e sur l'action de l'utilisateur.
        
        Args:
            state: Ã‰tat actuel du workflow
            
        Returns:
            Direction Ã  prendre : "continue_use_cases" ou "finalize_use_cases"
        """
        use_case_user_action = state.get("use_case_user_action", "")
        
        if use_case_user_action == "finalize_use_cases":
            return "finalize_use_cases"
        else:
            # Par dÃ©faut, continuer avec les use cases (rÃ©gÃ©nÃ©ration)
            return "continue_use_cases"
    
    def _save_results(self, state: WorkflowState) -> None:
        """
        Sauvegarde les rÃ©sultats dans le dossier outputs.
        
        Args:
            state: Ã‰tat final du workflow
        """
        try:
            from datetime import datetime
            # Sauvegarde des besoins finaux
            results = {
                "final_needs": state.get("final_needs", []),
                "timestamp": datetime.now().isoformat()
            }
            
            # Sauvegarde en JSON
            output_path = str(project_config.ensure_outputs_dir() / "need_analysis_results.json")
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(results, f, ensure_ascii=False, indent=2)
            
            # GÃ©nÃ©ration du graph PNG
            self._generate_graph_png()
            
        except Exception as e:
            print(f"Erreur sauvegarde: {str(e)}")
    
    def _generate_graph_png(self) -> None:
        """
        GÃ©nÃ¨re et sauvegarde le graph du workflow en PNG en utilisant LangGraph.
        """
        try:
            # Utilisation de la mÃ©thode LangGraph pour gÃ©nÃ©rer le graph
            png = self.graph.get_graph().draw_mermaid_png()
            
            # Sauvegarde du PNG
            output_path = str(project_config.ensure_outputs_dir() / "workflow_graph.png")
            with open(output_path, 'wb') as f:
                f.write(png)
            
        except Exception as e:
            print(f"Erreur gÃ©nÃ©ration graph: {str(e)}")
    
    def run(self, workshop_document_ids: List[int] = None, transcript_document_ids: List[int] = None,
            company_info: Dict[str, Any] = None, 
            workshop_results: Dict[str, Any] = None, transcript_results: List[Dict[str, Any]] = None, web_search_results: Dict[str, Any] = None,
            interviewer_names: List[str] = None, thread_id: str = None, additional_context: str = "", num_needs: int = 10, num_quotes_per_need: int = 4) -> Dict[str, Any]:
        """
        ExÃ©cute le workflow complet.
        NOUVELLE ARCHITECTURE: ExÃ©cution MANUELLE des nÅ“uds jusqu'Ã  human_validation.
        MODE DEV: Charge les besoins depuis need_analysis_results.json et passe directement aux use cases.
        
        Args:
            workshop_document_ids: Liste des IDs de documents workshop dans la BDD
            transcript_document_ids: Liste des IDs de documents transcript dans la BDD
            company_info: Informations sur l'entreprise pour la recherche web
            workshop_results: RÃ©sultats prÃ©-calculÃ©s du workshop agent
            transcript_results: RÃ©sultats prÃ©-calculÃ©s du transcript agent
            web_search_results: RÃ©sultats prÃ©-calculÃ©s du web search agent
            thread_id: ID du thread pour le checkpointer (optionnel, gÃ©nÃ©rÃ© automatiquement si non fourni)
            additional_context: Contexte additionnel fourni par l'utilisateur
            num_needs: Nombre de besoins Ã  gÃ©nÃ©rer (par dÃ©faut: 10)
            num_quotes_per_need: Nombre de citations par besoin (par dÃ©faut: 4)
            
        Returns:
            RÃ©sultats du workflow
        """
        print(f"\nğŸš€ [DEBUG] run() appelÃ© - NOUVELLE ARCHITECTURE")
        print(f"ğŸ”§ [DEBUG] Mode dev: {self.dev_mode}")
        print(f"ğŸ“Š [DEBUG] RÃ©sultats prÃ©-calculÃ©s: workshop={bool(workshop_results)}, transcript={bool(transcript_results)}, web_search={bool(web_search_results)}")
        print(f"ğŸ”‘ [DEBUG] Thread ID fourni: {thread_id}")
        
        # Configurer les interviewer_names si fournis
        if interviewer_names:
            print(f"ğŸ‘¥ [DEBUG] Configuration des interviewers: {interviewer_names}")
            self.transcript_agent.speaker_classifier.set_interviewer_names(interviewer_names)
        
        try:
            # Ã‰tat initial avec les fichiers d'entrÃ©e ET les rÃ©sultats prÃ©-calculÃ©s
            state = WorkflowState(
                messages=[],
                # IDs de documents dans la BDD
                workshop_document_ids=workshop_document_ids or [],
                transcript_document_ids=transcript_document_ids or [],
                company_info=company_info or {},
                # Informations supplÃ©mentaires fournies par l'utilisateur
                additional_context=additional_context or "",
                # ParamÃ¨tres de gÃ©nÃ©ration
                num_needs=num_needs,
                num_quotes_per_need=num_quotes_per_need,
                # RÃ©sultats des agents (prÃ©-calculÃ©s OU vides)
                workshop_results=workshop_results or {},
                transcript_results=transcript_results or [],
                web_search_results=web_search_results or {},
                # Flag pour parallÃ©lisation
                skip_agents=False,
                # DonnÃ©es agrÃ©gÃ©es (seulement transcript_data car transformation utile)
                transcript_data=[],
                # RÃ©sultats de l'analyse des besoins
                identified_needs=[],
                # Validation humaine des besoins
                validated_needs=[],
                rejected_needs=[],
                user_feedback="",
                validation_result={},
                # Ã‰tat du workflow des besoins
                final_needs=[],
                workflow_paused=False,
                # Action demandÃ©e par l'utilisateur (pour les boutons)
                user_action="",
                # RÃ©sultats de l'analyse des use cases
                proposed_use_cases=[],
                # Contexte additionnel pour la gÃ©nÃ©ration des use cases
                use_case_additional_context="",
                use_case_famille="",
                # Validation humaine des use cases
                validated_use_cases=[],
                rejected_use_cases=[],
                use_case_user_feedback="",
                use_case_validation_result={},
                # Ã‰tat du workflow des use cases
                final_use_cases=[],
                use_case_workflow_paused=False
            )
            
            # MODE DEV: VÃ©rifier si need_analysis_results.json existe
            if self.dev_mode:
                try:
                    print(f"ğŸ”§ [DEBUG] Mode dev activÃ© - tentative de chargement depuis need_analysis_results.json")
                    dev_json_path = str(project_config.OUTPUTS_DIR / "need_analysis_results.json")
                    if not os.path.exists(dev_json_path):
                        # Essayer aussi Ã  la racine du projet (legacy)
                        dev_json_path = str(project_config.PROJECT_ROOT / "need_analysis_results.json")
                    with open(dev_json_path, 'r', encoding='utf-8') as f:
                        need_data = json.load(f)
                    
                    final_needs = need_data.get("final_needs", [])
                    if final_needs:
                        print(f"âœ… [DEBUG] Besoins chargÃ©s depuis le JSON: {len(final_needs)}")
                        
                        # Charger les donnÃ©es mockÃ©es pour le contexte
                        state = self._collect_data_node(state)
                        
                        # DÃ©finir les besoins finaux et marquer comme succÃ¨s
                        state["final_needs"] = final_needs
                        state["validated_needs"] = final_needs
                        state["success"] = True
                        
                        # PASSER DIRECTEMENT Ã€ L'ANALYSE DES USE CASES
                        print(f"ğŸš€ [DEBUG] Passage direct Ã  l'analyse des use cases")
                        
                        # Analyser les use cases
                        state = self._analyze_use_cases_node(state)
                        
                        # Afficher l'interface de validation des use cases
                        state = self._validate_use_cases_node(state)
                        
                        print(f"â¸ï¸ [DEBUG] Workflow en pause - en attente de validation des use cases")
                        
                        # Retourner un Ã©tat "en pause" pour les use cases
                        return {
                            "success": False,
                            "final_needs": final_needs,
                            "summary": {
                                "total_needs": len(final_needs),
                                "themes": [need.get("theme", "") for need in final_needs],
                            },
                            "iteration_count": state.get("iteration_count", 0),
                            "workshop_results": state.get("workshop_results", {}),
                            "transcript_results": state.get("transcript_results", []),
                            "web_search_results": state.get("web_search_results", {}),
                            "messages": ["Workflow en pause - en attente de validation des use cases"]
                        }
                        
                except FileNotFoundError:
                    print(f"âš ï¸ [DEBUG] Fichier need_analysis_results.json non trouvÃ© - exÃ©cution normale")
                    # Continuer en mode normal
                except Exception as e:
                    print(f"âš ï¸ [DEBUG] Erreur lors du chargement du JSON: {str(e)}")
                    # Continuer en mode normal
            
            # MODE NORMAL: ExÃ©cution standard AVEC PARALLÃ‰LISATION
            print(f"ğŸ”„ [DEBUG] ExÃ©cution avec PARALLÃ‰LISATION des agents...")
            
            # NOUVEAU: Utiliser le graphe compilÃ© pour bÃ©nÃ©ficier de la parallÃ©lisation
            # Le graphe va exÃ©cuter : dispatcher â†’ 3 agents en parallÃ¨le â†’ collect_data â†’ analyze_needs â†’ human_validation (STOP)
            
            # Utiliser le thread_id fourni ou en gÃ©nÃ©rer un nouveau
            if thread_id is None:
                import uuid
                thread_id = str(uuid.uuid4())
                print(f"ğŸ”‘ [DEBUG] Thread ID gÃ©nÃ©rÃ© automatiquement: {thread_id}")
            
            config = {"configurable": {"thread_id": thread_id}}
            
            # ExÃ©cuter le workflow jusqu'Ã  l'interrupt (human_validation)
            print(f"ğŸš€ [DEBUG] ExÃ©cution du graphe avec thread_id: {thread_id}")
            
            # Le workflow va s'arrÃªter Ã  human_validation car c'est dÃ©fini dans interrupt_before
            final_state = None
            for chunk in self.graph.stream(state, config):
                print(f"ğŸ“Š [DEBUG] Chunk reÃ§u: {list(chunk.keys())}")
                # Chaque chunk contient l'Ã©tat mis Ã  jour par un nÅ“ud
                for node_name, node_state in chunk.items():
                    print(f"  â€¢ NÅ“ud '{node_name}' exÃ©cutÃ©")
                    final_state = node_state
            
            # Le workflow s'est arrÃªtÃ© Ã  human_validation
            print(f"â¸ï¸ [DEBUG] Workflow arrÃªtÃ© avant human_validation - en attente de validation")
            
            # IMPORTANT : RÃ©cupÃ©rer l'Ã©tat complet depuis le checkpointer aprÃ¨s l'interrupt
            # car le dernier chunk (__interrupt__) ne contient pas l'Ã©tat complet
            snapshot = self.graph.get_state(config)
            state = snapshot.values
            
            print(f"ğŸ“Š [DEBUG] Ã‰tat rÃ©cupÃ©rÃ© depuis le checkpointer:")
            print(f"ğŸ“Š [DEBUG] Besoins identifiÃ©s: {len(state.get('identified_needs', []))}")
            print(f"ğŸ“Š [DEBUG] Besoins validÃ©s: {len(state.get('validated_needs', []))}")
            
            # Retourner un Ã©tat "en pause" AVEC les besoins identifiÃ©s
            return {
                "success": False,
                "workflow_paused": True,  # â† AJOUTÃ‰
                "identified_needs": state.get("identified_needs", []),  # â† AJOUTÃ‰
                "validated_needs": state.get("validated_needs", []),  # â† AJOUTÃ‰
                "final_needs": [],
                "summary": {
                    "total_needs": 0,
                    "themes": [],
                },
                "iteration_count": state.get("iteration_count", 0),
                "workshop_results": state.get("workshop_results", {}),
                "transcript_results": state.get("transcript_results", []),
                "web_search_results": state.get("web_search_results", {}),
                "messages": ["Workflow en pause - en attente de validation"]
            }
            
        except Exception as e:
            print(f"âŒ [DEBUG] Erreur dans run(): {str(e)}")
            import traceback
            traceback.print_exc()
            return {
                "success": False,
                "error": str(e),
                "final_needs": [],
                "iteration_count": 0,
                "messages": [f"Erreur workflow: {str(e)}"]
            }
    
    def resume_workflow(self) -> Dict[str, Any]:
        """
        Reprend le workflow aprÃ¨s validation humaine.
        VERSION CORRIGÃ‰E: Reprend depuis le nÅ“ud check_success au lieu de repartir du dÃ©but.
        
        Returns:
            RÃ©sultats du workflow
        """
        print(f"\nğŸ”„ [DEBUG] resume_workflow() appelÃ©")
        
        try:
            # RÃ©cupÃ©rer l'Ã©tat du workflow depuis session_state
            if "workflow_state" not in st.session_state:
                print(f"âŒ [DEBUG] Aucun Ã©tat de workflow trouvÃ© dans session_state")
                return {
                    "success": False,
                    "error": "Aucun Ã©tat de workflow trouvÃ©",
                    "final_needs": [],
                    "iteration_count": 0,
                    "messages": ["Erreur: Aucun Ã©tat de workflow trouvÃ©"]
                }
            
            # RÃ©cupÃ©rer l'Ã©tat sauvegardÃ©
            workflow_state = st.session_state.workflow_state
            print(f"ğŸ“Š [DEBUG] Ã‰tat du workflow rÃ©cupÃ©rÃ©: {len(workflow_state)} clÃ©s")
            
            # RÃ©cupÃ©rer le rÃ©sultat de validation depuis session_state
            if "validation_result" not in st.session_state:
                print(f"âŒ [DEBUG] Aucun rÃ©sultat de validation trouvÃ©")
                return {
                    "success": False,
                    "error": "Aucun rÃ©sultat de validation trouvÃ©",
                    "final_needs": [],
                    "iteration_count": 0,
                    "messages": ["Erreur: Aucun rÃ©sultat de validation trouvÃ©"]
                }
            
            validation_result = st.session_state.validation_result
            print(f"ğŸ“Š [DEBUG] RÃ©sultat de validation rÃ©cupÃ©rÃ©: {validation_result.get('total_validated', 0)} besoins validÃ©s")
            
            # CORRECTION: Ne pas Ã©craser validated_needs, mais accumuler correctement
            # validation_result contient les besoins nouvellement validÃ©s
            existing_validated = workflow_state.get("validated_needs", [])
            newly_validated = validation_result.get("validated_needs", [])
            
            # Ã‰viter les doublons
            existing_ids = [need.get("theme", "") for need in existing_validated]
            unique_newly_validated = [need for need in newly_validated if need.get("theme", "") not in existing_ids]
            
            workflow_state["validated_needs"] = existing_validated + unique_newly_validated
            
            # MÃªme chose pour rejected_needs
            existing_rejected = workflow_state.get("rejected_needs", [])
            newly_rejected = validation_result.get("rejected_needs", [])
            
            existing_rejected_ids = [need.get("theme", "") for need in existing_rejected]
            unique_newly_rejected = [need for need in newly_rejected if need.get("theme", "") not in existing_rejected_ids]
            
            workflow_state["rejected_needs"] = existing_rejected + unique_newly_rejected
            
            workflow_state["user_feedback"] = validation_result.get("user_feedback", "")
            workflow_state["validation_result"] = validation_result
            
            print(f"ğŸ“Š [DEBUG] Besoins nouvellement validÃ©s: {len(unique_newly_validated)}")
            print(f"ğŸ“Š [DEBUG] Total besoins validÃ©s: {len(workflow_state['validated_needs'])}")
            
            # ExÃ©cuter les nÅ“uds suivants manuellement
            print(f"ğŸ”„ [DEBUG] ExÃ©cution des nÅ“uds suivants aprÃ¨s validation...")
            
            # 1. VÃ©rifier le succÃ¨s
            workflow_state = self._check_success_node(workflow_state)
            
            # 2. DÃ©terminer la suite selon le rÃ©sultat
            should_continue = self._should_continue(workflow_state)
            print(f"ğŸ“Š [DEBUG] DÃ©cision de continuation: {should_continue}")
            
            if should_continue == "success":
                # 3. Finaliser les rÃ©sultats
                print(f"ğŸ” [DEBUG] _finalize_results_node - DÃ‰BUT")
                workflow_state = self._finalize_results_node(workflow_state)
                print(f"âœ… [DEBUG] _finalize_results_node - FIN")
                
                print(f"âœ… [DEBUG] Phase 1 (besoins) terminÃ©e avec succÃ¨s")
                print(f"ğŸ“Š [DEBUG] Success: {workflow_state.get('success', False)}")
                print(f"ğŸ“Š [DEBUG] Final needs: {len(workflow_state.get('final_needs', []))}")
                
                # NETTOYAGE DES FLAGS DE LA PHASE 1 â† NOUVEAU
                print(f"ğŸ§¹ [DEBUG] Nettoyage des flags de la Phase 1")
                workflow_state["workflow_paused"] = False
                st.session_state.workflow_paused = False
                st.session_state.waiting_for_validation = False
                if "validation_result" in st.session_state:
                    del st.session_state.validation_result
                if "workflow_state" in st.session_state:
                    del st.session_state.workflow_state
                print(f"âœ… [DEBUG] Flags de Phase 1 nettoyÃ©s")
                
                # CORRECTION: Continuer vers l'analyse des use cases au lieu de retourner
                print(f"ğŸš€ [DEBUG] Passage Ã  la Phase 2 : Analyse des use cases")
                
                # 4. Analyser les use cases
                workflow_state = self._analyze_use_cases_node(workflow_state)
                
                # 5. Afficher l'interface de validation des use cases
                workflow_state = self._validate_use_cases_node(workflow_state)
                
                print(f"â¸ï¸ [DEBUG] Workflow en pause - en attente de validation des use cases")
                
                # Retourner un Ã©tat "en pause" pour les use cases
                return {
                    "success": False,  # Pas encore terminÃ©, on attend la validation use cases
                    "final_needs": workflow_state.get("final_needs", []),
                    "summary": {
                        "total_needs": len(workflow_state.get("final_needs", [])),
                        "themes": list(set([need.get("theme", "") for need in workflow_state.get("final_needs", []) if need.get("theme")])),
                    },
                    "iteration_count": workflow_state.get("iteration_count", 0),
                    "workshop_results": workflow_state.get("workshop_results", {}),
                    "transcript_results": workflow_state.get("transcript_results", []),
                    "web_search_results": workflow_state.get("web_search_results", {}),
                    "messages": ["Phase 1 terminÃ©e - en attente de validation des use cases"]
                }
            elif should_continue == "continue":
                # 4. Continuer avec une nouvelle analyse (pas encore 5 besoins validÃ©s)
                print(f"ğŸ”„ [DEBUG] Besoin de plus de besoins validÃ©s - gÃ©nÃ©ration d'une nouvelle itÃ©ration")
                print(f"ğŸ“Š [DEBUG] Besoins actuellement validÃ©s: {len(workflow_state.get('validated_needs', []))}/5")
                print(f"ğŸ”„ [DEBUG] ItÃ©ration actuelle: {workflow_state.get('iteration_count', 0)}/{workflow_state.get('max_iterations', 3)}")
                
                # NOTE: L'incrÃ©mentation est dÃ©jÃ  faite dans _check_success_node
                # Ne pas incrÃ©menter ici pour Ã©viter la double incrÃ©mentation !
                
                # CORRECTION: Nettoyer validation_result avant la nouvelle itÃ©ration
                print(f"ğŸ§¹ [DEBUG] Nettoyage de validation_result pour la nouvelle itÃ©ration")
                if "validation_result" in st.session_state:
                    del st.session_state.validation_result
                print(f"âœ… [DEBUG] validation_result nettoyÃ©")
                
                # Analyser de nouveaux besoins
                workflow_state = self._analyze_needs_node(workflow_state)
                
                # Afficher l'interface de validation pour les nouveaux besoins
                workflow_state = self._human_validation_node(workflow_state)
                
                print(f"â¸ï¸ [DEBUG] Workflow en pause - nouvelle validation requise")
                
                # Le workflow s'arrÃªte Ã  nouveau pour une nouvelle validation
                return {
                    "success": False,
                    "error": "Nouvelle validation requise",
                    "final_needs": [],
                    "iteration_count": workflow_state.get("iteration_count", 0),
                    "messages": ["Nouvelle validation requise"]
                }
            else:  # max_iterations
                print(f"âŒ [DEBUG] Nombre maximum d'itÃ©rations atteint")
                return {
                    "success": False,
                    "error": "Nombre maximum d'itÃ©rations atteint",
                    "final_needs": [],
                    "iteration_count": workflow_state.get("iteration_count", 0),
                    "messages": ["Nombre maximum d'itÃ©rations atteint"]
                }
            
        except Exception as e:
            print(f"âŒ [DEBUG] Erreur dans resume_workflow(): {str(e)}")
            return {
                "success": False,
                "error": str(e),
                "final_needs": [],
                "iteration_count": 0,
                "messages": [f"Erreur reprise workflow: {str(e)}"]
            }
    
    # ==================== NOUVEAUX NÅ’UDS POUR L'ANALYSE DES USE CASES ====================
    
    def _analyze_use_cases_node(self, state: WorkflowState) -> WorkflowState:
        """
        NÅ“ud d'analyse des cas d'usage IA Ã  partir des besoins validÃ©s.
        
        Args:
            state: Ã‰tat actuel du workflow
            
        Returns:
            Ã‰tat mis Ã  jour
        """
        print(f"\nğŸ”¬ [DEBUG] _analyze_use_cases_node - DÃ‰BUT")
        print(f"ğŸ“Š Besoins validÃ©s en entrÃ©e: {len(state.get('final_needs', []))}")
        
        try:
            # Initialiser les listes si premiÃ¨re fois
            if "validated_use_cases" not in state:
                state["validated_use_cases"] = []
                state["rejected_use_cases"] = []
            
            # RÃ©cupÃ©rer les besoins validÃ©s
            validated_needs = state.get("final_needs", [])
            
            if not validated_needs:
                print(f"âš ï¸ [DEBUG] Aucun besoin validÃ© trouvÃ©")
                state["proposed_use_cases"] = []
                return state
            
            # PrÃ©parer les donnÃ©es pour la gÃ©nÃ©ration
            previous_use_cases = state.get("proposed_use_cases", [])
            rejected_use_cases = state.get("rejected_use_cases", [])
            user_feedback = state.get("use_case_user_feedback", "")
            additional_context = state.get("use_case_additional_context", "")
            famille = state.get("use_case_famille", "")
            
            if previous_use_cases:
                print(f"ğŸ’¬ [DEBUG] RÃ©gÃ©nÃ©ration avec feedback")
                if user_feedback:
                    print(f"ğŸ’¬ [DEBUG] Commentaires utilisateur : {user_feedback[:100]}...")
                if rejected_use_cases:
                    print(f"ğŸš« [DEBUG] Cas d'usage rejetÃ©s Ã  Ã©viter : {len(rejected_use_cases)}")
            
            # MODE DEV: Charger les donnÃ©es mockÃ©es depuis le fichier JSON
            if project_config.is_agent_dev_mode("use_case_analysis"):
                print(f"ğŸ”§ [DEBUG] Mode dev USE_CASE_ANALYSIS_DEV_MODE activÃ© - chargement des donnÃ©es mockÃ©es")
                try:
                    mock_data = project_config.load_mock_data()
                    use_case_analysis_data = mock_data.get("use_case_analysis", {})
                    proposed_use_cases = use_case_analysis_data.get("use_cases", [])
                    state["proposed_use_cases"] = proposed_use_cases
                    print(f"âœ… [DEBUG] Cas d'usage mockÃ©s chargÃ©s: {len(proposed_use_cases)}")
                    print(f"âœ… [DEBUG] _analyze_use_cases_node - FIN")
                    return state
                except Exception as e:
                    print(f"âš ï¸ [DEBUG] Erreur lors du chargement des donnÃ©es mockÃ©es: {str(e)}")
                    # Continuer en mode normal si le chargement Ã©choue
            
            # RÃ©cupÃ©rer les donnÃ©es sources pour enrichir le contexte
            workshop_results = state.get("workshop_results", {})
            transcript_data = state.get("transcript_data", [])
            web_search_results = state.get("web_search_results", {})
            
            print(f"ğŸ” [DEBUG] DonnÃ©es de contexte: {len(workshop_results.get('workshops', []))} workshops, "
                  f"{len(transcript_data)} transcripts, web_search prÃ©sent={bool(web_search_results)}")
            
            # ğŸ’° OPTIMISATION: Filtrer les quotes des validated_needs pour Ã©conomiser les tokens
            validated_needs_light = [
                {"id": need.get("id"), "theme": need.get("theme"), "description": need.get("description", "")}
                for need in validated_needs
            ]
            print(f"ğŸ’° [OPTIMISATION] Validated needs allÃ©gÃ©s: {len(validated_needs)} besoins sans quotes")
            
            # Appeler l'agent d'analyse des use cases avec les donnÃ©es de contexte
            print(f"ğŸ¤– [DEBUG] Appel Ã  l'agent d'analyse des use cases")
            result = self.use_case_analysis_agent.analyze_use_cases(
                validated_needs=validated_needs_light,
                workshop_data=workshop_results,
                transcript_data=transcript_data,
                web_search_data=web_search_results,
                previous_use_cases=previous_use_cases if previous_use_cases else None,
                rejected_use_cases=rejected_use_cases if rejected_use_cases else None,
                user_feedback=user_feedback,
                additional_context=additional_context,
                famille=famille
            )
            
            if "error" in result:
                print(f"âŒ [DEBUG] Erreur lors de l'analyse: {result['error']}")
                state["messages"] = state.get("messages", []) + [HumanMessage(content=f"Erreur analyse use cases: {result['error']}")]
                return state
            
            # Mettre Ã  jour l'Ã©tat avec les rÃ©sultats
            proposed_use_cases = result.get("use_cases", [])
            
            # Filtrer les use cases dÃ©jÃ  validÃ©s pour ne pas les reproposer
            existing_validated = state.get("validated_use_cases", [])
            if existing_validated:
                validated_ids = {uc.get("id", "") for uc in existing_validated}
                original_count = len(proposed_use_cases)
                proposed_use_cases = [uc for uc in proposed_use_cases if uc.get("id", "") not in validated_ids]
                filtered_count = original_count - len(proposed_use_cases)
                if filtered_count > 0:
                    print(f"ğŸ” [FILTER] {filtered_count} cas d'usage dÃ©jÃ  validÃ©s filtrÃ©s ({len(proposed_use_cases)} restants)")
            
            state["proposed_use_cases"] = proposed_use_cases
            
            print(f"âœ… [DEBUG] _analyze_use_cases_node - FIN")
            print(f"ğŸ“Š Cas d'usage proposÃ©s: {len(state['proposed_use_cases'])}")
            
            # Affichage des coÃ»ts aprÃ¨s l'analyse des cas d'usage
            self._print_tracker_stats(agent_name="use_case_analysis")
            
            return state
            
        except Exception as e:
            print(f"âŒ [DEBUG] Erreur dans _analyze_use_cases_node: {str(e)}")
            import traceback
            traceback.print_exc()
            state["messages"] = state.get("messages", []) + [HumanMessage(content=f"Erreur analyse use cases: {str(e)}")]
            return state
    
    def _validate_use_cases_node(self, state: WorkflowState) -> WorkflowState:
        """
        NÅ“ud de validation humaine des cas d'usage SIMPLIFIÃ‰.
        
        NOUVELLE ARCHITECTURE avec interrupts natifs :
        - Le workflow s'arrÃªte AVANT ce nÅ“ud (interrupt_before)
        - L'API/Streamlit dÃ©tecte que le workflow est en pause
        - Streamlit affiche l'interface de validation des use cases
        - L'utilisateur valide et renvoie le feedback
        - Le feedback est injectÃ© dans l'Ã©tat via l'API
        - Le workflow reprend et ce nÅ“ud traite le feedback
        
        Args:
            state: Ã‰tat actuel du workflow
            
        Returns:
            Ã‰tat mis Ã  jour avec les use cases validÃ©s/rejetÃ©s
        """
        print(f"\nğŸ›‘ [INTERRUPT] validate_use_cases_node - DÃ‰BUT")
        print(f"ğŸ“Š Cas d'usage proposÃ©s: {len(state.get('proposed_use_cases', []))}")
        print(f"ğŸ“Š Cas d'usage validÃ©s existants: {len(state.get('validated_use_cases', []))}")
        
        try:
            # VÃ©rifier si on a reÃ§u le feedback (injectÃ© par l'API)
            if "use_case_validation_result" in state and state["use_case_validation_result"]:
                print(f"âœ… [RESUME] Feedback use cases reÃ§u via API")
                validation_data = state["use_case_validation_result"]
                
                # Traiter les rÃ©sultats de validation
                existing_validated = state.get("validated_use_cases", [])
                newly_validated = validation_data.get("validated_use_cases", [])
                
                # Ã‰viter les doublons
                existing_ids = [uc.get("id", "") for uc in existing_validated]
                unique_newly_validated = [uc for uc in newly_validated if uc.get("id", "") not in existing_ids]
                
                state["validated_use_cases"] = existing_validated + unique_newly_validated
                
                # MÃªme chose pour les rejetÃ©s
                existing_rejected = state.get("rejected_use_cases", [])
                newly_rejected = validation_data.get("rejected_use_cases", [])
                
                existing_rejected_ids = [uc.get("id", "") for uc in existing_rejected]
                unique_newly_rejected = [uc for uc in newly_rejected if uc.get("id", "") not in existing_rejected_ids]
                
                state["rejected_use_cases"] = existing_rejected + unique_newly_rejected
                state["use_case_user_feedback"] = validation_data.get("user_feedback", "")
                
                # IncrÃ©menter le compteur d'itÃ©ration
                state["use_case_iteration_count"] = state.get("use_case_iteration_count", 0) + 1
                print(f"ğŸ”„ [DEBUG] use_case_iteration_count incrÃ©mentÃ© Ã  {state['use_case_iteration_count']}")
                
                # Nettoyer le flag
                state["use_case_validation_result"] = {}
                
                print(f"ğŸ“Š [RESUME] Cas d'usage nouvellement validÃ©s: {len(unique_newly_validated)}")
                print(f"ğŸ“Š [RESUME] Total cas d'usage validÃ©s: {len(state['validated_use_cases'])}")
                print(f"â–¶ï¸ [RESUME] Workflow continue...")
                
                return state
            else:
                # PremiÃ¨re fois : le workflow va s'arrÃªter ici (interrupt_before)
                print(f"â¸ï¸ [INTERRUPT] Aucun feedback - le workflow va s'arrÃªter")
                print(f"ğŸ’¡ [INTERRUPT] L'API dÃ©tectera cet arrÃªt et Streamlit affichera l'interface")
                
                # Juste retourner l'Ã©tat
                # Le workflow s'arrÃªte automatiquement car interrupt_before
                return state
            
        except Exception as e:
            print(f"âŒ [ERROR] Erreur dans validate_use_cases_node: {str(e)}")
            import traceback
            traceback.print_exc()
            state["messages"] = state.get("messages", []) + [HumanMessage(content=f"Erreur validation use cases: {str(e)}")]
            return state
    
    def _pre_use_case_interrupt_node(self, state: WorkflowState) -> WorkflowState:
        """
        NÅ“ud d'interrupt avant la gÃ©nÃ©ration des use cases.
        Affiche un rÃ©sumÃ© des besoins validÃ©s et attend un contexte additionnel.
        
        Args:
            state: Ã‰tat actuel du workflow
            
        Returns:
            Ã‰tat mis Ã  jour avec le contexte additionnel
        """
        print(f"\nğŸ›‘ [INTERRUPT] pre_use_case_interrupt_node - DÃ‰BUT")
        print(f"ğŸ“Š Besoins validÃ©s: {len(state.get('final_needs', []))}")
        
        try:
            # VÃ©rifier si on a reÃ§u le contexte additionnel (injectÃ© par l'API)
            if "use_case_additional_context" in state:
                context = state.get("use_case_additional_context", "")
                print(f"âœ… [RESUME] Contexte additionnel reÃ§u: {len(context)} caractÃ¨res")
                return state
            else:
                # PremiÃ¨re fois : le workflow va s'arrÃªter ici (interrupt_before)
                print(f"â¸ï¸ [INTERRUPT] Aucun contexte - le workflow va s'arrÃªter")
                print(f"ğŸ’¡ [INTERRUPT] L'API dÃ©tectera cet arrÃªt et Streamlit affichera l'interface")
                return state
            
        except Exception as e:
            print(f"âŒ [ERROR] Erreur dans pre_use_case_interrupt_node: {str(e)}")
            state["messages"] = state.get("messages", []) + [HumanMessage(content=f"Erreur interrupt: {str(e)}")]
            return state
    
    def _finalize_use_cases_node(self, state: WorkflowState) -> WorkflowState:
        """
        NÅ“ud de finalisation des cas d'usage.
        
        Args:
            state: Ã‰tat actuel du workflow
            
        Returns:
            Ã‰tat mis Ã  jour
        """
        try:
            print(f"\nğŸ” [DEBUG] _finalize_use_cases_node - DÃ‰BUT")
            print(f"ğŸ“Š [DEBUG] Cas d'usage validÃ©s: {len(state.get('validated_use_cases', []))}")
            
            # Utiliser directement les cas d'usage validÃ©s depuis l'Ã©tat
            validated_use_cases = state.get("validated_use_cases", [])
            
            state["final_use_cases"] = validated_use_cases
            
            print(f"ğŸ“Š [DEBUG] Final cas d'usage dÃ©finis: {len(validated_use_cases)}")
            
            # Debug: Afficher les titres des cas d'usage
            if validated_use_cases:
                print(f"ğŸ“‹ [DEBUG] Titres des cas d'usage validÃ©s:")
                for i, uc in enumerate(validated_use_cases, 1):
                    print(f"   {i}. {uc.get('titre', 'N/A')}")
            
            # Sauvegarde des rÃ©sultats
            self._save_use_case_results(state)
            
            print(f"âœ… [DEBUG] _finalize_use_cases_node - FIN")
            
            # Affichage du rapport final des coÃ»ts
            print("\n" + "="*70)
            print("ğŸ“Š RAPPORT FINAL DES COÃ›TS")
            print("="*70)
            self.tracker.print_summary()
            
            # Sauvegarde du rapport de tracking
            report_path = self.tracker.save_report()
            print(f"ğŸ“„ Rapport de coÃ»ts sauvegardÃ©: {report_path}\n")
            
            return state
            
        except Exception as e:
            print(f"âŒ [DEBUG] Erreur dans _finalize_use_cases_node: {str(e)}")
            import traceback
            traceback.print_exc()
            state["messages"] = state.get("messages", []) + [HumanMessage(content=f"Erreur finalisation use cases: {str(e)}")]
            return state
    
    def _save_use_case_results(self, state: WorkflowState) -> None:
        """
        Sauvegarde les rÃ©sultats des cas d'usage dans le dossier outputs.
        
        Args:
            state: Ã‰tat final du workflow
        """
        try:
            from datetime import datetime
            # Sauvegarde des cas d'usage finaux
            results = {
                "final_use_cases": state.get("final_use_cases", []),
                "timestamp": datetime.now().isoformat(),
                # Inclure aussi les besoins pour rÃ©fÃ©rence
                "source_needs": state.get("final_needs", [])
            }
            
            # Sauvegarde en JSON
            output_path = str(project_config.ensure_outputs_dir() / "use_case_analysis_results.json")
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(results, f, ensure_ascii=False, indent=2)
            
            print(f"ğŸ’¾ [DEBUG] RÃ©sultats sauvegardÃ©s dans {output_path}")
            
        except Exception as e:
            print(f"âŒ Erreur sauvegarde use cases: {str(e)}")
    
    def resume_workflow_with_feedback(self, validated_needs: List[Dict[str, Any]], 
                                       rejected_needs: List[Dict[str, Any]], 
                                       user_feedback: str,
                                       user_action: str,
                                       thread_id: str) -> Dict[str, Any]:
        """
        Reprend le workflow aprÃ¨s validation humaine avec le feedback.
        NOUVELLE VERSION pour architecture API avec LangGraph checkpointer.
        
        Args:
            validated_needs: Besoins validÃ©s par l'utilisateur
            rejected_needs: Besoins rejetÃ©s par l'utilisateur
            user_feedback: Commentaires de l'utilisateur
            user_action: Action demandÃ©e par l'utilisateur ("continue_needs" ou "continue_to_use_cases")
            thread_id: ID du thread pour rÃ©cupÃ©rer l'Ã©tat depuis le checkpointer
        
        Returns:
            RÃ©sultats du workflow
        """
        print(f"\nğŸ”„ [API] resume_workflow_with_feedback() appelÃ©")
        print(f"âœ… ValidÃ©s: {len(validated_needs)}")
        print(f"âŒ RejetÃ©s: {len(rejected_needs)}")
        print(f"ğŸ’¬ Feedback: {user_feedback[:100] if user_feedback else 'Aucun'}")
        print(f"ğŸ¯ Action: {user_action}")
        print(f"ğŸ”‘ Thread ID: {thread_id}")
        
        try:
            # Configuration pour rÃ©cupÃ©rer l'Ã©tat depuis le checkpointer
            config = {"configurable": {"thread_id": thread_id}}
            
            # RÃ©cupÃ©rer l'Ã©tat actuel depuis le checkpointer
            snapshot = self.graph.get_state(config)
            state = snapshot.values
            
            print(f"ğŸ“Š [API] Ã‰tat rÃ©cupÃ©rÃ© depuis le checkpointer")
            print(f"ğŸ“Š [API] Besoins identifiÃ©s: {len(state.get('identified_needs', []))}")
            print(f"ğŸ“Š [API] Besoins dÃ©jÃ  validÃ©s: {len(state.get('validated_needs', []))}")
            
            # CrÃ©er le rÃ©sultat de validation
            validation_result = {
                "validated_needs": validated_needs,
                "rejected_needs": rejected_needs,
                "user_feedback": user_feedback
            }
            
            # Mettre Ã  jour l'Ã©tat avec le feedback de validation et l'action utilisateur
            self.graph.update_state(
                config,
                {
                    "validation_result": validation_result,
                    "user_action": user_action
                }
            )
            
            print(f"âœ… [API] Ã‰tat mis Ã  jour avec le feedback de validation")
            
            # Reprendre l'exÃ©cution du workflow
            print(f"â–¶ï¸ [API] Reprise du workflow...")
            
            final_state = None
            for chunk in self.graph.stream(None, config):
                print(f"ğŸ“Š [API] Chunk reÃ§u: {list(chunk.keys())}")
                for node_name, node_state in chunk.items():
                    print(f"  â€¢ NÅ“ud '{node_name}' exÃ©cutÃ©")
                    final_state = node_state
            
            # RÃ©cupÃ©rer l'Ã©tat final depuis le checkpointer
            snapshot = self.graph.get_state(config)
            state = snapshot.values
            
            print(f"ğŸ“Š [API] Workflow terminÃ© ou en pause")
            print(f"ğŸ“Š [API] Next nodes: {snapshot.next}")
            
            # VÃ©rifier si le workflow est terminÃ© ou en pause
            # Note: snapshot.next peut Ãªtre une liste ou un tuple
            next_nodes = list(snapshot.next) if snapshot.next else []
            
            if len(next_nodes) == 0:
                # Workflow terminÃ©
                print(f"âœ… [API] Workflow terminÃ© avec succÃ¨s")
                return {
                    "success": True,
                    "final_needs": state.get("final_needs", []),
                    "summary": {
                        "total_needs": len(state.get("final_needs", [])),
                        "themes": list(set([need.get("theme", "") for need in state.get("final_needs", []) if need.get("theme")])),
                    },
                    "workshop_results": state.get("workshop_results", {}),
                    "transcript_results": state.get("transcript_results", []),
                    "web_search_results": state.get("web_search_results", {}),
                    "messages": ["Phase 1 terminÃ©e - transition vers Phase 2"]
                }
            elif "human_validation" in next_nodes:
                # En attente d'une nouvelle validation
                print(f"â¸ï¸ [API] Workflow en pause - nouvelle validation requise")
                return {
                    "success": False,
                    "workflow_paused": True,
                    "identified_needs": state.get("identified_needs", []),
                    "validated_needs": state.get("validated_needs", []),
                    "final_needs": [],
                    "summary": {
                        "total_needs": 0,
                        "themes": [],
                    },
                    "workshop_results": state.get("workshop_results", {}),
                    "transcript_results": state.get("transcript_results", []),
                    "web_search_results": state.get("web_search_results", {}),
                    "messages": ["Nouvelle validation requise"]
                }
            elif "pre_use_case_interrupt" in next_nodes:
                # Transition vers interrupt avant gÃ©nÃ©ration des use cases
                print(f"â¸ï¸ [API] Workflow en pause - contexte additionnel requis")
                return {
                    "success": False,
                    "workflow_paused": True,
                    "final_needs": state.get("final_needs", []),
                    "summary": {
                        "total_needs": len(state.get("final_needs", [])),
                        "themes": list(set([need.get("theme", "") for need in state.get("final_needs", []) if need.get("theme")])),
                    },
                    "workshop_results": state.get("workshop_results", {}),
                    "transcript_results": state.get("transcript_results", []),
                    "web_search_results": state.get("web_search_results", {}),
                    "messages": ["Phase 1 terminÃ©e - contexte additionnel requis pour gÃ©nÃ©ration des use cases"]
                }
            elif "validate_use_cases" in next_nodes:
                # Transition vers validation des use cases
                print(f"â¸ï¸ [API] Workflow en pause - validation des use cases requise")
                return {
                    "success": False,
                    "workflow_paused": True,
                    "use_case_workflow_paused": True,
                    "final_needs": state.get("final_needs", []),
                    "proposed_use_cases": state.get("proposed_use_cases", []),
                    "summary": {
                        "total_needs": len(state.get("final_needs", [])),
                        "themes": list(set([need.get("theme", "") for need in state.get("final_needs", []) if need.get("theme")])),
                    },
                    "workshop_results": state.get("workshop_results", {}),
                    "transcript_results": state.get("transcript_results", []),
                    "web_search_results": state.get("web_search_results", {}),
                    "messages": ["Validation des use cases requise"]
                }
            else:
                # Autre cas
                print(f"âš ï¸ [API] Ã‰tat inattendu: {next_nodes}")
                return {
                    "success": False,
                    "error": f"Ã‰tat inattendu: {next_nodes}",
                    "final_needs": [],
                    "messages": [f"Ã‰tat inattendu: {next_nodes}"]
                }
        
        except Exception as e:
            print(f"âŒ [API] Erreur dans resume_workflow_with_feedback(): {str(e)}")
            import traceback
            traceback.print_exc()
            return {
                "success": False,
                "error": str(e),
                "final_needs": [],
                "messages": [f"Erreur reprise workflow: {str(e)}"]
            }
    
    def resume_pre_use_case_interrupt_with_context(self, use_case_additional_context: str, use_case_famille: str, thread_id: str) -> Dict[str, Any]:
        """
        Reprend le workflow aprÃ¨s l'interrupt pre_use_case_interrupt avec le contexte additionnel.
        
        Args:
            use_case_additional_context: Contexte additionnel pour la gÃ©nÃ©ration des use cases
            use_case_famille: Famille des cas d'usage (optionnel)
            thread_id: ID du thread pour rÃ©cupÃ©rer l'Ã©tat depuis le checkpointer
        
        Returns:
            RÃ©sultats du workflow
        """
        print(f"\nğŸ”„ [API] resume_pre_use_case_interrupt_with_context() appelÃ©")
        print(f"ğŸ’¡ Contexte: {len(use_case_additional_context)} caractÃ¨res")
        print(f"ğŸ·ï¸ Famille: {use_case_famille or 'Non spÃ©cifiÃ©e'}")
        print(f"ğŸ”‘ Thread ID: {thread_id}")
        
        try:
            # Configuration pour rÃ©cupÃ©rer l'Ã©tat depuis le checkpointer
            config = {"configurable": {"thread_id": thread_id}}
            
            # RÃ©cupÃ©rer l'Ã©tat actuel depuis le checkpointer
            snapshot = self.graph.get_state(config)
            state = snapshot.values
            
            print(f"ğŸ“Š [API] Ã‰tat rÃ©cupÃ©rÃ© depuis le checkpointer")
            
            # Mettre Ã  jour l'Ã©tat avec le contexte additionnel et la famille
            self.graph.update_state(
                config,
                {
                    "use_case_additional_context": use_case_additional_context,
                    "use_case_famille": use_case_famille or ""
                }
            )
            
            print(f"âœ… [API] Ã‰tat mis Ã  jour avec le contexte additionnel")
            
            # Reprendre l'exÃ©cution du workflow
            print(f"â–¶ï¸ [API] Reprise du workflow...")
            
            final_state = None
            for chunk in self.graph.stream(None, config):
                print(f"ğŸ“Š [API] Chunk reÃ§u: {list(chunk.keys())}")
                for node_name, node_state in chunk.items():
                    print(f"  â€¢ NÅ“ud '{node_name}' exÃ©cutÃ©")
                    final_state = node_state
            
            # RÃ©cupÃ©rer l'Ã©tat final depuis le checkpointer
            snapshot = self.graph.get_state(config)
            state = snapshot.values
            
            print(f"ğŸ“Š [API] Workflow terminÃ© ou en pause")
            print(f"ğŸ“Š [API] Next nodes: {snapshot.next}")
            
            # VÃ©rifier si le workflow est terminÃ© ou en pause
            next_nodes = list(snapshot.next) if snapshot.next else []
            
            if "validate_use_cases" in next_nodes:
                # En attente de validation des use cases
                print(f"â¸ï¸ [API] Workflow en pause - validation des use cases requise")
                return {
                    "success": False,
                    "workflow_paused": True,
                    "use_case_workflow_paused": True,
                    "final_needs": state.get("final_needs", []),
                    "proposed_use_cases": state.get("proposed_use_cases", []),
                    "messages": ["Validation des use cases requise"]
                }
            else:
                # Autre cas
                print(f"âš ï¸ [API] Ã‰tat inattendu: {next_nodes}")
                return {
                    "success": False,
                    "error": f"Ã‰tat inattendu: {next_nodes}",
                    "messages": [f"Ã‰tat inattendu: {next_nodes}"]
                }
        
        except Exception as e:
            print(f"âŒ [API] Erreur dans resume_pre_use_case_interrupt_with_context(): {str(e)}")
            import traceback
            traceback.print_exc()
            return {
                "success": False,
                "error": str(e),
                "messages": [f"Erreur reprise workflow: {str(e)}"]
            }
    
    def resume_use_case_workflow_with_feedback(self, validated_use_cases: List[Dict[str, Any]],
                                                rejected_use_cases: List[Dict[str, Any]],
                                                user_feedback: str,
                                                use_case_user_action: str,
                                                thread_id: str) -> Dict[str, Any]:
        """
        Reprend le workflow aprÃ¨s validation des use cases avec le feedback.
        NOUVELLE VERSION pour architecture API avec LangGraph checkpointer.
        
        Args:
            validated_use_cases: Cas d'usage validÃ©s
            rejected_use_cases: Cas d'usage rejetÃ©s
            user_feedback: Commentaires de l'utilisateur
            use_case_user_action: Action demandÃ©e par l'utilisateur ("continue_use_cases" ou "finalize_use_cases")
            thread_id: ID du thread pour rÃ©cupÃ©rer l'Ã©tat depuis le checkpointer
        
        Returns:
            RÃ©sultats finaux du workflow
        """
        print(f"\nğŸ”„ [API] resume_use_case_workflow_with_feedback() appelÃ©")
        print(f"âœ… Cas d'usage validÃ©s: {len(validated_use_cases)}")
        print(f"ğŸ¯ Action: {use_case_user_action}")
        print(f"ğŸ”‘ Thread ID: {thread_id}")
        
        try:
            # Configuration pour rÃ©cupÃ©rer l'Ã©tat depuis le checkpointer
            config = {"configurable": {"thread_id": thread_id}}
            
            # RÃ©cupÃ©rer l'Ã©tat actuel depuis le checkpointer
            snapshot = self.graph.get_state(config)
            state = snapshot.values
            
            print(f"ğŸ“Š [API] Ã‰tat rÃ©cupÃ©rÃ© depuis le checkpointer")
            print(f"ğŸ“Š [API] Cas d'usage proposÃ©s: {len(state.get('proposed_use_cases', []))}")
            print(f"ğŸ“Š [API] Cas d'usage dÃ©jÃ  validÃ©s: {len(state.get('validated_use_cases', []))}")
            
            # CrÃ©er le rÃ©sultat de validation
            validation_result = {
                "validated_use_cases": validated_use_cases,
                "rejected_use_cases": rejected_use_cases,
                "user_feedback": user_feedback
            }
            
            # Mettre Ã  jour l'Ã©tat avec le feedback de validation et l'action utilisateur
            self.graph.update_state(
                config,
                {
                    "use_case_validation_result": validation_result,
                    "use_case_user_action": use_case_user_action
                }
            )
            
            print(f"âœ… [API] Ã‰tat mis Ã  jour avec le feedback de validation use cases")
            
            # Reprendre l'exÃ©cution du workflow
            print(f"â–¶ï¸ [API] Reprise du workflow use cases...")
            
            final_state = None
            for chunk in self.graph.stream(None, config):
                print(f"ğŸ“Š [API] Chunk reÃ§u: {list(chunk.keys())}")
                for node_name, node_state in chunk.items():
                    print(f"  â€¢ NÅ“ud '{node_name}' exÃ©cutÃ©")
                    final_state = node_state
            
            # RÃ©cupÃ©rer l'Ã©tat final depuis le checkpointer
            snapshot = self.graph.get_state(config)
            state = snapshot.values
            
            print(f"ğŸ“Š [API] Workflow use cases terminÃ© ou en pause")
            print(f"ğŸ“Š [API] Next nodes: {snapshot.next}")
            
            # VÃ©rifier si le workflow est terminÃ© ou en pause
            # Note: snapshot.next peut Ãªtre une liste ou un tuple
            next_nodes = list(snapshot.next) if snapshot.next else []
            
            if len(next_nodes) == 0:
                # Workflow terminÃ©
                print(f"âœ… [API] Workflow use cases terminÃ© avec succÃ¨s")
                
                # Affichage du rapport final des coÃ»ts
                print("\n" + "="*70)
                print("ğŸ“Š RAPPORT FINAL DES COÃ›TS")
                print("="*70)
                self.tracker.print_summary()
                
                # Sauvegarde du rapport de tracking
                report_path = self.tracker.save_report()
                print(f"ğŸ“„ Rapport de coÃ»ts sauvegardÃ©: {report_path}\n")
                
                return {
                    "success": True,
                    "final_needs": state.get("final_needs", []),
                    "final_use_cases": state.get("final_use_cases", []),
                    "summary": {
                        "total_needs": len(state.get("final_needs", [])),
                        "total_use_cases": len(state.get("final_use_cases", [])),
                        "themes": list(set([need.get("theme", "") for need in state.get("final_needs", []) if need.get("theme")])),
                    },
                    "workshop_results": state.get("workshop_results", {}),
                    "transcript_results": state.get("transcript_results", []),
                    "web_search_results": state.get("web_search_results", {}),
                    "messages": ["Workflow terminÃ© avec succÃ¨s !"]
                }
            elif "validate_use_cases" in next_nodes:
                # En attente d'une nouvelle validation use cases
                print(f"â¸ï¸ [API] Workflow en pause - nouvelle validation use cases requise")
                return {
                    "success": False,
                    "use_case_workflow_paused": True,
                    "final_needs": state.get("final_needs", []),
                    "proposed_use_cases": state.get("proposed_use_cases", []),
                    "validated_use_cases": state.get("validated_use_cases", []),
                    "summary": {
                        "total_needs": len(state.get("final_needs", [])),
                        "themes": list(set([need.get("theme", "") for need in state.get("final_needs", []) if need.get("theme")])),
                    },
                    "workshop_results": state.get("workshop_results", {}),
                    "transcript_results": state.get("transcript_results", []),
                    "web_search_results": state.get("web_search_results", {}),
                    "messages": ["Nouvelle validation use cases requise"]
                }
            else:
                # Autre cas
                print(f"âš ï¸ [API] Ã‰tat inattendu: {next_nodes}")
                return {
                    "success": False,
                    "error": f"Ã‰tat inattendu: {next_nodes}",
                    "final_needs": [],
                    "final_use_cases": [],
                    "messages": [f"Ã‰tat inattendu: {next_nodes}"]
                }
        
        except Exception as e:
            print(f"âŒ [API] Erreur dans resume_use_case_workflow_with_feedback(): {str(e)}")
            import traceback
            traceback.print_exc()
            return {
                "success": False,
                "error": str(e),
                "final_needs": [],
                "final_use_cases": [],
                "messages": [f"Erreur reprise workflow use cases: {str(e)}"]
            }
    
    def resume_use_case_workflow(self) -> Dict[str, Any]:
        """
        Reprend le workflow aprÃ¨s validation humaine des use cases.
        
        Returns:
            RÃ©sultats du workflow
        """
        print(f"\nğŸ”„ [DEBUG] resume_use_case_workflow() appelÃ©")
        
        try:
            # RÃ©cupÃ©rer l'Ã©tat du workflow depuis session_state
            if "use_case_workflow_state" not in st.session_state:
                print(f"âŒ [DEBUG] Aucun Ã©tat de workflow use case trouvÃ© dans session_state")
                return {
                    "success": False,
                    "error": "Aucun Ã©tat de workflow use case trouvÃ©",
                    "final_quick_wins": [],
                    "final_structuration_ia": [],
                    "messages": ["Erreur: Aucun Ã©tat de workflow use case trouvÃ©"]
                }
            
            # RÃ©cupÃ©rer l'Ã©tat sauvegardÃ©
            workflow_state = st.session_state.use_case_workflow_state
            print(f"ğŸ“Š [DEBUG] Ã‰tat du workflow rÃ©cupÃ©rÃ©: {len(workflow_state)} clÃ©s")
            
            # RÃ©cupÃ©rer le rÃ©sultat de validation depuis session_state
            if "use_case_validation_result" not in st.session_state:
                print(f"âŒ [DEBUG] Aucun rÃ©sultat de validation trouvÃ©")
                return {
                    "success": False,
                    "error": "Aucun rÃ©sultat de validation trouvÃ©",
                    "final_quick_wins": [],
                    "final_structuration_ia": [],
                    "messages": ["Erreur: Aucun rÃ©sultat de validation trouvÃ©"]
                }
            
            validation_result = st.session_state.use_case_validation_result
            print(f"ğŸ“Š [DEBUG] RÃ©sultat de validation rÃ©cupÃ©rÃ©")
            
            # Accumuler les validations
            existing_qw = workflow_state.get("validated_quick_wins", [])
            newly_validated_qw = validation_result.get("validated_quick_wins", [])
            
            existing_sia = workflow_state.get("validated_structuration_ia", [])
            newly_validated_sia = validation_result.get("validated_structuration_ia", [])
            
            # Ã‰viter les doublons
            existing_qw_ids = [uc.get("titre", "") for uc in existing_qw]
            unique_qw = [uc for uc in newly_validated_qw if uc.get("titre", "") not in existing_qw_ids]
            
            existing_sia_ids = [uc.get("titre", "") for uc in existing_sia]
            unique_sia = [uc for uc in newly_validated_sia if uc.get("titre", "") not in existing_sia_ids]
            
            workflow_state["validated_quick_wins"] = existing_qw + unique_qw
            workflow_state["validated_structuration_ia"] = existing_sia + unique_sia
            
            # MÃªme chose pour les rejetÃ©s
            existing_rejected_qw = workflow_state.get("rejected_quick_wins", [])
            newly_rejected_qw = validation_result.get("rejected_quick_wins", [])
            workflow_state["rejected_quick_wins"] = existing_rejected_qw + newly_rejected_qw
            
            existing_rejected_sia = workflow_state.get("rejected_structuration_ia", [])
            newly_rejected_sia = validation_result.get("rejected_structuration_ia", [])
            workflow_state["rejected_structuration_ia"] = existing_rejected_sia + newly_rejected_sia
            
            workflow_state["use_case_user_feedback"] = validation_result.get("user_feedback", "")
            workflow_state["use_case_validation_result"] = validation_result
            
            print(f"ğŸ“Š [DEBUG] Quick Wins nouvellement validÃ©s: {len(unique_qw)}")
            print(f"ğŸ“Š [DEBUG] Structuration IA nouvellement validÃ©s: {len(unique_sia)}")
            print(f"ğŸ“Š [DEBUG] Total Quick Wins validÃ©s: {len(workflow_state['validated_quick_wins'])}")
            print(f"ğŸ“Š [DEBUG] Total Structuration IA validÃ©s: {len(workflow_state['validated_structuration_ia'])}")
            
            # ExÃ©cuter les nÅ“uds suivants manuellement
            print(f"ğŸ”„ [DEBUG] ExÃ©cution des nÅ“uds suivants aprÃ¨s validation...")
            
            # 1. VÃ©rifier le succÃ¨s
            workflow_state = self._check_use_case_success_node(workflow_state)
            
            # 2. DÃ©terminer la suite selon le rÃ©sultat
            should_continue = self._should_continue_use_cases(workflow_state)
            print(f"ğŸ“Š [DEBUG] DÃ©cision de continuation: {should_continue}")
            
            if should_continue == "success":
                # 3. Finaliser les rÃ©sultats
                print(f"ğŸ” [DEBUG] _finalize_use_cases_node - DÃ‰BUT")
                workflow_state = self._finalize_use_cases_node(workflow_state)
                print(f"âœ… [DEBUG] _finalize_use_cases_node - FIN")
                
                print(f"âœ… [DEBUG] Workflow use cases terminÃ© avec succÃ¨s")
                print(f"ğŸ“Š [DEBUG] Success: {workflow_state.get('use_case_success', False)}")
                print(f"ğŸ“Š [DEBUG] Final Quick Wins: {len(workflow_state.get('final_quick_wins', []))}")
                print(f"ğŸ“Š [DEBUG] Final Structuration IA: {len(workflow_state.get('final_structuration_ia', []))}")
                
                return {
                    "success": workflow_state.get("use_case_success", False),
                    "final_quick_wins": workflow_state.get("final_quick_wins", []),
                    "final_structuration_ia": workflow_state.get("final_structuration_ia", []),
                    "use_case_iteration": workflow_state.get("use_case_iteration", 0),
                    "final_needs": workflow_state.get("final_needs", []),
                    "messages": ["Analyse des use cases terminÃ©e avec succÃ¨s"]
                }
            elif should_continue == "continue":
                # 4. Continuer avec une nouvelle analyse
                print(f"ğŸ”„ [DEBUG] Besoin de plus de use cases validÃ©s - gÃ©nÃ©ration d'une nouvelle itÃ©ration")
                print(f"ğŸ“Š [DEBUG] Quick Wins actuellement validÃ©s: {len(workflow_state.get('validated_quick_wins', []))}/5")
                print(f"ğŸ“Š [DEBUG] Structuration IA actuellement validÃ©s: {len(workflow_state.get('validated_structuration_ia', []))}/5")
                print(f"ğŸ”„ [DEBUG] ItÃ©ration actuelle: {workflow_state.get('use_case_iteration', 0)}/{workflow_state.get('max_use_case_iterations', 3)}")
                
                # Nettoyer validation_result avant la nouvelle itÃ©ration
                print(f"ğŸ§¹ [DEBUG] Nettoyage de use_case_validation_result pour la nouvelle itÃ©ration")
                if "use_case_validation_result" in st.session_state:
                    del st.session_state.use_case_validation_result
                print(f"âœ… [DEBUG] use_case_validation_result nettoyÃ©")
                
                # Analyser de nouveaux use cases
                workflow_state = self._analyze_use_cases_node(workflow_state)
                
                # Afficher l'interface de validation pour les nouveaux use cases
                workflow_state = self._validate_use_cases_node(workflow_state)
                
                print(f"â¸ï¸ [DEBUG] Workflow en pause - nouvelle validation use cases requise")
                
                # Le workflow s'arrÃªte Ã  nouveau pour une nouvelle validation
                return {
                    "success": False,
                    "error": "Nouvelle validation use cases requise",
                    "final_quick_wins": [],
                    "final_structuration_ia": [],
                    "use_case_iteration": workflow_state.get("use_case_iteration", 0),
                    "messages": ["Nouvelle validation use cases requise"]
                }
            else:  # max_iterations
                print(f"âŒ [DEBUG] Nombre maximum d'itÃ©rations atteint")
                return {
                    "success": False,
                    "error": "Nombre maximum d'itÃ©rations atteint",
                    "final_quick_wins": [],
                    "final_structuration_ia": [],
                    "use_case_iteration": workflow_state.get("use_case_iteration", 0),
                    "messages": ["Nombre maximum d'itÃ©rations atteint"]
                }
            
        except Exception as e:
            print(f"âŒ [DEBUG] Erreur dans resume_use_case_workflow(): {str(e)}")
            import traceback
            traceback.print_exc()
            return {
                "success": False,
                "error": str(e),
                "final_quick_wins": [],
                "final_structuration_ia": [],
                "messages": [f"Erreur reprise workflow use cases: {str(e)}"]
            }
