"""
Workflow LangGraph pour l'analyse des besoins
"""

import os
import json
from typing import Dict, List, Any, TypedDict, Annotated
from langgraph.graph import StateGraph, END
from langgraph.graph.message import add_messages
from langchain_core.messages import BaseMessage, HumanMessage, AIMessage
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langgraph.checkpoint.memory import MemorySaver
import streamlit as st

# Import des agents
import sys
sys.path.append('/home/addeche/aiko/aikoGPT')
from need_analysis.need_analysis_agent import NeedAnalysisAgent
from process_atelier.workshop_agent import WorkshopAgent
from process_transcript.transcript_agent import TranscriptAgent
from web_search.web_search_agent import WebSearchAgent
from human_in_the_loop.streamlit_validation_interface import StreamlitValidationInterface


class WorkflowState(TypedDict):
    """Ã‰tat du workflow LangGraph"""
    messages: Annotated[List[BaseMessage], add_messages]
    # Fichiers d'entrÃ©e
    workshop_files: List[str]
    transcript_files: List[str]
    company_info: Dict[str, Any]
    # RÃ©sultats des agents
    workshop_results: Dict[str, Any]
    transcript_results: List[Dict[str, Any]]
    web_search_results: Dict[str, Any]
    # DonnÃ©es agrÃ©gÃ©es pour l'analyse
    workshop_data: Dict[str, Any]
    transcript_data: List[Dict[str, Any]]
    web_search_data: Dict[str, Any]
    # RÃ©sultats de l'analyse
    identified_needs: List[Dict[str, Any]]
    # Validation humaine
    validated_needs: List[Dict[str, Any]]
    rejected_needs: List[Dict[str, Any]]
    user_feedback: str
    validation_result: Dict[str, Any]
    # Ã‰tat du workflow
    final_needs: List[Dict[str, Any]]
    success: bool
    iteration_count: int
    max_iterations: int
    workflow_paused: bool


class NeedAnalysisWorkflow:
    """
    Workflow LangGraph pour l'analyse des besoins mÃ©tier
    """
    
    def __init__(self, api_key: str, dev_mode: bool = False, debug_mode: bool = False):
        """
        Initialise le workflow avec la clÃ© API OpenAI.
        
        Args:
            api_key: ClÃ© API OpenAI
            dev_mode: Mode dÃ©veloppement (utilise les donnÃ©es mockÃ©es)
            debug_mode: Mode debugging avec LangGraph Studio
        """
        self.api_key = api_key
        self.dev_mode = dev_mode
        self.debug_mode = debug_mode
        self.llm = ChatOpenAI(
            model="gpt-5-nano",
            api_key=api_key
        )
        
        # Initialisation des agents
        self.workshop_agent = WorkshopAgent(api_key)
        self.transcript_agent = TranscriptAgent(api_key)
        self.web_search_agent = WebSearchAgent()  # Pas de paramÃ¨tre
        self.need_analysis_agent = NeedAnalysisAgent(api_key)
        self.human_interface = StreamlitValidationInterface()
        
        # Configuration du checkpointer pour le debugging
        self.checkpointer = self._setup_checkpointer()
        
        # CrÃ©ation du graphe
        self.graph = self._create_graph()
    
    def _setup_checkpointer(self):
        """
        Configure le checkpointer pour le debugging avec LangGraph Studio.
        
        Returns:
            Checkpointer configurÃ©
        """
        if self.debug_mode:
            # Mode debugging - utiliser MemorySaver pour la persistance
            return MemorySaver()
        else:
            # Mode normal - pas de checkpointer
            return None
    
    def _create_graph(self) -> StateGraph:
        """
        CrÃ©e le graphe LangGraph pour le workflow d'analyse des besoins.
        
        Returns:
            StateGraph configurÃ©
        """
        # CrÃ©ation du graphe
        workflow = StateGraph(WorkflowState)
        
        # Ajout des nÅ“uds
        workflow.add_node("start_agents", self._start_agents_node)
        workflow.add_node("collect_data", self._collect_data_node)
        workflow.add_node("analyze_needs", self._analyze_needs_node)
        workflow.add_node("human_validation", self._human_validation_node)
        workflow.add_node("check_success", self._check_success_node)
        workflow.add_node("finalize_results", self._finalize_results_node)
        
        # DÃ©finition du flux - point d'entrÃ©e selon le mode
        if self.dev_mode:
            workflow.set_entry_point("collect_data")
        else:
            workflow.set_entry_point("start_agents")
        
        # Flux sÃ©quentiel
        workflow.add_edge("start_agents", "collect_data")
        
        # Suite du flux
        workflow.add_edge("collect_data", "analyze_needs")
        workflow.add_edge("analyze_needs", "human_validation")
        workflow.add_edge("human_validation", "check_success")
        
        # Conditions de branchement
        workflow.add_conditional_edges(
            "check_success",
            self._should_continue,
            {
                "continue": "analyze_needs",
                "success": "finalize_results",
                "max_iterations": END
            }
        )
        
        workflow.add_edge("finalize_results", END)
        
        # Configuration pour le debugging
        compile_kwargs = {}
        if self.debug_mode and self.checkpointer:
            compile_kwargs["checkpointer"] = self.checkpointer
            # Points d'interruption pour le debugging
            compile_kwargs["interrupt_before"] = ["analyze_needs", "human_validation"]
            compile_kwargs["interrupt_after"] = ["start_agents", "collect_data"]
            # Mode debug activÃ©
            compile_kwargs["debug"] = True
        
        return workflow.compile(**compile_kwargs)
    
    def _start_agents_node(self, state: WorkflowState) -> WorkflowState:
        """
        NÅ“ud de dÃ©marrage qui lance les 3 agents en parallÃ¨le.
        
        Args:
            state: Ã‰tat actuel du workflow
            
        Returns:
            Ã‰tat mis Ã  jour
        """
        print(f"\nğŸš€ [DEBUG] _start_agents_node - DÃ‰BUT")
        print(f"ğŸ“Š Ã‰tat d'entrÃ©e: {len(state.get('workshop_files', []))} fichiers workshop, {len(state.get('transcript_files', []))} fichiers transcript")
        
        try:
            # ExÃ©cution des 3 agents en parallÃ¨le
            workshop_files = state.get("workshop_files", [])
            transcript_files = state.get("transcript_files", [])
            company_info = state.get("company_info", {})
            
            # Workshop Agent
            if workshop_files:
                all_results = []
                for file_path in workshop_files:
                    file_results = self.workshop_agent.process_workshop_file(file_path)
                    all_results.extend(file_results)
                state["workshop_results"] = {"workshops": all_results}
            else:
                state["workshop_results"] = {}
                state["messages"] = state.get("messages", []) + [HumanMessage(content="Aucun fichier workshop fourni")]
            
            # Transcript Agent
            if transcript_files:
                results = self.transcript_agent.process_multiple_pdfs(transcript_files)
                state["transcript_results"] = results
            else:
                state["transcript_results"] = []
                state["messages"] = state.get("messages", []) + [HumanMessage(content="Aucun fichier transcript fourni")]
            
            # Web Search Agent
            if company_info:
                company_name = company_info.get("company_name", "")
                if company_name:
                    results = self.web_search_agent.search_company_info(company_name)
                    state["web_search_results"] = results
                else:
                    state["web_search_results"] = {}
                    state["messages"] = state.get("messages", []) + [HumanMessage(content="Nom d'entreprise non fourni")]
            else:
                state["web_search_results"] = {}
                state["messages"] = state.get("messages", []) + [HumanMessage(content="Aucune information entreprise fournie")]
            
            print(f"âœ… [DEBUG] _start_agents_node - FIN")
            print(f"ğŸ“Š RÃ©sultats: {len(state.get('workshop_results', {}).get('workshops', []))} workshops, {len(state.get('transcript_results', []))} transcripts, {len(state.get('web_search_results', {}))} recherches web")
            return state
            
        except Exception as e:
            print(f"âŒ [DEBUG] Erreur dans _start_agents_node: {str(e)}")
            state["messages"] = state.get("messages", []) + [HumanMessage(content=f"Erreur dÃ©marrage agents: {str(e)}")]
            return state
    
    
    def _collect_data_node(self, state: WorkflowState) -> WorkflowState:
        """
        NÅ“ud d'agrÃ©gation des donnÃ©es des 3 agents.
        
        Args:
            state: Ã‰tat actuel du workflow
            
        Returns:
            Ã‰tat mis Ã  jour
        """
        print(f"\nğŸ“Š [DEBUG] _collect_data_node - DÃ‰BUT")
        print(f"ğŸ”„ Mode dev: {self.dev_mode}")
        
        try:
            if self.dev_mode:
                # Mode dÃ©veloppement - charger les donnÃ©es mockÃ©es
                import json
                try:
                    # Charger les donnÃ©es mockÃ©es avec gestion d'erreur robuste
                    with open('/home/addeche/aiko/aikoGPT/workshop_results.json', 'r', encoding='utf-8') as f:
                        workshop_data = json.load(f)
                    
                    # Charger transcript_results avec gestion des caractÃ¨res de contrÃ´le
                    try:
                        with open('/home/addeche/aiko/aikoGPT/transcript_results.json', 'r', encoding='utf-8') as f:
                            transcript_data = json.load(f)
                    except json.JSONDecodeError as e:
                        print(f"âš ï¸ [DEBUG] Erreur parsing transcript_results.json: {e}")
                        # Essayer avec une approche plus robuste
                        with open('/home/addeche/aiko/aikoGPT/transcript_results.json', 'r', encoding='utf-8') as f:
                            content = f.read()
                            # Nettoyer les caractÃ¨res de contrÃ´le
                            import re
                            content = re.sub(r'[\x00-\x1f\x7f-\x9f]', '', content)
                            transcript_data = json.loads(content)
                    
                    with open('/home/addeche/aiko/aikoGPT/web_search_cousin_surgery.json', 'r', encoding='utf-8') as f:
                        web_search_data = json.load(f)
                    
                    # AgrÃ©gation des donnÃ©es mockÃ©es
                    # Les donnÃ©es JSON sont dÃ©jÃ  des dictionnaires, pas besoin de conversion
                    state["workshop_data"] = {"workshops": workshop_data}
                    state["transcript_data"] = transcript_data.get("results", [])
                    state["web_search_data"] = web_search_data
                    
                    # AUSSI sauvegarder dans les champs de rÃ©sultats pour la cohÃ©rence
                    state["workshop_results"] = {"workshops": workshop_data}
                    state["transcript_results"] = transcript_data.get("results", [])
                    state["web_search_results"] = web_search_data
                    
                except Exception as e:
                    state["messages"] = state.get("messages", []) + [HumanMessage(content=f"Erreur chargement donnÃ©es mockÃ©es: {str(e)}")]
                    return state
            else:
                # Mode normal - agrÃ©gation des rÃ©sultats des 3 agents
                state["workshop_data"] = state.get("workshop_results", {})
                state["transcript_data"] = state.get("transcript_results", [])
                state["web_search_data"] = state.get("web_search_results", {})
            
            # Initialisation des compteurs
            state["iteration_count"] = 0
            state["max_iterations"] = 3
            
            print(f"âœ… [DEBUG] _collect_data_node - FIN")
            print(f"ğŸ“Š DonnÃ©es agrÃ©gÃ©es: {len(state.get('workshop_data', {}).get('workshops', []))} workshops, {len(state.get('transcript_data', []))} transcripts, {len(state.get('web_search_data', {}))} recherches")
            
            return state
            
        except Exception as e:
            print(f"âŒ [DEBUG] Erreur dans _collect_data_node: {str(e)}")
            state["messages"] = state.get("messages", []) + [HumanMessage(content=f"Erreur collecte donnÃ©es: {str(e)}")]
            return state
    
    def _analyze_needs_node(self, state: WorkflowState) -> WorkflowState:
        """
        NÅ“ud d'analyse des besoins.
        
        Args:
            state: Ã‰tat actuel du workflow
            
        Returns:
            Ã‰tat mis Ã  jour
        """
        print(f"\nğŸ” [DEBUG] _analyze_needs_node - DÃ‰BUT")
        print(f"ğŸ“Š Besoins dÃ©jÃ  validÃ©s: {len(state.get('validated_needs', []))}")
        print(f"ğŸ”„ ItÃ©ration: {state.get('iteration_count', 0)}/{state.get('max_iterations', 3)}")
        
        try:
            # VÃ©rifier s'il y a des besoins dÃ©jÃ  validÃ©s
            validated_count = len(state.get("validated_needs", []))
            remaining_needs = max(0, 10 - validated_count)
            
            if remaining_needs <= 0:
                # Tous les besoins sont validÃ©s
                state["identified_needs"] = []
                return state
            
            # Analyse des besoins avec feedback si disponible
            user_feedback = state.get("user_feedback", "")
            rejected_needs = state.get("rejected_needs", [])
            
            if user_feedback or rejected_needs:
                print(f"\nğŸ”„ GÃ©nÃ©ration de {remaining_needs} nouvelles propositions...")
                if user_feedback:
                    print(f"ğŸ’¬ En tenant compte du feedback: {user_feedback}")
            
            analysis_result = self.need_analysis_agent.analyze_needs(
                state["workshop_data"],
                state["transcript_data"],
                state["web_search_data"]
            )
            
            if "error" in analysis_result:
                state["messages"] = state.get("messages", []) + [HumanMessage(content=f"Erreur analyse: {analysis_result['error']}")]
                return state
            
            # Limiter le nombre de besoins gÃ©nÃ©rÃ©s
            identified_needs = analysis_result.get("identified_needs", [])
            if len(identified_needs) > remaining_needs:
                identified_needs = identified_needs[:remaining_needs]
            
            state["identified_needs"] = identified_needs
            
            print(f"âœ… [DEBUG] _analyze_needs_node - FIN")
            print(f"ğŸ“Š Besoins identifiÃ©s: {len(identified_needs)}")
            print(f"ğŸ¯ Besoins validÃ©s total: {len(state.get('validated_needs', []))}")
            
            return state
            
        except Exception as e:
            print(f"âŒ [DEBUG] Erreur dans _analyze_needs_node: {str(e)}")
            state["messages"] = state.get("messages", []) + [HumanMessage(content=f"Erreur analyse besoins: {str(e)}")]
            return state
    
    def _human_validation_node(self, state: WorkflowState) -> WorkflowState:
        """
        NÅ“ud de validation humaine via Streamlit.
        NOUVELLE APPROCHE: Utilise session_state pour gÃ©rer l'interruption.
        
        Args:
            state: Ã‰tat actuel du workflow
            
        Returns:
            Ã‰tat mis Ã  jour
        """
        print(f"\nğŸ›‘ [DEBUG] ===== _human_validation_node - DÃ‰BUT =====")
        print(f"ğŸ“Š identified_needs: {len(state.get('identified_needs', []))}")
        print(f"ğŸ“Š validated_needs: {len(state.get('validated_needs', []))}")
        print(f"ğŸ”„ [DEBUG] Session state avant validation: {list(st.session_state.keys()) if 'st' in globals() else 'Streamlit non disponible'}")
        
        try:
            # Sauvegarder l'Ã©tat du workflow dans session_state
            print(f"ğŸ’¾ [DEBUG] Sauvegarde de l'Ã©tat du workflow")
            # Sauvegarder toutes les donnÃ©es importantes
            workflow_state = {
                "messages": state.get("messages", []),
                "workshop_files": state.get("workshop_files", []),
                "transcript_files": state.get("transcript_files", []),
                "company_info": state.get("company_info", {}),
                "workshop_results": state.get("workshop_results", {}),
                "transcript_results": state.get("transcript_results", []),
                "web_search_results": state.get("web_search_results", {}),
                "workshop_data": state.get("workshop_data", {}),
                "transcript_data": state.get("transcript_data", []),
                "web_search_data": state.get("web_search_data", {}),
                "identified_needs": state.get("identified_needs", []),
                "validated_needs": state.get("validated_needs", []),
                "rejected_needs": state.get("rejected_needs", []),
                "user_feedback": state.get("user_feedback", ""),
                "validation_result": state.get("validation_result", {}),
                "final_needs": state.get("final_needs", []),
                "success": state.get("success", False),
                "iteration_count": state.get("iteration_count", 0),
                "max_iterations": state.get("max_iterations", 3),
                "workflow_paused": state.get("workflow_paused", False)
            }
            st.session_state.workflow_state = workflow_state
            st.session_state.workflow_paused = True
            st.session_state.waiting_for_validation = True
            print(f"ğŸ’¾ [DEBUG] Ã‰tat sauvegardÃ© avec {len(workflow_state)} clÃ©s")
            
            # VÃ©rifier si on a dÃ©jÃ  des rÃ©sultats de validation
            if "validation_result" in st.session_state and st.session_state.validation_result:
                print(f"âœ… [DEBUG] RÃ©sultats de validation trouvÃ©s dans session_state")
                validation_data = st.session_state.validation_result
                
                # Traiter les rÃ©sultats de validation
                if validation_data and "validated_needs" in validation_data:
                    # Accumuler les besoins validÃ©s
                    existing_validated = state.get("validated_needs", [])
                    newly_validated = validation_data.get("validated_needs", [])
                    state["validated_needs"] = existing_validated + newly_validated
                    
                    # Accumuler les besoins rejetÃ©s
                    existing_rejected = state.get("rejected_needs", [])
                    newly_rejected = validation_data.get("rejected_needs", [])
                    state["rejected_needs"] = existing_rejected + newly_rejected
                    
                    state["user_feedback"] = validation_data.get("user_feedback", "")
                    state["validation_result"] = validation_data
                    
                    print(f"ğŸ“Š [DEBUG] Besoins validÃ©s total: {len(state['validated_needs'])}")
                    print(f"ğŸ“Š [DEBUG] Besoins rejetÃ©s total: {len(state['rejected_needs'])}")
                
                # Nettoyer l'Ã©tat de validation
                if "validation_result" in st.session_state:
                    del st.session_state.validation_result
                
                # Reprendre le workflow
                state["workflow_paused"] = False
                st.session_state.workflow_paused = False
                st.session_state.waiting_for_validation = False
                print(f"â–¶ï¸ [DEBUG] Workflow repris aprÃ¨s validation")
                print(f"ğŸ›‘ [DEBUG] ===== _human_validation_node - FIN =====")
                
                return state
            else:
                # PremiÃ¨re fois : afficher l'interface de validation
                print(f"â¸ï¸ [DEBUG] Affichage de l'interface de validation")
                
                # Afficher l'interface de validation
                self.human_interface.display_needs_for_validation(
                    state["identified_needs"],
                    len(state.get("validated_needs", []))
                )
                
                # En attente de validation - retourner l'Ã©tat actuel
                print(f"â³ [DEBUG] En attente de validation - workflow en pause")
                return state
            
        except Exception as e:
            print(f"âŒ [DEBUG] Erreur dans _human_validation_node: {str(e)}")
            state["messages"] = state.get("messages", []) + [HumanMessage(content=f"Erreur validation: {str(e)}")]
            return state
    
    def _check_success_node(self, state: WorkflowState) -> WorkflowState:
        """
        NÅ“ud de vÃ©rification du succÃ¨s.
        
        Args:
            state: Ã‰tat actuel du workflow
            
        Returns:
            Ã‰tat mis Ã  jour
        """
        try:
            # VÃ©rifier si on est en attente de validation
            if state.get("workflow_paused", False) or st.session_state.get("waiting_for_validation", False):
                print(f"â³ [DEBUG] Workflow en pause - en attente de validation")
                return state
            
            # VÃ©rification du succÃ¨s
            validated_count = len(state.get("validated_needs", []))
            success = validated_count >= 5
            
            state["success"] = success
            
            # CORRECTION: Afficher les logs APRÃˆS la validation, pas avant
            print(f"\nğŸ”„ [DEBUG] _check_success_node - APRÃˆS validation")
            print(f"ğŸ“Š Besoins validÃ©s: {validated_count}/5")
            print(f"ğŸ¯ SuccÃ¨s: {success}")
            
            if not success:
                # IncrÃ©menter le compteur d'itÃ©rations
                state["iteration_count"] = state.get("iteration_count", 0) + 1
                
                print(f"ğŸ”„ ItÃ©ration {state['iteration_count']}/{state.get('max_iterations', 3)}")
                print(f"ğŸ’¬ Feedback: {state.get('user_feedback', 'Aucun')}")
            else:
                print(f"âœ… Objectif atteint ! {validated_count} besoins validÃ©s")
            
            return state
            
        except Exception as e:
            state["messages"] = state.get("messages", []) + [HumanMessage(content=f"Erreur vÃ©rification: {str(e)}")]
            return state
    
    def _finalize_results_node(self, state: WorkflowState) -> WorkflowState:
        """
        NÅ“ud de finalisation des rÃ©sultats.
        VERSION CORRIGÃ‰E: Utilise directement les besoins validÃ©s.
        
        Args:
            state: Ã‰tat actuel du workflow
            
        Returns:
            Ã‰tat mis Ã  jour
        """
        try:
            print(f"ğŸ” [DEBUG] _finalize_results_node - DÃ‰BUT")
            print(f"ğŸ“Š [DEBUG] validation_result prÃ©sent: {'validation_result' in state}")
            print(f"ğŸ“Š [DEBUG] validated_needs dans state: {len(state.get('validated_needs', []))}")
            
            # Utiliser directement les besoins validÃ©s depuis l'Ã©tat
            validated_needs = state.get("validated_needs", [])
            
            # Si pas de besoins validÃ©s dans l'Ã©tat, essayer depuis validation_result
            if not validated_needs and "validation_result" in state and state["validation_result"]:
                validation_result = state["validation_result"]
                validated_needs = validation_result.get("validated_needs", [])
                print(f"ğŸ“Š [DEBUG] Besoins rÃ©cupÃ©rÃ©s depuis validation_result: {len(validated_needs)}")
            
            # Si toujours pas de besoins, utiliser tous les besoins identifiÃ©s
            if not validated_needs:
                validated_needs = state.get("identified_needs", [])
                print(f"ğŸ“Š [DEBUG] Utilisation de tous les besoins identifiÃ©s: {len(validated_needs)}")
            
            state["final_needs"] = validated_needs
            print(f"ğŸ“Š [DEBUG] Final needs dÃ©finis: {len(validated_needs)}")
            
            # Sauvegarde des rÃ©sultats
            self._save_results(state)
            
            return state
            
        except Exception as e:
            state["messages"] = state.get("messages", []) + [HumanMessage(content=f"Erreur finalisation: {str(e)}")]
            return state
    
    def _should_continue(self, state: WorkflowState) -> str:
        """
        DÃ©termine si le workflow doit continuer.
        
        Args:
            state: Ã‰tat actuel du workflow
            
        Returns:
            Direction Ã  prendre
        """
        if state.get("success", False):
            return "success"
        
        if state.get("iteration_count", 0) >= state.get("max_iterations", 3):
            return "max_iterations"
        
        return "continue"
    
    def _save_results(self, state: WorkflowState) -> None:
        """
        Sauvegarde les rÃ©sultats dans le dossier outputs.
        
        Args:
            state: Ã‰tat final du workflow
        """
        try:
            from datetime import datetime
            # Sauvegarde des besoins finaux
            results = {
                "final_needs": state.get("final_needs", []),
                "success": state.get("success", False),
                "iteration_count": state.get("iteration_count", 0),
                "timestamp": datetime.now().isoformat()
            }
            
            # Sauvegarde en JSON
            output_path = "/home/addeche/aiko/aikoGPT/outputs/need_analysis_results.json"
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(results, f, ensure_ascii=False, indent=2)
            
            # GÃ©nÃ©ration du graph PNG
            self._generate_graph_png()
            
        except Exception as e:
            print(f"Erreur sauvegarde: {str(e)}")
    
    def _generate_graph_png(self) -> None:
        """
        GÃ©nÃ¨re et sauvegarde le graph du workflow en PNG en utilisant LangGraph.
        """
        try:
            # Utilisation de la mÃ©thode LangGraph pour gÃ©nÃ©rer le graph
            png = self.graph.get_graph().draw_mermaid_png()
            
            # Sauvegarde du PNG
            output_path = "/home/addeche/aiko/aikoGPT/outputs/workflow_graph.png"
            with open(output_path, 'wb') as f:
                f.write(png)
            
        except Exception as e:
            print(f"Erreur gÃ©nÃ©ration graph: {str(e)}")
    
    def run(self, workshop_files: List[str] = None, transcript_files: List[str] = None, company_info: Dict[str, Any] = None) -> Dict[str, Any]:
        """
        ExÃ©cute le workflow complet.
        NOUVELLE ARCHITECTURE: Le workflow s'arrÃªte au nÅ“ud human_validation.
        
        Args:
            workshop_files: Liste des fichiers Excel des ateliers
            transcript_files: Liste des fichiers PDF des transcriptions
            company_info: Informations sur l'entreprise pour la recherche web
            
        Returns:
            RÃ©sultats du workflow
        """
        print(f"\nğŸš€ [DEBUG] run() appelÃ© - NOUVELLE ARCHITECTURE")
        
        try:
            # Ã‰tat initial avec les fichiers d'entrÃ©e
            initial_state = WorkflowState(
                messages=[],
                # Fichiers d'entrÃ©e
                workshop_files=workshop_files or [],
                transcript_files=transcript_files or [],
                company_info=company_info or {},
                # RÃ©sultats des agents (vides au dÃ©but)
                workshop_results={},
                transcript_results=[],
                web_search_results={},
                # DonnÃ©es agrÃ©gÃ©es (vides au dÃ©but)
                workshop_data={},
                transcript_data=[],
                web_search_data={},
                # RÃ©sultats de l'analyse
                identified_needs=[],
                # Validation humaine
                validated_needs=[],
                rejected_needs=[],
                user_feedback="",
                validation_result={},
                # Ã‰tat du workflow
                final_needs=[],
                success=False,
                iteration_count=0,
                max_iterations=3,
                workflow_paused=False
            )
            
            print(f"ğŸ”„ [DEBUG] ExÃ©cution du workflow jusqu'au nÅ“ud human_validation...")
            
            # ExÃ©cution du workflow JUSQU'AU NÅ’UD HUMAN_VALIDATION
            # Le workflow va s'arrÃªter lÃ  et attendre la validation humaine
            final_state = self.graph.invoke(initial_state)
            
            print(f"âœ… [DEBUG] Workflow terminÃ© aprÃ¨s validation humaine")
            print(f"ğŸ“Š [DEBUG] Success: {final_state.get('success', False)}")
            print(f"ğŸ“Š [DEBUG] Final needs: {len(final_state.get('final_needs', []))}")
            
            return {
                "success": final_state.get("success", False),
                "final_needs": final_state.get("final_needs", []),
                "summary": {
                    "total_needs": len(final_state.get("final_needs", [])),
                    "themes": list(set([need.get("theme", "") for need in final_state.get("final_needs", []) if need.get("theme")])),
                    "high_priority_count": 0  # Pas de prioritÃ© dans la structure simplifiÃ©e
                },
                "iteration_count": final_state.get("iteration_count", 0),
                "workshop_results": final_state.get("workshop_results", {}),
                "transcript_results": final_state.get("transcript_results", []),
                "web_search_results": final_state.get("web_search_results", {}),
                "messages": [msg.content for msg in final_state.get("messages", [])]
            }
            
        except Exception as e:
            print(f"âŒ [DEBUG] Erreur dans run(): {str(e)}")
            return {
                "success": False,
                "error": str(e),
                "final_needs": [],
                "iteration_count": 0,
                "messages": [f"Erreur workflow: {str(e)}"]
            }
    
    def resume_workflow(self) -> Dict[str, Any]:
        """
        Reprend le workflow aprÃ¨s validation humaine.
        VERSION CORRIGÃ‰E: Reprend depuis le nÅ“ud check_success au lieu de repartir du dÃ©but.
        
        Returns:
            RÃ©sultats du workflow
        """
        print(f"\nğŸ”„ [DEBUG] resume_workflow() appelÃ©")
        
        try:
            # RÃ©cupÃ©rer l'Ã©tat du workflow depuis session_state
            if "workflow_state" not in st.session_state:
                print(f"âŒ [DEBUG] Aucun Ã©tat de workflow trouvÃ© dans session_state")
                return {
                    "success": False,
                    "error": "Aucun Ã©tat de workflow trouvÃ©",
                    "final_needs": [],
                    "iteration_count": 0,
                    "messages": ["Erreur: Aucun Ã©tat de workflow trouvÃ©"]
                }
            
            # RÃ©cupÃ©rer l'Ã©tat sauvegardÃ©
            workflow_state = st.session_state.workflow_state
            print(f"ğŸ“Š [DEBUG] Ã‰tat du workflow rÃ©cupÃ©rÃ©: {len(workflow_state)} clÃ©s")
            
            # RÃ©cupÃ©rer le rÃ©sultat de validation depuis session_state
            if "validation_result" not in st.session_state:
                print(f"âŒ [DEBUG] Aucun rÃ©sultat de validation trouvÃ©")
                return {
                    "success": False,
                    "error": "Aucun rÃ©sultat de validation trouvÃ©",
                    "final_needs": [],
                    "iteration_count": 0,
                    "messages": ["Erreur: Aucun rÃ©sultat de validation trouvÃ©"]
                }
            
            validation_result = st.session_state.validation_result
            print(f"ğŸ“Š [DEBUG] RÃ©sultat de validation rÃ©cupÃ©rÃ©: {validation_result.get('total_validated', 0)} besoins validÃ©s")
            
            # Mettre Ã  jour l'Ã©tat avec les rÃ©sultats de validation
            workflow_state["validated_needs"] = validation_result.get("validated_needs", [])
            workflow_state["rejected_needs"] = validation_result.get("rejected_needs", [])
            workflow_state["user_feedback"] = validation_result.get("user_feedback", "")
            workflow_state["validation_result"] = validation_result
            
            # ExÃ©cuter les nÅ“uds suivants manuellement
            print(f"ğŸ”„ [DEBUG] ExÃ©cution des nÅ“uds suivants aprÃ¨s validation...")
            
            # 1. VÃ©rifier le succÃ¨s
            print(f"ğŸ” [DEBUG] _check_success_node - DÃ‰BUT")
            workflow_state = self._check_success_node(workflow_state)
            print(f"âœ… [DEBUG] _check_success_node - FIN")
            
            # 2. DÃ©terminer la suite selon le rÃ©sultat
            should_continue = self._should_continue(workflow_state)
            print(f"ğŸ“Š [DEBUG] DÃ©cision de continuation: {should_continue}")
            
            if should_continue == "success":
                # 3. Finaliser les rÃ©sultats
                print(f"ğŸ” [DEBUG] _finalize_results_node - DÃ‰BUT")
                workflow_state = self._finalize_results_node(workflow_state)
                print(f"âœ… [DEBUG] _finalize_results_node - FIN")
                
                print(f"âœ… [DEBUG] Workflow terminÃ© avec succÃ¨s")
                print(f"ğŸ“Š [DEBUG] Success: {workflow_state.get('success', False)}")
                print(f"ğŸ“Š [DEBUG] Final needs: {len(workflow_state.get('final_needs', []))}")
                
                return {
                    "success": workflow_state.get("success", False),
                    "final_needs": workflow_state.get("final_needs", []),
                    "summary": {
                        "total_needs": len(workflow_state.get("final_needs", [])),
                        "themes": list(set([need.get("theme", "") for need in workflow_state.get("final_needs", []) if need.get("theme")])),
                        "high_priority_count": 0
                    },
                    "iteration_count": workflow_state.get("iteration_count", 0),
                    "workshop_results": workflow_state.get("workshop_results", {}),
                    "transcript_results": workflow_state.get("transcript_results", []),
                    "web_search_results": workflow_state.get("web_search_results", {}),
                    "messages": [msg.content for msg in workflow_state.get("messages", [])]
                }
            elif should_continue == "continue":
                # 4. Continuer avec une nouvelle analyse
                print(f"ğŸ” [DEBUG] _analyze_needs_node - DÃ‰BUT (nouvelle itÃ©ration)")
                workflow_state = self._analyze_needs_node(workflow_state)
                print(f"âœ… [DEBUG] _analyze_needs_node - FIN")
                
                # 5. Nouvelle validation humaine
                print(f"ğŸ›‘ [DEBUG] ===== _human_validation_node - DÃ‰BUT (nouvelle validation) =====")
                workflow_state = self._human_validation_node(workflow_state)
                print(f"â³ [DEBUG] Workflow en pause - nouvelle validation requise")
                
                # Le workflow s'arrÃªte Ã  nouveau pour une nouvelle validation
                return {
                    "success": False,
                    "error": "Nouvelle validation requise",
                    "final_needs": [],
                    "iteration_count": workflow_state.get("iteration_count", 0),
                    "messages": ["Nouvelle validation requise"]
                }
            else:  # max_iterations
                print(f"âŒ [DEBUG] Nombre maximum d'itÃ©rations atteint")
                return {
                    "success": False,
                    "error": "Nombre maximum d'itÃ©rations atteint",
                    "final_needs": [],
                    "iteration_count": workflow_state.get("iteration_count", 0),
                    "messages": ["Nombre maximum d'itÃ©rations atteint"]
                }
            
        except Exception as e:
            print(f"âŒ [DEBUG] Erreur dans resume_workflow(): {str(e)}")
            return {
                "success": False,
                "error": str(e),
                "final_needs": [],
                "iteration_count": 0,
                "messages": [f"Erreur reprise workflow: {str(e)}"]
            }
