"""
Workflow LangGraph pour l'analyse des besoins
"""

import os
import json
from typing import Dict, List, Any, TypedDict, Annotated
from langgraph.graph import StateGraph, END
from langgraph.graph.message import add_messages
from langchain_core.messages import BaseMessage, HumanMessage, AIMessage
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langgraph.checkpoint.memory import MemorySaver
# Streamlit supprim√© - plus utilis√©

# Import des agents
import sys
sys.path.append('/home/addeche/aiko/aikoGPT')
from need_analysis.need_analysis_agent import NeedAnalysisAgent
from process_atelier.workshop_agent import WorkshopAgent
from process_transcript.transcript_agent import TranscriptAgent
from web_search.web_search_agent import WebSearchAgent
# StreamlitValidationInterface supprim√© - plus utilis√©
from use_case_analysis.use_case_analysis_agent import UseCaseAnalysisAgent
# StreamlitUseCaseValidation supprim√© - plus utilis√©
from utils.token_tracker import TokenTracker


class WorkflowState(TypedDict):
    """√âtat du workflow LangGraph"""
    messages: Annotated[List[BaseMessage], add_messages]
    # Fichiers d'entr√©e
    workshop_files: List[str]
    transcript_files: List[str]
    company_info: Dict[str, Any]
    # R√©sultats des agents
    workshop_results: Dict[str, Any]
    transcript_results: List[Dict[str, Any]]
    web_search_results: Dict[str, Any]
    # Flag pour skip agents si r√©sultats pr√©-calcul√©s
    skip_agents: bool
    # Donn√©es agr√©g√©es pour l'analyse (seulement transcript_data car il contient une transformation utile)
    transcript_data: List[Dict[str, Any]]
    # R√©sultats de l'analyse des besoins
    identified_needs: List[Dict[str, Any]]
    # Validation humaine des besoins
    validated_needs: List[Dict[str, Any]]
    rejected_needs: List[Dict[str, Any]]
    user_feedback: str
    validation_result: Dict[str, Any]
    # √âtat du workflow des besoins
    final_needs: List[Dict[str, Any]]
    success: bool
    iteration_count: int
    max_iterations: int
    workflow_paused: bool
    # R√©sultats de l'analyse des use cases
    proposed_quick_wins: List[Dict[str, Any]]
    proposed_structuration_ia: List[Dict[str, Any]]
    # Validation humaine des use cases
    validated_quick_wins: List[Dict[str, Any]]
    validated_structuration_ia: List[Dict[str, Any]]
    rejected_quick_wins: List[Dict[str, Any]]
    rejected_structuration_ia: List[Dict[str, Any]]
    use_case_user_feedback: str
    use_case_validation_result: Dict[str, Any]
    # √âtat du workflow des use cases
    final_quick_wins: List[Dict[str, Any]]
    final_structuration_ia: List[Dict[str, Any]]
    use_case_success: bool
    use_case_iteration: int
    max_use_case_iterations: int
    use_case_workflow_paused: bool


class NeedAnalysisWorkflow:
    """
    Workflow LangGraph pour l'analyse des besoins m√©tier
    """
    
    def __init__(self, api_key: str, dev_mode: bool = False, debug_mode: bool = False):
        """
        Initialise le workflow avec la cl√© API OpenAI.
        
        Args:
            api_key: Cl√© API OpenAI
            dev_mode: Mode d√©veloppement (utilise les donn√©es mock√©es)
            debug_mode: Mode debugging avec LangGraph Studio
        """
        self.api_key = api_key
        self.dev_mode = dev_mode
        self.debug_mode = debug_mode
        model = os.getenv('OPENAI_MODEL', 'gpt-5-nano')
        self.llm = ChatOpenAI(
            model=model,
            api_key=api_key
        )
        
        # Initialisation du tracker de tokens et co√ªts
        self.tracker = TokenTracker(output_dir="outputs/token_tracking")
        print("üìä Token Tracker initialis√© - Suivi des co√ªts activ√©\n")
        
        # Initialisation des agents AVEC le tracker pour ceux qui le supportent
        self.workshop_agent = WorkshopAgent(api_key)
        self.transcript_agent = TranscriptAgent(api_key)
        self.web_search_agent = WebSearchAgent()  # Pas de param√®tre
        self.need_analysis_agent = NeedAnalysisAgent(api_key, tracker=self.tracker)
        # Interfaces Streamlit supprim√©es - plus utilis√©es
        self.human_interface = None
        # Nouveaux agents pour l'analyse des use cases
        self.use_case_analysis_agent = UseCaseAnalysisAgent(api_key, tracker=self.tracker)
        self.use_case_validation_interface = None
        
        # Configuration du checkpointer pour le debugging
        self.checkpointer = self._setup_checkpointer()
        
        # Cr√©ation du graphe
        self.graph = self._create_graph()
    
    def _print_tracker_stats(self, agent_name: str = None):
        """
        Affiche les statistiques de tokens du tracker.
        
        Args:
            agent_name: Nom de l'agent qui vient de s'ex√©cuter (optionnel)
        """
        if not self.tracker:
            return
        
        summary = self.tracker.get_session_summary()
        
        print("\n" + "‚îÄ"*70)
        if agent_name:
            print(f"üìä TOKENS APR√àS {agent_name.upper()}")
        else:
            print("üìä TOKENS CUMUL√âS")
        print("‚îÄ"*70)
        
        # Tokens cumul√©s
        total_tokens = summary['total_tokens']
        input_tokens = summary['total_input_tokens']
        output_tokens = summary['total_output_tokens']
        
        print(f"üî§ Tokens cumul√©s: {total_tokens:,}")
        print(f"   ‚îú‚îÄ Input:  {input_tokens:,}")
        print(f"   ‚îî‚îÄ Output: {output_tokens:,}")
        
        # D√©tails par agent
        if summary['calls_by_agent']:
            print(f"\nüìä D√©tails par agent:")
            for name, stats in summary['calls_by_agent'].items():
                print(f"   ‚Ä¢ {name}:")
                print(f"     ‚îú‚îÄ Total: {stats['total_tokens']:,} tokens")
                print(f"     ‚îú‚îÄ Input: {stats['input_tokens']:,}")
                print(f"     ‚îî‚îÄ Output: {stats['output_tokens']:,}")
        
        print("‚îÄ"*70 + "\n")
    
    def _setup_checkpointer(self):
        """
        Configure le checkpointer pour le debugging avec LangGraph Studio.
        
        Returns:
            Checkpointer configur√©
        """
        if self.debug_mode:
            # Mode debugging - utiliser MemorySaver pour la persistance
            return MemorySaver()
        else:
            # Mode normal - pas de checkpointer
            return None
    
    def _create_graph(self) -> StateGraph:
        """
        Cr√©e le graphe LangGraph pour le workflow d'analyse des besoins.
        NOUVELLE VERSION: Avec parall√©lisation des agents.
        
        Returns:
            StateGraph configur√©
        """
        # Cr√©ation du graphe
        workflow = StateGraph(WorkflowState)
        
        # Ajout des n≈ìuds - Phase 1 : Analyse des besoins
        # NOUVEAU: Dispatcher et agents parall√®les
        workflow.add_node("dispatcher", self._dispatcher_node)
        workflow.add_node("workshop_agent", self._workshop_agent_node)
        workflow.add_node("transcript_agent", self._transcript_agent_node)
        workflow.add_node("web_search_agent", self._web_search_agent_node)
        workflow.add_node("collect_data", self._collect_data_node)
        workflow.add_node("analyze_needs", self._analyze_needs_node)
        workflow.add_node("human_validation", self._human_validation_node)
        workflow.add_node("check_success", self._check_success_node)
        workflow.add_node("finalize_results", self._finalize_results_node)
        
        # Ajout des n≈ìuds - Phase 2 : Analyse des use cases
        workflow.add_node("analyze_use_cases", self._analyze_use_cases_node)
        workflow.add_node("validate_use_cases", self._validate_use_cases_node)
        workflow.add_node("check_use_case_success", self._check_use_case_success_node)
        workflow.add_node("finalize_use_cases", self._finalize_use_cases_node)
        
        # D√©finition du flux - point d'entr√©e selon le mode
        if self.dev_mode:
            workflow.set_entry_point("collect_data")
        else:
            workflow.set_entry_point("dispatcher")
        
        # NOUVEAU: Flux parall√®le - Phase 1 : Collecte de donn√©es
        # Dispatcher ‚Üí 3 agents en parall√®le ‚Üí collect_data
        workflow.add_edge("dispatcher", "workshop_agent")
        workflow.add_edge("dispatcher", "transcript_agent")
        workflow.add_edge("dispatcher", "web_search_agent")
        workflow.add_edge("workshop_agent", "collect_data")
        workflow.add_edge("transcript_agent", "collect_data")
        workflow.add_edge("web_search_agent", "collect_data")
        
        # Flux s√©quentiel - Phase 1 : Analyse des besoins
        workflow.add_edge("collect_data", "analyze_needs")
        workflow.add_edge("analyze_needs", "human_validation")
        workflow.add_edge("human_validation", "check_success")
        
        # Conditions de branchement - Phase 1
        workflow.add_conditional_edges(
            "check_success",
            self._should_continue,
            {
                "continue": "analyze_needs",
                "success": "finalize_results",
                "max_iterations": END
            }
        )
        
        # Transition vers Phase 2 : Analyse des use cases
        workflow.add_edge("finalize_results", "analyze_use_cases")
        workflow.add_edge("analyze_use_cases", "validate_use_cases")
        workflow.add_edge("validate_use_cases", "check_use_case_success")
        
        # Conditions de branchement - Phase 2
        workflow.add_conditional_edges(
            "check_use_case_success",
            self._should_continue_use_cases,
            {
                "continue": "analyze_use_cases",
                "success": "finalize_use_cases",
                "max_iterations": END
            }
        )
        
        workflow.add_edge("finalize_use_cases", END)
        
        # Configuration avec checkpointer et interrupts
        # NOUVEAU: Toujours utiliser checkpointer et interrupts (pas seulement en debug)
        compile_kwargs = {
            "checkpointer": MemorySaver(),  # Toujours actif pour g√©rer les interrupts
            "interrupt_before": ["human_validation", "validate_use_cases"]  # Points d'arr√™t pour validation humaine
        }
        
        # Options suppl√©mentaires en mode debug
        if self.debug_mode:
            compile_kwargs["interrupt_after"] = ["dispatcher", "collect_data"]
            compile_kwargs["debug"] = True
        
        return workflow.compile(**compile_kwargs)
    
    # ==================== NOUVEAUX N≈íUDS POUR LA PARALL√âLISATION ====================
    
    def _dispatcher_node(self, state: WorkflowState) -> WorkflowState:
        """
        N≈ìud dispatcher qui pr√©pare et distribue le travail aux 3 agents en parall√®le.
        
        Args:
            state: √âtat actuel du workflow
            
        Returns:
            √âtat mis √† jour
        """
        print(f"\nüöÄ [PARALL√âLISATION] dispatcher_node - D√âBUT")
        print(f"üìä √âtat d'entr√©e:")
        print(f"   - workshop_files: {len(state.get('workshop_files', []))}")
        print(f"   - transcript_files: {len(state.get('transcript_files', []))}")
        print(f"   - company_info: {bool(state.get('company_info', {}))}")
        print(f"   - R√©sultats pr√©-calcul√©s:")
        print(f"     ‚Ä¢ workshop_results: {bool(state.get('workshop_results', {}))}")
        print(f"     ‚Ä¢ transcript_results: {bool(state.get('transcript_results', []))}")
        print(f"     ‚Ä¢ web_search_results: {bool(state.get('web_search_results', {}))}")
        
        try:
            # V√©rifier si les r√©sultats sont d√©j√† pr√©sents (calcul√©s dans Streamlit)
            if state.get("workshop_results") or state.get("transcript_results") or state.get("web_search_results"):
                print(f"‚úÖ [PARALL√âLISATION] R√©sultats pr√©-calcul√©s d√©tect√©s - skip des agents")
                # Marquer que nous n'avons pas besoin d'ex√©cuter les agents
                state["skip_agents"] = True
            else:
                print(f"üîÑ [PARALL√âLISATION] Aucun r√©sultat pr√©-calcul√© - les 3 agents vont s'ex√©cuter en PARALL√àLE")
                state["skip_agents"] = False
            
            print(f"‚úÖ [PARALL√âLISATION] dispatcher_node - FIN")
            return state
            
        except Exception as e:
            print(f"‚ùå [PARALL√âLISATION] Erreur dans dispatcher_node: {str(e)}")
            state["messages"] = state.get("messages", []) + [HumanMessage(content=f"Erreur dispatcher: {str(e)}")]
            return state
    
    def _workshop_agent_node(self, state: WorkflowState) -> Dict[str, Any]:
        """
        N≈ìud workshop agent - s'ex√©cute en PARALL√àLE avec les autres agents.
        
        Args:
            state: √âtat actuel du workflow
            
        Returns:
            Dictionnaire partiel avec seulement workshop_results (pour √©viter les conflits de fusion)
        """
        print(f"\nüìù [PARALL√àLE-1/3] workshop_agent_node - D√âBUT")
        
        try:
            # Si les r√©sultats sont pr√©-calcul√©s, skip
            if state.get("skip_agents", False):
                print(f"‚è© [PARALL√àLE-1/3] R√©sultats pr√©-calcul√©s - skip")
                return {}
            
            workshop_files = state.get("workshop_files", [])
            
            if workshop_files:
                print(f"üîÑ [PARALL√àLE-1/3] Traitement de {len(workshop_files)} fichiers workshop...")
                all_results = []
                for file_path in workshop_files:
                    file_results = self.workshop_agent.process_workshop_file(file_path)
                    all_results.extend(file_results)
                print(f"‚úÖ [PARALL√àLE-1/3] {len(all_results)} workshops trait√©s")
                print(f"‚úÖ [PARALL√àLE-1/3] workshop_agent_node - FIN")
                return {"workshop_results": {"workshops": all_results}}
            else:
                print(f"‚ö†Ô∏è [PARALL√àLE-1/3] Aucun fichier workshop fourni")
                print(f"‚úÖ [PARALL√àLE-1/3] workshop_agent_node - FIN")
                return {"workshop_results": {}}
            
        except Exception as e:
            print(f"‚ùå [PARALL√àLE-1/3] Erreur dans workshop_agent_node: {str(e)}")
            return {
                "workshop_results": {},
                "messages": [HumanMessage(content=f"Erreur workshop agent: {str(e)}")]
            }
    
    def _transcript_agent_node(self, state: WorkflowState) -> Dict[str, Any]:
        """
        N≈ìud transcript agent - s'ex√©cute en PARALL√àLE avec les autres agents.
        
        Args:
            state: √âtat actuel du workflow
            
        Returns:
            Dictionnaire partiel avec seulement transcript_results (pour √©viter les conflits de fusion)
        """
        print(f"\nüìÑ [PARALL√àLE-2/3] transcript_agent_node - D√âBUT")
        
        try:
            # Si les r√©sultats sont pr√©-calcul√©s, skip
            if state.get("skip_agents", False):
                print(f"‚è© [PARALL√àLE-2/3] R√©sultats pr√©-calcul√©s - skip")
                return {}
            
            transcript_files = state.get("transcript_files", [])
            
            if transcript_files:
                print(f"üîÑ [PARALL√àLE-2/3] Traitement de {len(transcript_files)} PDFs...")
                results = self.transcript_agent.process_multiple_pdfs(transcript_files)
                print(f"‚úÖ [PARALL√àLE-2/3] {len(results.get('results', []))} transcripts trait√©s")
                print(f"‚úÖ [PARALL√àLE-2/3] transcript_agent_node - FIN")
                return {"transcript_results": results}
            else:
                print(f"‚ö†Ô∏è [PARALL√àLE-2/3] Aucun fichier transcript fourni")
                print(f"‚úÖ [PARALL√àLE-2/3] transcript_agent_node - FIN")
                return {"transcript_results": []}
            
        except Exception as e:
            print(f"‚ùå [PARALL√àLE-2/3] Erreur dans transcript_agent_node: {str(e)}")
            return {
                "transcript_results": [],
                "messages": [HumanMessage(content=f"Erreur transcript agent: {str(e)}")]
            }
    
    def _web_search_agent_node(self, state: WorkflowState) -> Dict[str, Any]:
        """
        N≈ìud web search agent - s'ex√©cute en PARALL√àLE avec les autres agents.
        
        Args:
            state: √âtat actuel du workflow
            
        Returns:
            Dictionnaire partiel avec seulement web_search_results (pour √©viter les conflits de fusion)
        """
        print(f"\nüåê [PARALL√àLE-3/3] web_search_agent_node - D√âBUT")
        
        try:
            # Si les r√©sultats sont pr√©-calcul√©s, skip
            if state.get("skip_agents", False):
                print(f"‚è© [PARALL√àLE-3/3] R√©sultats pr√©-calcul√©s - skip")
                return {}
            
            company_info = state.get("company_info", {})
            
            if company_info:
                company_name = company_info.get("company_name", "")
                if company_name:
                    print(f"üîÑ [PARALL√àLE-3/3] Recherche web pour: {company_name}")
                    results = self.web_search_agent.search_company_info(company_name)
                    print(f"‚úÖ [PARALL√àLE-3/3] Recherche web termin√©e")
                    print(f"‚úÖ [PARALL√àLE-3/3] web_search_agent_node - FIN")
                    return {"web_search_results": results}
                else:
                    print(f"‚ö†Ô∏è [PARALL√àLE-3/3] Nom d'entreprise non fourni")
                    print(f"‚úÖ [PARALL√àLE-3/3] web_search_agent_node - FIN")
                    return {"web_search_results": {}}
            else:
                print(f"‚ö†Ô∏è [PARALL√àLE-3/3] Aucune information entreprise fournie")
                print(f"‚úÖ [PARALL√àLE-3/3] web_search_agent_node - FIN")
                return {"web_search_results": {}}
            
        except Exception as e:
            print(f"‚ùå [PARALL√àLE-3/3] Erreur dans web_search_agent_node: {str(e)}")
            return {
                "web_search_results": {},
                "messages": [HumanMessage(content=f"Erreur web search agent: {str(e)}")]
            }
    
    # ==================== ANCIEN N≈íUD (LEGACY - conserv√© pour compatibilit√©) ====================
    
    def _start_agents_node(self, state: WorkflowState) -> WorkflowState:
        """
        N≈ìud de d√©marrage qui utilise les r√©sultats pr√©-calcul√©s ou lance les agents si n√©cessaire.
        NOUVELLE APPROCHE: Les r√©sultats sont calcul√©s dans Streamlit et pass√©s directement.
        
        Args:
            state: √âtat actuel du workflow
            
        Returns:
            √âtat mis √† jour
        """
        print(f"\nüöÄ [DEBUG] _start_agents_node - D√âBUT")
        print(f"üìä √âtat d'entr√©e: workshop_results={len(state.get('workshop_results', {}).get('workshops', []))}, transcript_results={len(state.get('transcript_results', []))}, web_search_results pr√©sent={bool(state.get('web_search_results', {}))}")
        
        try:
            # V√âRIFIER SI LES R√âSULTATS SONT D√âJ√Ä PR√âSENTS (calcul√©s dans Streamlit)
            if state.get("workshop_results") or state.get("transcript_results") or state.get("web_search_results"):
                print(f"‚úÖ [DEBUG] R√©sultats pr√©-calcul√©s d√©tect√©s - utilisation directe")
                print(f"üìä workshop_results: {len(state.get('workshop_results', {}).get('workshops', []))} workshops")
                print(f"üìä transcript_results: {len(state.get('transcript_results', []))} transcripts")
                print(f"üìä web_search_results: {len(state.get('web_search_results', {}))} recherches")
                
                # Les r√©sultats sont d√©j√† dans l'√©tat, on les utilise directement
                # Pas besoin de relancer les agents
                print(f"‚úÖ [DEBUG] _start_agents_node - FIN (r√©sultats pr√©-calcul√©s utilis√©s)")
                return state
            
            # SINON, lancer les agents (mode legacy / fichiers fournis)
            print(f"‚ö†Ô∏è [DEBUG] Aucun r√©sultat pr√©-calcul√© - lancement des agents")
            workshop_files = state.get("workshop_files", [])
            transcript_files = state.get("transcript_files", [])
            company_info = state.get("company_info", {})
            
            # Workshop Agent
            if workshop_files:
                all_results = []
                for file_path in workshop_files:
                    file_results = self.workshop_agent.process_workshop_file(file_path)
                    all_results.extend(file_results)
                state["workshop_results"] = {"workshops": all_results}
            else:
                state["workshop_results"] = {}
                state["messages"] = state.get("messages", []) + [HumanMessage(content="Aucun fichier workshop fourni")]
            
            # Transcript Agent
            if transcript_files:
                results = self.transcript_agent.process_multiple_pdfs(transcript_files)
                state["transcript_results"] = results
            else:
                state["transcript_results"] = []
                state["messages"] = state.get("messages", []) + [HumanMessage(content="Aucun fichier transcript fourni")]
            
            # Web Search Agent
            if company_info:
                company_name = company_info.get("company_name", "")
                if company_name:
                    results = self.web_search_agent.search_company_info(company_name)
                    state["web_search_results"] = results
                else:
                    state["web_search_results"] = {}
                    state["messages"] = state.get("messages", []) + [HumanMessage(content="Nom d'entreprise non fourni")]
            else:
                state["web_search_results"] = {}
                state["messages"] = state.get("messages", []) + [HumanMessage(content="Aucune information entreprise fournie")]
            
            print(f"‚úÖ [DEBUG] _start_agents_node - FIN")
            print(f"üìä R√©sultats: {len(state.get('workshop_results', {}).get('workshops', []))} workshops, {len(state.get('transcript_results', []))} transcripts, {len(state.get('web_search_results', {}))} recherches web")
            return state
            
        except Exception as e:
            print(f"‚ùå [DEBUG] Erreur dans _start_agents_node: {str(e)}")
            state["messages"] = state.get("messages", []) + [HumanMessage(content=f"Erreur d√©marrage agents: {str(e)}")]
            return state
    
    
    def _collect_data_node(self, state: WorkflowState) -> WorkflowState:
        """
        N≈ìud d'agr√©gation des donn√©es des 3 agents.
        NOUVEAU: Attend que les 3 agents parall√®les aient termin√©.
        
        Args:
            state: √âtat actuel du workflow
            
        Returns:
            √âtat mis √† jour
        """
        print(f"\nüìä [CONVERGENCE] collect_data_node - D√âBUT")
        print(f"üîÑ Mode dev: {self.dev_mode}")
        print(f"üìä R√©sultats des agents parall√®les:")
        print(f"   ‚Ä¢ workshop_results: {len(state.get('workshop_results', {}).get('workshops', []))} workshops")
        print(f"   ‚Ä¢ transcript_results: {len(state.get('transcript_results', {}).get('results', []) if isinstance(state.get('transcript_results', {}), dict) else state.get('transcript_results', []))} transcripts")
        print(f"   ‚Ä¢ web_search_results: {bool(state.get('web_search_results', {}))}")
        
        try:
            if self.dev_mode:
                # Mode d√©veloppement - charger les donn√©es mock√©es
                import json
                try:
                    # Charger les donn√©es mock√©es avec gestion d'erreur robuste
                    with open('/home/addeche/aiko/aikoGPT/workshop_results.json', 'r', encoding='utf-8') as f:
                        workshop_data = json.load(f)
                    
                    # Charger transcript_results avec gestion des caract√®res de contr√¥le
                    try:
                        with open('/home/addeche/aiko/aikoGPT/transcript_results.json', 'r', encoding='utf-8') as f:
                            transcript_data = json.load(f)
                    except json.JSONDecodeError as e:
                        print(f"‚ö†Ô∏è [DEBUG] Erreur parsing transcript_results.json: {e}")
                        # Essayer avec une approche plus robuste
                        with open('/home/addeche/aiko/aikoGPT/transcript_results.json', 'r', encoding='utf-8') as f:
                            content = f.read()
                            # Nettoyer les caract√®res de contr√¥le
                            import re
                            content = re.sub(r'[\x00-\x1f\x7f-\x9f]', '', content)
                            transcript_data = json.loads(content)
                    
                    with open('/home/addeche/aiko/aikoGPT/web_search_cousin_surgery.json', 'r', encoding='utf-8') as f:
                        web_search_data = json.load(f)
                    
                    # Agr√©gation des donn√©es mock√©es
                    # SIMPLIFICATION: Utiliser directement workshop_results au lieu de workshop_data
                    state["workshop_results"] = {"workshops": workshop_data}
                    
                    # OPTIMISATION: Ne garder que semantic_analysis dans transcript_data
                    # pour √©viter le doublon avec interesting_parts
                    
                    # Extraire la liste "results" du dictionnaire transcript_data
                    transcript_results = transcript_data.get("results", [])
                    
                    filtered_transcripts = []
                    for transcript in transcript_results:
                        # V√©rifier que transcript est bien un dictionnaire
                        if not isinstance(transcript, dict):
                            print(f"‚ö†Ô∏è [DEBUG] Transcript ignor√© (type incorrect): {type(transcript)}")
                            continue
                        
                        filtered_transcript = {
                            "pdf_path": transcript.get("pdf_path"),
                            "status": transcript.get("status"),
                            "semantic_analysis": transcript.get("semantic_analysis", {})
                        }
                        filtered_transcripts.append(filtered_transcript)
                    
                    state["transcript_data"] = filtered_transcripts
                    
                    # Sauvegarder les r√©sultats (web_search_data d√©j√† sauvegard√© plus haut)
                    state["transcript_results"] = transcript_data  # Garder la structure compl√®te
                    state["web_search_results"] = web_search_data
                    
                    print(f"üîç [DEBUG] Transcripts filtr√©s: {len(filtered_transcripts)} transcripts (semantic_analysis uniquement)")
                    
                except Exception as e:
                    state["messages"] = state.get("messages", []) + [HumanMessage(content=f"Erreur chargement donn√©es mock√©es: {str(e)}")]
                    return state
            else:
                # Mode normal - agr√©gation des r√©sultats des 3 agents PARALL√àLES
                print(f"üìä [CONVERGENCE] Agr√©gation des r√©sultats des agents parall√®les")
                
                # SIMPLIFICATION: Utiliser directement workshop_results et web_search_results
                # Seule transformation n√©cessaire : filtrer transcript_data pour garder seulement semantic_analysis
                
                # OPTIMISATION: Ne garder que semantic_analysis dans transcript_data
                transcript_results_raw = state.get("transcript_results", {})
                
                print(f"üîç [CONVERGENCE] Type de transcript_results_raw: {type(transcript_results_raw)}")
                if isinstance(transcript_results_raw, dict):
                    print(f"üîç [CONVERGENCE] Cl√©s du dictionnaire: {list(transcript_results_raw.keys())}")
                
                # Extraire la liste "results" si c'est un dictionnaire avec cette cl√©
                if isinstance(transcript_results_raw, dict) and "results" in transcript_results_raw:
                    transcript_results = transcript_results_raw.get("results", [])
                    print(f"‚úÖ [CONVERGENCE] Extraction de la cl√© 'results': {len(transcript_results)} transcripts")
                elif isinstance(transcript_results_raw, list):
                    transcript_results = transcript_results_raw
                    print(f"‚úÖ [CONVERGENCE] transcript_results est d√©j√† une liste: {len(transcript_results)} √©l√©ments")
                else:
                    transcript_results = []
                    print(f"‚ö†Ô∏è [CONVERGENCE] Format inattendu, utilisation d'une liste vide")
                
                filtered_transcripts = []
                for transcript in transcript_results:
                    # V√©rifier que transcript est bien un dictionnaire
                    if not isinstance(transcript, dict):
                        print(f"‚ö†Ô∏è [CONVERGENCE] Transcript ignor√© (type incorrect): {type(transcript)}")
                        continue
                    
                    filtered_transcript = {
                        "pdf_path": transcript.get("pdf_path"),
                        "status": transcript.get("status"),
                        "semantic_analysis": transcript.get("semantic_analysis", {})
                    }
                    filtered_transcripts.append(filtered_transcript)
                
                state["transcript_data"] = filtered_transcripts
                
                print(f"üîç [CONVERGENCE] Transcripts filtr√©s: {len(filtered_transcripts)} transcripts (semantic_analysis uniquement)")
            
            # Initialisation des compteurs
            state["iteration_count"] = 0
            state["max_iterations"] = 3
            
            print(f"‚úÖ [CONVERGENCE] collect_data_node - FIN")
            print(f"üìä Donn√©es agr√©g√©es: {len(state.get('workshop_results', {}).get('workshops', []))} workshops, {len(state.get('transcript_data', []))} transcripts, recherche web={bool(state.get('web_search_results', {}))}")
            print(f"üéØ [CONVERGENCE] Les 3 agents parall√®les ont termin√© avec succ√®s")
            
            return state
            
        except Exception as e:
            print(f"‚ùå [CONVERGENCE] Erreur dans collect_data_node: {str(e)}")
            state["messages"] = state.get("messages", []) + [HumanMessage(content=f"Erreur collecte donn√©es: {str(e)}")]
            return state
    
    def _analyze_needs_node(self, state: WorkflowState) -> WorkflowState:
        """
        N≈ìud d'analyse des besoins.
        MODE DEV: Charge les besoins depuis un JSON au lieu de les g√©n√©rer.
        
        Args:
            state: √âtat actuel du workflow
            
        Returns:
            √âtat mis √† jour
        """
        print(f"\nüîç [DEBUG] _analyze_needs_node - D√âBUT")
        print(f"üìä Besoins d√©j√† valid√©s: {len(state.get('validated_needs', []))}")
        print(f"üîÑ It√©ration: {state.get('iteration_count', 0)}/{state.get('max_iterations', 3)}")
        print(f"üîß Mode dev: {self.dev_mode}")
        
        try:
            # V√©rifier s'il y a des besoins d√©j√† valid√©s
            validated_count = len(state.get("validated_needs", []))
            remaining_needs = max(0, 10 - validated_count)
            
            if remaining_needs <= 0:
                # Tous les besoins sont valid√©s
                print(f"‚úÖ [DEBUG] Tous les besoins sont d√©j√† valid√©s ({validated_count})")
                state["identified_needs"] = []
                return state
            
            # MODE DEV: Charger les besoins depuis le JSON
            if self.dev_mode:
                print(f"üîß [DEBUG] Mode dev activ√© - chargement des besoins depuis le JSON")
                try:
                    with open('/home/addeche/aiko/aikoGPT/need_analysis_results_mock.json', 'r', encoding='utf-8') as f:
                        mock_data = json.load(f)
                    
                    identified_needs = mock_data.get("identified_needs", [])
                    
                    # Limiter le nombre de besoins selon les besoins restants
                    if len(identified_needs) > remaining_needs:
                        identified_needs = identified_needs[:remaining_needs]
                    
                    state["identified_needs"] = identified_needs
                    
                    print(f"‚úÖ [DEBUG] Besoins charg√©s depuis le JSON: {len(identified_needs)}")
                    print(f"üìä [DEBUG] Besoins identifi√©s: {len(identified_needs)}")
                    print(f"üéØ [DEBUG] Besoins valid√©s total: {len(state.get('validated_needs', []))}")
                    
                    return state
                    
                except Exception as e:
                    print(f"‚ùå [DEBUG] Erreur lors du chargement du JSON: {str(e)}")
                    # Continuer en mode normal si le chargement √©choue
            
            # MODE NORMAL: G√©n√©ration des besoins avec l'IA
            print(f"ü§ñ [DEBUG] Mode normal - g√©n√©ration des besoins avec l'IA")
            
            # Analyse des besoins avec feedback si disponible
            user_feedback = state.get("user_feedback", "")
            rejected_needs = state.get("rejected_needs", [])
            previous_needs = state.get("identified_needs", [])
            iteration = state.get("iteration_count", 0) + 1
            
            if user_feedback or rejected_needs:
                print(f"\nüîÑ G√©n√©ration de {remaining_needs} nouvelles propositions...")
                if user_feedback:
                    print(f"üí¨ En tenant compte du feedback: {user_feedback}")
                if rejected_needs:
                    print(f"üö´ Besoins rejet√©s √† √©viter: {len(rejected_needs)}")
            
            # üí∞ OPTIMISATION: Filtrer les quotes des previous_needs et rejected_needs pour √©conomiser les tokens
            # Les quotes sont d√©j√† dans workshop/transcript, pas besoin de les dupliquer au LLM
            previous_needs_light = None
            rejected_needs_light = None
            
            if iteration > 1 and previous_needs:
                previous_needs_light = [
                    {"id": need.get("id"), "theme": need.get("theme")}
                    for need in previous_needs
                ]
                print(f"üí∞ [OPTIMISATION] Previous needs all√©g√©s: {len(previous_needs)} besoins sans quotes")
            
            if iteration > 1 and rejected_needs:
                rejected_needs_light = [
                    {"id": need.get("id"), "theme": need.get("theme")}
                    for need in rejected_needs
                ]
                print(f"üí∞ [OPTIMISATION] Rejected needs all√©g√©s: {len(rejected_needs)} besoins sans quotes")
            
            analysis_result = self.need_analysis_agent.analyze_needs(
                workshop_data=state["workshop_results"],  # SIMPLIFICATION: utiliser directement workshop_results
                transcript_data=state["transcript_data"],
                web_search_data=state["web_search_results"],  # SIMPLIFICATION: utiliser directement web_search_results
                iteration=iteration,
                previous_needs=previous_needs_light,
                rejected_needs=rejected_needs_light,
                user_feedback=user_feedback,
                validated_needs_count=validated_count
            )
            
            if "error" in analysis_result:
                state["messages"] = state.get("messages", []) + [HumanMessage(content=f"Erreur analyse: {analysis_result['error']}")]
                return state
            
            # Limiter le nombre de besoins g√©n√©r√©s
            identified_needs = analysis_result.get("identified_needs", [])
            if len(identified_needs) > remaining_needs:
                identified_needs = identified_needs[:remaining_needs]
            
            state["identified_needs"] = identified_needs
            
            print(f"‚úÖ [DEBUG] _analyze_needs_node - FIN")
            print(f"üìä Besoins identifi√©s: {len(identified_needs)}")
            print(f"üéØ Besoins valid√©s total: {len(state.get('validated_needs', []))}")
            
            # Affichage des co√ªts apr√®s l'analyse des besoins
            self._print_tracker_stats(agent_name="need_analysis")
            
            return state
            
        except Exception as e:
            print(f"‚ùå [DEBUG] Erreur dans _analyze_needs_node: {str(e)}")
            state["messages"] = state.get("messages", []) + [HumanMessage(content=f"Erreur analyse besoins: {str(e)}")]
            return state
    
    def _human_validation_node(self, state: WorkflowState) -> WorkflowState:
        """
        N≈ìud de validation humaine SIMPLIFI√â.
        
        NOUVELLE ARCHITECTURE avec interrupts natifs :
        - Le workflow s'arr√™te AVANT ce n≈ìud (interrupt_before)
        - L'API/Streamlit d√©tecte que le workflow est en pause
        - Streamlit affiche l'interface de validation
        - L'utilisateur valide et renvoie le feedback
        - Le feedback est inject√© dans l'√©tat via l'API
        - Le workflow reprend et ce n≈ìud traite le feedback
        
        Args:
            state: √âtat actuel du workflow
            
        Returns:
            √âtat mis √† jour avec les besoins valid√©s/rejet√©s
        """
        print(f"\nüõë [INTERRUPT] human_validation_node - D√âBUT")
        print(f"üìä identified_needs: {len(state.get('identified_needs', []))}")
        print(f"üìä validated_needs existants: {len(state.get('validated_needs', []))}")
        
        try:
            # V√©rifier si on a re√ßu le feedback (inject√© par l'API)
            if "validation_result" in state and state["validation_result"]:
                print(f"‚úÖ [RESUME] Feedback re√ßu via API")
                validation_data = state["validation_result"]
                
                # Traiter les r√©sultats de validation
                existing_validated = state.get("validated_needs", [])
                newly_validated = validation_data.get("validated_needs", [])
                
                # √âviter les doublons
                existing_ids = [need.get("theme", "") for need in existing_validated]
                unique_newly_validated = [need for need in newly_validated if need.get("theme", "") not in existing_ids]
                
                state["validated_needs"] = existing_validated + unique_newly_validated
                
                # M√™me logique pour les rejets
                existing_rejected = state.get("rejected_needs", [])
                newly_rejected = validation_data.get("rejected_needs", [])
                
                existing_rejected_ids = [need.get("theme", "") for need in existing_rejected]
                unique_newly_rejected = [need for need in newly_rejected if need.get("theme", "") not in existing_rejected_ids]
                
                state["rejected_needs"] = existing_rejected + unique_newly_rejected
                state["user_feedback"] = validation_data.get("user_feedback", "")
                
                # Nettoyer le flag
                state["validation_result"] = {}
                
                print(f"üìä [RESUME] Besoins nouvellement valid√©s: {len(unique_newly_validated)}")
                print(f"üìä [RESUME] Total besoins valid√©s: {len(state['validated_needs'])}")
                print(f"‚ñ∂Ô∏è [RESUME] Workflow continue...")
                
                return state
            else:
                # Premi√®re fois : le workflow va s'arr√™ter ici (interrupt_before)
                print(f"‚è∏Ô∏è [INTERRUPT] Aucun feedback - le workflow va s'arr√™ter")
                print(f"üí° [INTERRUPT] L'API d√©tectera cet arr√™t et Streamlit affichera l'interface")
                
                # Juste retourner l'√©tat
                # Le workflow s'arr√™te automatiquement car interrupt_before
                return state
            
        except Exception as e:
            print(f"‚ùå [ERROR] Erreur dans human_validation_node: {str(e)}")
            state["messages"] = state.get("messages", []) + [HumanMessage(content=f"Erreur validation: {str(e)}")]
            return state
    
    def _check_success_node(self, state: WorkflowState) -> WorkflowState:
        """
        N≈ìud de v√©rification du succ√®s.
        
        Args:
            state: √âtat actuel du workflow
            
        Returns:
            √âtat mis √† jour
        """
        try:
            print(f"\nüîÑ [DEBUG] _check_success_node - D√âBUT")
            
            # NE PAS v√©rifier workflow_paused ici car nous sommes APR√àS validation
            # Cette v√©rification emp√™chait le workflow de progresser
            
            # V√©rification du succ√®s
            validated_count = len(state.get("validated_needs", []))
            success = validated_count >= 5
            
            state["success"] = success
            
            print(f"üìä Besoins valid√©s: {validated_count}/5")
            print(f"üéØ Succ√®s: {success}")
            
            if not success:
                # Incr√©menter le compteur d'it√©rations
                state["iteration_count"] = state.get("iteration_count", 0) + 1
                
                print(f"üîÑ It√©ration {state['iteration_count']}/{state.get('max_iterations', 3)}")
                print(f"üí¨ Feedback: {state.get('user_feedback', 'Aucun')}")
            else:
                print(f"‚úÖ Objectif atteint ! {validated_count} besoins valid√©s")
            
            print(f"‚úÖ [DEBUG] _check_success_node - FIN")
            return state
            
        except Exception as e:
            print(f"‚ùå [DEBUG] Erreur dans _check_success_node: {str(e)}")
            state["messages"] = state.get("messages", []) + [HumanMessage(content=f"Erreur v√©rification: {str(e)}")]
            return state
    
    def _finalize_results_node(self, state: WorkflowState) -> WorkflowState:
        """
        N≈ìud de finalisation des r√©sultats.
        VERSION CORRIG√âE: Utilise directement les besoins valid√©s.
        MODE DEV: Charge les besoins depuis need_analysis_results.json si disponible.
        
        Args:
            state: √âtat actuel du workflow
            
        Returns:
            √âtat mis √† jour
        """
        try:
            print(f"\nüîç [DEBUG] _finalize_results_node - D√âBUT")
            print(f"üîß [DEBUG] Mode dev: {self.dev_mode}")
            print(f"üìä [DEBUG] validation_result pr√©sent: {'validation_result' in state}")
            print(f"üìä [DEBUG] validated_needs dans state: {len(state.get('validated_needs', []))}")
            
            # MODE DEV: Charger les besoins depuis le JSON si disponible
            if self.dev_mode:
                try:
                    print(f"üîß [DEBUG] Mode dev activ√© - tentative de chargement depuis need_analysis_results.json")
                    with open('/home/addeche/aiko/aikoGPT/need_analysis_results.json', 'r', encoding='utf-8') as f:
                        need_data = json.load(f)
                    
                    final_needs = need_data.get("final_needs", [])
                    if final_needs:
                        state["final_needs"] = final_needs
                        print(f"‚úÖ [DEBUG] Besoins charg√©s depuis le JSON: {len(final_needs)}")
                        
                        # Debug: Afficher les th√®mes des besoins
                        print(f"üìã [DEBUG] Th√®mes des besoins valid√©s:")
                        for i, need in enumerate(final_needs, 1):
                            print(f"   {i}. {need.get('theme', 'N/A')}")
                        
                        # Sauvegarde des r√©sultats
                        self._save_results(state)
                        
                        print(f"‚úÖ [DEBUG] _finalize_results_node - FIN")
                        return state
                except Exception as e:
                    print(f"‚ö†Ô∏è [DEBUG] Erreur lors du chargement du JSON: {str(e)}")
                    # Continuer en mode normal si le chargement √©choue
            
            # MODE NORMAL: Utiliser directement les besoins valid√©s depuis l'√©tat
            validated_needs = state.get("validated_needs", [])
            
            # Si pas de besoins valid√©s dans l'√©tat, essayer depuis validation_result
            if not validated_needs and "validation_result" in state and state["validation_result"]:
                validation_result = state["validation_result"]
                validated_needs = validation_result.get("validated_needs", [])
                print(f"üìä [DEBUG] Besoins r√©cup√©r√©s depuis validation_result: {len(validated_needs)}")
            
            # Si toujours pas de besoins, utiliser tous les besoins identifi√©s
            if not validated_needs:
                validated_needs = state.get("identified_needs", [])
                print(f"üìä [DEBUG] Utilisation de tous les besoins identifi√©s: {len(validated_needs)}")
            
            state["final_needs"] = validated_needs
            print(f"üìä [DEBUG] Final needs d√©finis: {len(validated_needs)}")
            
            # Debug: Afficher les th√®mes des besoins
            if validated_needs:
                print(f"üìã [DEBUG] Th√®mes des besoins valid√©s:")
                for i, need in enumerate(validated_needs, 1):
                    print(f"   {i}. {need.get('theme', 'N/A')}")
            
            # Sauvegarde des r√©sultats
            self._save_results(state)
            
            print(f"‚úÖ [DEBUG] _finalize_results_node - FIN")
            return state
            
        except Exception as e:
            print(f"‚ùå [DEBUG] Erreur dans _finalize_results_node: {str(e)}")
            state["messages"] = state.get("messages", []) + [HumanMessage(content=f"Erreur finalisation: {str(e)}")]
            return state
    
    def _should_continue(self, state: WorkflowState) -> str:
        """
        D√©termine si le workflow doit continuer.
        
        Args:
            state: √âtat actuel du workflow
            
        Returns:
            Direction √† prendre
        """
        if state.get("success", False):
            return "success"
        
        if state.get("iteration_count", 0) >= state.get("max_iterations", 3):
            return "max_iterations"
        
        return "continue"
    
    def _save_results(self, state: WorkflowState) -> None:
        """
        Sauvegarde les r√©sultats dans le dossier outputs.
        
        Args:
            state: √âtat final du workflow
        """
        try:
            from datetime import datetime
            # Sauvegarde des besoins finaux
            results = {
                "final_needs": state.get("final_needs", []),
                "success": state.get("success", False),
                "iteration_count": state.get("iteration_count", 0),
                "timestamp": datetime.now().isoformat()
            }
            
            # Sauvegarde en JSON
            output_path = "/home/addeche/aiko/aikoGPT/outputs/need_analysis_results.json"
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(results, f, ensure_ascii=False, indent=2)
            
            # G√©n√©ration du graph PNG
            self._generate_graph_png()
            
        except Exception as e:
            print(f"Erreur sauvegarde: {str(e)}")
    
    def _generate_graph_png(self) -> None:
        """
        G√©n√®re et sauvegarde le graph du workflow en PNG en utilisant LangGraph.
        """
        try:
            # Utilisation de la m√©thode LangGraph pour g√©n√©rer le graph
            png = self.graph.get_graph().draw_mermaid_png()
            
            # Sauvegarde du PNG
            output_path = "/home/addeche/aiko/aikoGPT/outputs/workflow_graph.png"
            with open(output_path, 'wb') as f:
                f.write(png)
            
        except Exception as e:
            print(f"Erreur g√©n√©ration graph: {str(e)}")
    
    def run(self, workshop_files: List[str] = None, transcript_files: List[str] = None, company_info: Dict[str, Any] = None, 
            workshop_results: Dict[str, Any] = None, transcript_results: List[Dict[str, Any]] = None, web_search_results: Dict[str, Any] = None,
            thread_id: str = None) -> Dict[str, Any]:
        """
        Ex√©cute le workflow complet.
        NOUVELLE ARCHITECTURE: Ex√©cution MANUELLE des n≈ìuds jusqu'√† human_validation.
        MODE DEV: Charge les besoins depuis need_analysis_results.json et passe directement aux use cases.
        
        Args:
            workshop_files: Liste des fichiers Excel des ateliers (legacy)
            transcript_files: Liste des fichiers PDF des transcriptions (legacy)
            company_info: Informations sur l'entreprise pour la recherche web
            workshop_results: R√©sultats pr√©-calcul√©s du workshop agent (NOUVEAU)
            transcript_results: R√©sultats pr√©-calcul√©s du transcript agent (NOUVEAU)
            web_search_results: R√©sultats pr√©-calcul√©s du web search agent (NOUVEAU)
            thread_id: ID du thread pour le checkpointer (optionnel, g√©n√©r√© automatiquement si non fourni)
            
        Returns:
            R√©sultats du workflow
        """
        print(f"\nüöÄ [DEBUG] run() appel√© - NOUVELLE ARCHITECTURE")
        print(f"üîß [DEBUG] Mode dev: {self.dev_mode}")
        print(f"üìä [DEBUG] R√©sultats pr√©-calcul√©s: workshop={bool(workshop_results)}, transcript={bool(transcript_results)}, web_search={bool(web_search_results)}")
        print(f"üîë [DEBUG] Thread ID fourni: {thread_id}")
        
        try:
            # √âtat initial avec les fichiers d'entr√©e ET les r√©sultats pr√©-calcul√©s
            state = WorkflowState(
                messages=[],
                # Fichiers d'entr√©e (legacy)
                workshop_files=workshop_files or [],
                transcript_files=transcript_files or [],
                company_info=company_info or {},
                # R√©sultats des agents (pr√©-calcul√©s OU vides)
                workshop_results=workshop_results or {},
                transcript_results=transcript_results or [],
                web_search_results=web_search_results or {},
                # Flag pour parall√©lisation
                skip_agents=False,
                # Donn√©es agr√©g√©es (seulement transcript_data car transformation utile)
                transcript_data=[],
                # R√©sultats de l'analyse des besoins
                identified_needs=[],
                # Validation humaine des besoins
                validated_needs=[],
                rejected_needs=[],
                user_feedback="",
                validation_result={},
                # √âtat du workflow des besoins
                final_needs=[],
                success=False,
                iteration_count=0,
                max_iterations=3,
                workflow_paused=False,
                # R√©sultats de l'analyse des use cases
                proposed_quick_wins=[],
                proposed_structuration_ia=[],
                # Validation humaine des use cases
                validated_quick_wins=[],
                validated_structuration_ia=[],
                rejected_quick_wins=[],
                rejected_structuration_ia=[],
                use_case_user_feedback="",
                use_case_validation_result={},
                # √âtat du workflow des use cases
                final_quick_wins=[],
                final_structuration_ia=[],
                use_case_success=False,
                use_case_iteration=0,
                max_use_case_iterations=3,
                use_case_workflow_paused=False
            )
            
            # MODE DEV: V√©rifier si need_analysis_results.json existe
            if self.dev_mode:
                try:
                    print(f"üîß [DEBUG] Mode dev activ√© - tentative de chargement depuis need_analysis_results.json")
                    with open('/home/addeche/aiko/aikoGPT/need_analysis_results.json', 'r', encoding='utf-8') as f:
                        need_data = json.load(f)
                    
                    final_needs = need_data.get("final_needs", [])
                    if final_needs:
                        print(f"‚úÖ [DEBUG] Besoins charg√©s depuis le JSON: {len(final_needs)}")
                        
                        # Charger les donn√©es mock√©es pour le contexte
                        state = self._collect_data_node(state)
                        
                        # D√©finir les besoins finaux et marquer comme succ√®s
                        state["final_needs"] = final_needs
                        state["validated_needs"] = final_needs
                        state["success"] = True
                        
                        # PASSER DIRECTEMENT √Ä L'ANALYSE DES USE CASES
                        print(f"üöÄ [DEBUG] Passage direct √† l'analyse des use cases")
                        
                        # Analyser les use cases
                        state = self._analyze_use_cases_node(state)
                        
                        # Afficher l'interface de validation des use cases
                        state = self._validate_use_cases_node(state)
                        
                        print(f"‚è∏Ô∏è [DEBUG] Workflow en pause - en attente de validation des use cases")
                        
                        # Retourner un √©tat "en pause" pour les use cases
                        return {
                            "success": False,
                            "final_needs": final_needs,
                            "summary": {
                                "total_needs": len(final_needs),
                                "themes": [need.get("theme", "") for need in final_needs],
                            },
                            "iteration_count": state.get("iteration_count", 0),
                            "workshop_results": state.get("workshop_results", {}),
                            "transcript_results": state.get("transcript_results", []),
                            "web_search_results": state.get("web_search_results", {}),
                            "messages": ["Workflow en pause - en attente de validation des use cases"]
                        }
                        
                except FileNotFoundError:
                    print(f"‚ö†Ô∏è [DEBUG] Fichier need_analysis_results.json non trouv√© - ex√©cution normale")
                    # Continuer en mode normal
                except Exception as e:
                    print(f"‚ö†Ô∏è [DEBUG] Erreur lors du chargement du JSON: {str(e)}")
                    # Continuer en mode normal
            
            # MODE NORMAL: Ex√©cution standard AVEC PARALL√âLISATION
            print(f"üîÑ [DEBUG] Ex√©cution avec PARALL√âLISATION des agents...")
            
            # NOUVEAU: Utiliser le graphe compil√© pour b√©n√©ficier de la parall√©lisation
            # Le graphe va ex√©cuter : dispatcher ‚Üí 3 agents en parall√®le ‚Üí collect_data ‚Üí analyze_needs ‚Üí human_validation (STOP)
            
            # Utiliser le thread_id fourni ou en g√©n√©rer un nouveau
            if thread_id is None:
                import uuid
                thread_id = str(uuid.uuid4())
                print(f"üîë [DEBUG] Thread ID g√©n√©r√© automatiquement: {thread_id}")
            
            config = {"configurable": {"thread_id": thread_id}}
            
            # Ex√©cuter le workflow jusqu'√† l'interrupt (human_validation)
            print(f"üöÄ [DEBUG] Ex√©cution du graphe avec thread_id: {thread_id}")
            
            # Le workflow va s'arr√™ter √† human_validation car c'est d√©fini dans interrupt_before
            final_state = None
            for chunk in self.graph.stream(state, config):
                print(f"üìä [DEBUG] Chunk re√ßu: {list(chunk.keys())}")
                # Chaque chunk contient l'√©tat mis √† jour par un n≈ìud
                for node_name, node_state in chunk.items():
                    print(f"  ‚Ä¢ N≈ìud '{node_name}' ex√©cut√©")
                    final_state = node_state
            
            # Le workflow s'est arr√™t√© √† human_validation
            print(f"‚è∏Ô∏è [DEBUG] Workflow arr√™t√© avant human_validation - en attente de validation")
            
            # IMPORTANT : R√©cup√©rer l'√©tat complet depuis le checkpointer apr√®s l'interrupt
            # car le dernier chunk (__interrupt__) ne contient pas l'√©tat complet
            snapshot = self.graph.get_state(config)
            state = snapshot.values
            
            print(f"üìä [DEBUG] √âtat r√©cup√©r√© depuis le checkpointer:")
            print(f"üìä [DEBUG] Besoins identifi√©s: {len(state.get('identified_needs', []))}")
            print(f"üìä [DEBUG] Besoins valid√©s: {len(state.get('validated_needs', []))}")
            
            # Retourner un √©tat "en pause" AVEC les besoins identifi√©s
            return {
                "success": False,
                "workflow_paused": True,  # ‚Üê AJOUT√â
                "identified_needs": state.get("identified_needs", []),  # ‚Üê AJOUT√â
                "validated_needs": state.get("validated_needs", []),  # ‚Üê AJOUT√â
                "final_needs": [],
                "summary": {
                    "total_needs": 0,
                    "themes": [],
                },
                "iteration_count": state.get("iteration_count", 0),
                "workshop_results": state.get("workshop_results", {}),
                "transcript_results": state.get("transcript_results", []),
                "web_search_results": state.get("web_search_results", {}),
                "messages": ["Workflow en pause - en attente de validation"]
            }
            
        except Exception as e:
            print(f"‚ùå [DEBUG] Erreur dans run(): {str(e)}")
            import traceback
            traceback.print_exc()
            return {
                "success": False,
                "error": str(e),
                "final_needs": [],
                "iteration_count": 0,
                "messages": [f"Erreur workflow: {str(e)}"]
            }
    
    # Fonction resume_workflow supprim√©e - √©tait sp√©cifique √† Streamlit
    def resume_workflow_removed(self) -> Dict[str, Any]:
        """
        FONCTION SUPPRIM√âE - √©tait sp√©cifique √† Streamlit.
        La validation humaine se fait maintenant via l'API FastAPI.
        """
        return {
            "success": False,
            "error": "Fonction supprim√©e - utilisez l'API FastAPI pour la validation",
            "final_needs": [],
            "iteration_count": 0,
            "messages": ["Fonction obsol√®te"]
        }
    
    # ==================== NOUVEAUX N≈íUDS POUR L'ANALYSE DES USE CASES ====================
    
    def _analyze_use_cases_node(self, state: WorkflowState) -> WorkflowState:
        """
        N≈ìud d'analyse des cas d'usage IA √† partir des besoins valid√©s.
        
        Args:
            state: √âtat actuel du workflow
            
        Returns:
            √âtat mis √† jour
        """
        print(f"\nüî¨ [DEBUG] _analyze_use_cases_node - D√âBUT")
        print(f"üìä Besoins valid√©s en entr√©e: {len(state.get('final_needs', []))}")
        
        try:
            # Initialiser les compteurs si premi√®re it√©ration
            if "use_case_iteration" not in state:
                state["use_case_iteration"] = 0
                state["max_use_case_iterations"] = 3
                state["validated_quick_wins"] = []
                state["validated_structuration_ia"] = []
                state["rejected_quick_wins"] = []
                state["rejected_structuration_ia"] = []
            
            # Incr√©menter l'it√©ration au d√©but de l'analyse
            state["use_case_iteration"] = state.get("use_case_iteration", 0) + 1
            
            print(f"üîÑ It√©ration use case: {state.get('use_case_iteration', 0)}/{state.get('max_use_case_iterations', 3)}")
            
            # R√©cup√©rer les besoins valid√©s
            validated_needs = state.get("final_needs", [])
            
            if not validated_needs:
                print(f"‚ö†Ô∏è [DEBUG] Aucun besoin valid√© trouv√©")
                state["proposed_quick_wins"] = []
                state["proposed_structuration_ia"] = []
                return state
            
            # Calculer les cas d'usage d√©j√† valid√©s
            validated_qw_count = len(state.get("validated_quick_wins", []))
            validated_sia_count = len(state.get("validated_structuration_ia", []))
            
            print(f"üìä [DEBUG] Quick Wins valid√©s: {validated_qw_count}/5")
            print(f"üìä [DEBUG] Structuration IA valid√©s: {validated_sia_count}/5")
            
            # Pr√©parer les donn√©es pour la g√©n√©ration
            iteration = state.get("use_case_iteration", 1)
            previous_use_cases = None
            rejected_quick_wins = state.get("rejected_quick_wins", [])
            rejected_structuration_ia = state.get("rejected_structuration_ia", [])
            user_feedback = state.get("use_case_user_feedback", "")
            
            if iteration > 1:
                # R√©g√©n√©ration avec feedback
                previous_use_cases = {
                    "quick_wins": state.get("proposed_quick_wins", []),
                    "structuration_ia": state.get("proposed_structuration_ia", [])
                }
                
                if user_feedback:
                    print(f"üí¨ [DEBUG] Commentaires utilisateur : {user_feedback[:100]}...")
                if rejected_quick_wins:
                    print(f"üö´ [DEBUG] Quick Wins rejet√©s √† √©viter : {len(rejected_quick_wins)}")
                if rejected_structuration_ia:
                    print(f"üö´ [DEBUG] Structuration IA rejet√©s √† √©viter : {len(rejected_structuration_ia)}")
            
            # R√©cup√©rer les donn√©es sources pour enrichir le contexte
            # SIMPLIFICATION: Utiliser directement les r√©sultats au lieu des copies
            workshop_results = state.get("workshop_results", {})
            transcript_data = state.get("transcript_data", [])
            web_search_results = state.get("web_search_results", {})
            
            print(f"üîç [DEBUG] Donn√©es de contexte: {len(workshop_results.get('workshops', []))} workshops, "
                  f"{len(transcript_data)} transcripts, web_search pr√©sent={bool(web_search_results)}")
            
            # üí∞ OPTIMISATION: Filtrer les quotes des validated_needs pour √©conomiser les tokens
            # Les quotes sont d√©j√† dans workshop/transcript, pas besoin de les dupliquer au LLM
            validated_needs_light = [
                {"id": need.get("id"), "theme": need.get("theme"), "description": need.get("description", "")}
                for need in validated_needs
            ]
            print(f"üí∞ [OPTIMISATION] Validated needs all√©g√©s: {len(validated_needs)} besoins sans quotes")
            
            # Appeler l'agent d'analyse des use cases avec les donn√©es de contexte
            print(f"ü§ñ [DEBUG] Appel √† l'agent d'analyse des use cases")
            result = self.use_case_analysis_agent.analyze_use_cases(
                validated_needs=validated_needs_light,
                workshop_data=workshop_results,
                transcript_data=transcript_data,
                web_search_data=web_search_results,
                iteration=iteration,
                previous_use_cases=previous_use_cases,
                rejected_quick_wins=rejected_quick_wins if iteration > 1 else None,
                rejected_structuration_ia=rejected_structuration_ia if iteration > 1 else None,
                user_feedback=user_feedback,
                validated_quick_wins_count=validated_qw_count,
                validated_structuration_ia_count=validated_sia_count
            )
            
            if "error" in result:
                print(f"‚ùå [DEBUG] Erreur lors de l'analyse: {result['error']}")
                state["messages"] = state.get("messages", []) + [HumanMessage(content=f"Erreur analyse use cases: {result['error']}")]
                return state
            
            # Mettre √† jour l'√©tat avec les r√©sultats
            state["proposed_quick_wins"] = result.get("quick_wins", [])
            state["proposed_structuration_ia"] = result.get("structuration_ia", [])
            
            print(f"‚úÖ [DEBUG] _analyze_use_cases_node - FIN")
            print(f"üìä Quick Wins propos√©s: {len(state['proposed_quick_wins'])}")
            print(f"üìä Structuration IA propos√©s: {len(state['proposed_structuration_ia'])}")
            
            # Affichage des co√ªts apr√®s l'analyse des cas d'usage
            self._print_tracker_stats(agent_name="use_case_analysis")
            
            return state
            
        except Exception as e:
            print(f"‚ùå [DEBUG] Erreur dans _analyze_use_cases_node: {str(e)}")
            import traceback
            traceback.print_exc()
            state["messages"] = state.get("messages", []) + [HumanMessage(content=f"Erreur analyse use cases: {str(e)}")]
            return state
    
    def _validate_use_cases_node(self, state: WorkflowState) -> WorkflowState:
        """
        N≈ìud de validation humaine des cas d'usage SIMPLIFI√â.
        
        NOUVELLE ARCHITECTURE avec interrupts natifs :
        - Le workflow s'arr√™te AVANT ce n≈ìud (interrupt_before)
        - L'API/Streamlit d√©tecte que le workflow est en pause
        - Streamlit affiche l'interface de validation des use cases
        - L'utilisateur valide et renvoie le feedback
        - Le feedback est inject√© dans l'√©tat via l'API
        - Le workflow reprend et ce n≈ìud traite le feedback
        
        Args:
            state: √âtat actuel du workflow
            
        Returns:
            √âtat mis √† jour avec les use cases valid√©s/rejet√©s
        """
        print(f"\nüõë [INTERRUPT] validate_use_cases_node - D√âBUT")
        print(f"üìä Quick Wins propos√©s: {len(state.get('proposed_quick_wins', []))}")
        print(f"üìä Structuration IA propos√©s: {len(state.get('proposed_structuration_ia', []))}")
        print(f"üìä Quick Wins valid√©s existants: {len(state.get('validated_quick_wins', []))}")
        print(f"üìä Structuration IA valid√©s existants: {len(state.get('validated_structuration_ia', []))}")
        
        try:
            # V√©rifier si on a re√ßu le feedback (inject√© par l'API)
            if "use_case_validation_result" in state and state["use_case_validation_result"]:
                print(f"‚úÖ [RESUME] Feedback use cases re√ßu via API")
                validation_data = state["use_case_validation_result"]
                
                # Traiter les r√©sultats de validation
                existing_qw = state.get("validated_quick_wins", [])
                newly_validated_qw = validation_data.get("validated_quick_wins", [])
                
                existing_sia = state.get("validated_structuration_ia", [])
                newly_validated_sia = validation_data.get("validated_structuration_ia", [])
                
                # √âviter les doublons
                existing_qw_ids = [uc.get("titre", "") for uc in existing_qw]
                unique_qw = [uc for uc in newly_validated_qw if uc.get("titre", "") not in existing_qw_ids]
                
                existing_sia_ids = [uc.get("titre", "") for uc in existing_sia]
                unique_sia = [uc for uc in newly_validated_sia if uc.get("titre", "") not in existing_sia_ids]
                
                state["validated_quick_wins"] = existing_qw + unique_qw
                state["validated_structuration_ia"] = existing_sia + unique_sia
                
                # M√™me chose pour les rejet√©s
                existing_rejected_qw = state.get("rejected_quick_wins", [])
                newly_rejected_qw = validation_data.get("rejected_quick_wins", [])
                state["rejected_quick_wins"] = existing_rejected_qw + newly_rejected_qw
                
                existing_rejected_sia = state.get("rejected_structuration_ia", [])
                newly_rejected_sia = validation_data.get("rejected_structuration_ia", [])
                state["rejected_structuration_ia"] = existing_rejected_sia + newly_rejected_sia
                
                state["use_case_user_feedback"] = validation_data.get("user_feedback", "")
                
                # Nettoyer le flag
                state["use_case_validation_result"] = {}
                
                print(f"üìä [RESUME] Quick Wins nouvellement valid√©s: {len(unique_qw)}")
                print(f"üìä [RESUME] Structuration IA nouvellement valid√©s: {len(unique_sia)}")
                print(f"üìä [RESUME] Total Quick Wins valid√©s: {len(state['validated_quick_wins'])}")
                print(f"üìä [RESUME] Total Structuration IA valid√©s: {len(state['validated_structuration_ia'])}")
                print(f"‚ñ∂Ô∏è [RESUME] Workflow continue...")
                
                return state
            else:
                # Premi√®re fois : le workflow va s'arr√™ter ici (interrupt_before)
                print(f"‚è∏Ô∏è [INTERRUPT] Aucun feedback - le workflow va s'arr√™ter")
                print(f"üí° [INTERRUPT] L'API d√©tectera cet arr√™t et Streamlit affichera l'interface")
                
                # Juste retourner l'√©tat
                # Le workflow s'arr√™te automatiquement car interrupt_before
                return state
            
        except Exception as e:
            print(f"‚ùå [ERROR] Erreur dans validate_use_cases_node: {str(e)}")
            import traceback
            traceback.print_exc()
            state["messages"] = state.get("messages", []) + [HumanMessage(content=f"Erreur validation use cases: {str(e)}")]
            return state
    
    def _check_use_case_success_node(self, state: WorkflowState) -> WorkflowState:
        """
        N≈ìud de v√©rification du succ√®s de la validation des use cases.
        
        Args:
            state: √âtat actuel du workflow
            
        Returns:
            √âtat mis √† jour
        """
        try:
            print(f"\nüîÑ [DEBUG] _check_use_case_success_node - D√âBUT")
            
            # V√©rification du succ√®s
            validated_qw_count = len(state.get("validated_quick_wins", []))
            validated_sia_count = len(state.get("validated_structuration_ia", []))
            
            success = self.use_case_analysis_agent.check_validation_success(
                validated_qw_count,
                validated_sia_count
            )
            
            state["use_case_success"] = success
            
            print(f"üìä Quick Wins valid√©s: {validated_qw_count}/5")
            print(f"üìä Structuration IA valid√©s: {validated_sia_count}/5")
            print(f"üéØ Succ√®s: {success}")
            
            if not success:
                # L'incr√©mentation est maintenant faite au d√©but de _analyze_use_cases_node
                print(f"üîÑ It√©ration {state['use_case_iteration']}/{state.get('max_use_case_iterations', 3)}")
                print(f"üí¨ Feedback: {state.get('use_case_user_feedback', 'Aucun')}")
            else:
                print(f"‚úÖ Objectif atteint ! {validated_qw_count} Quick Wins et {validated_sia_count} Structuration IA valid√©s")
            
            print(f"‚úÖ [DEBUG] _check_use_case_success_node - FIN")
            return state
            
        except Exception as e:
            print(f"‚ùå [DEBUG] Erreur dans _check_use_case_success_node: {str(e)}")
            import traceback
            traceback.print_exc()
            state["messages"] = state.get("messages", []) + [HumanMessage(content=f"Erreur v√©rification use cases: {str(e)}")]
            return state
    
    def _finalize_use_cases_node(self, state: WorkflowState) -> WorkflowState:
        """
        N≈ìud de finalisation des cas d'usage.
        
        Args:
            state: √âtat actuel du workflow
            
        Returns:
            √âtat mis √† jour
        """
        try:
            print(f"\nüîç [DEBUG] _finalize_use_cases_node - D√âBUT")
            print(f"üìä [DEBUG] Quick Wins valid√©s: {len(state.get('validated_quick_wins', []))}")
            print(f"üìä [DEBUG] Structuration IA valid√©s: {len(state.get('validated_structuration_ia', []))}")
            
            # Utiliser directement les cas d'usage valid√©s depuis l'√©tat
            validated_qw = state.get("validated_quick_wins", [])
            validated_sia = state.get("validated_structuration_ia", [])
            
            state["final_quick_wins"] = validated_qw
            state["final_structuration_ia"] = validated_sia
            
            print(f"üìä [DEBUG] Final Quick Wins d√©finis: {len(validated_qw)}")
            print(f"üìä [DEBUG] Final Structuration IA d√©finis: {len(validated_sia)}")
            
            # Debug: Afficher les titres des cas d'usage
            if validated_qw:
                print(f"üìã [DEBUG] Titres des Quick Wins valid√©s:")
                for i, uc in enumerate(validated_qw, 1):
                    print(f"   {i}. {uc.get('titre', 'N/A')}")
            
            if validated_sia:
                print(f"üìã [DEBUG] Titres des Structuration IA valid√©s:")
                for i, uc in enumerate(validated_sia, 1):
                    print(f"   {i}. {uc.get('titre', 'N/A')}")
            
            # Sauvegarde des r√©sultats
            self._save_use_case_results(state)
            
            print(f"‚úÖ [DEBUG] _finalize_use_cases_node - FIN")
            
            # Affichage du rapport final des co√ªts
            print("\n" + "="*70)
            print("üìä RAPPORT FINAL DES CO√õTS")
            print("="*70)
            self.tracker.print_summary()
            
            # Sauvegarde du rapport de tracking
            report_path = self.tracker.save_report()
            print(f"üìÑ Rapport de co√ªts sauvegard√©: {report_path}\n")
            
            return state
            
        except Exception as e:
            print(f"‚ùå [DEBUG] Erreur dans _finalize_use_cases_node: {str(e)}")
            import traceback
            traceback.print_exc()
            state["messages"] = state.get("messages", []) + [HumanMessage(content=f"Erreur finalisation use cases: {str(e)}")]
            return state
    
    def _should_continue_use_cases(self, state: WorkflowState) -> str:
        """
        D√©termine si le workflow des use cases doit continuer.
        
        Args:
            state: √âtat actuel du workflow
            
        Returns:
            Direction √† prendre
        """
        if state.get("use_case_success", False):
            return "success"
        
        if state.get("use_case_iteration", 0) >= state.get("max_use_case_iterations", 3):
            return "max_iterations"
        
        return "continue"
    
    def _save_use_case_results(self, state: WorkflowState) -> None:
        """
        Sauvegarde les r√©sultats des cas d'usage dans le dossier outputs.
        
        Args:
            state: √âtat final du workflow
        """
        try:
            from datetime import datetime
            # Sauvegarde des cas d'usage finaux
            results = {
                "final_quick_wins": state.get("final_quick_wins", []),
                "final_structuration_ia": state.get("final_structuration_ia", []),
                "use_case_success": state.get("use_case_success", False),
                "use_case_iteration": state.get("use_case_iteration", 0),
                "timestamp": datetime.now().isoformat(),
                # Inclure aussi les besoins pour r√©f√©rence
                "source_needs": state.get("final_needs", [])
            }
            
            # Sauvegarde en JSON
            output_path = "/home/addeche/aiko/aikoGPT/outputs/use_case_analysis_results.json"
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(results, f, ensure_ascii=False, indent=2)
            
            print(f"üíæ [DEBUG] R√©sultats sauvegard√©s dans {output_path}")
            
        except Exception as e:
            print(f"‚ùå Erreur sauvegarde use cases: {str(e)}")
    
    def resume_workflow_with_feedback(self, validated_needs: List[Dict[str, Any]], 
                                       rejected_needs: List[Dict[str, Any]], 
                                       user_feedback: str,
                                       thread_id: str) -> Dict[str, Any]:
        """
        Reprend le workflow apr√®s validation humaine avec le feedback.
        NOUVELLE VERSION pour architecture API avec LangGraph checkpointer.
        
        Args:
            validated_needs: Besoins valid√©s par l'utilisateur
            rejected_needs: Besoins rejet√©s par l'utilisateur
            user_feedback: Commentaires de l'utilisateur
            thread_id: ID du thread pour r√©cup√©rer l'√©tat depuis le checkpointer
        
        Returns:
            R√©sultats du workflow
        """
        print(f"\nüîÑ [API] resume_workflow_with_feedback() appel√©")
        print(f"‚úÖ Valid√©s: {len(validated_needs)}")
        print(f"‚ùå Rejet√©s: {len(rejected_needs)}")
        print(f"üí¨ Feedback: {user_feedback[:100] if user_feedback else 'Aucun'}")
        print(f"üîë Thread ID: {thread_id}")
        
        try:
            # Configuration pour r√©cup√©rer l'√©tat depuis le checkpointer
            config = {"configurable": {"thread_id": thread_id}}
            
            # R√©cup√©rer l'√©tat actuel depuis le checkpointer
            snapshot = self.graph.get_state(config)
            state = snapshot.values
            
            print(f"üìä [API] √âtat r√©cup√©r√© depuis le checkpointer")
            print(f"üìä [API] Besoins identifi√©s: {len(state.get('identified_needs', []))}")
            print(f"üìä [API] Besoins d√©j√† valid√©s: {len(state.get('validated_needs', []))}")
            
            # Cr√©er le r√©sultat de validation
            validation_result = {
                "validated_needs": validated_needs,
                "rejected_needs": rejected_needs,
                "user_feedback": user_feedback
            }
            
            # Mettre √† jour l'√©tat avec le feedback de validation
            self.graph.update_state(
                config,
                {
                    "validation_result": validation_result
                }
            )
            
            print(f"‚úÖ [API] √âtat mis √† jour avec le feedback de validation")
            
            # Reprendre l'ex√©cution du workflow
            print(f"‚ñ∂Ô∏è [API] Reprise du workflow...")
            
            final_state = None
            for chunk in self.graph.stream(None, config):
                print(f"üìä [API] Chunk re√ßu: {list(chunk.keys())}")
                for node_name, node_state in chunk.items():
                    print(f"  ‚Ä¢ N≈ìud '{node_name}' ex√©cut√©")
                    final_state = node_state
            
            # R√©cup√©rer l'√©tat final depuis le checkpointer
            snapshot = self.graph.get_state(config)
            state = snapshot.values
            
            print(f"üìä [API] Workflow termin√© ou en pause")
            print(f"üìä [API] Next nodes: {snapshot.next}")
            
            # V√©rifier si le workflow est termin√© ou en pause
            # Note: snapshot.next peut √™tre une liste ou un tuple
            next_nodes = list(snapshot.next) if snapshot.next else []
            
            if len(next_nodes) == 0:
                # Workflow termin√©
                print(f"‚úÖ [API] Workflow termin√© avec succ√®s")
                return {
                    "success": True,
                    "final_needs": state.get("final_needs", []),
                    "summary": {
                        "total_needs": len(state.get("final_needs", [])),
                        "themes": list(set([need.get("theme", "") for need in state.get("final_needs", []) if need.get("theme")])),
                    },
                    "iteration_count": state.get("iteration_count", 0),
                    "workshop_results": state.get("workshop_results", {}),
                    "transcript_results": state.get("transcript_results", []),
                    "web_search_results": state.get("web_search_results", {}),
                    "messages": ["Phase 1 termin√©e - transition vers Phase 2"]
                }
            elif "human_validation" in next_nodes:
                # En attente d'une nouvelle validation
                print(f"‚è∏Ô∏è [API] Workflow en pause - nouvelle validation requise")
                return {
                    "success": False,
                    "workflow_paused": True,
                    "identified_needs": state.get("identified_needs", []),
                    "validated_needs": state.get("validated_needs", []),
                    "final_needs": [],
                    "summary": {
                        "total_needs": 0,
                        "themes": [],
                    },
                    "iteration_count": state.get("iteration_count", 0),
                    "workshop_results": state.get("workshop_results", {}),
                    "transcript_results": state.get("transcript_results", []),
                    "web_search_results": state.get("web_search_results", {}),
                    "messages": ["Nouvelle validation requise"]
                }
            elif "validate_use_cases" in next_nodes:
                # Transition vers validation des use cases
                print(f"‚è∏Ô∏è [API] Workflow en pause - validation des use cases requise")
                return {
                    "success": False,
                    "workflow_paused": True,
                    "use_case_workflow_paused": True,
                    "final_needs": state.get("final_needs", []),
                    "proposed_quick_wins": state.get("proposed_quick_wins", []),
                    "proposed_structuration_ia": state.get("proposed_structuration_ia", []),
                    "summary": {
                        "total_needs": len(state.get("final_needs", [])),
                        "themes": list(set([need.get("theme", "") for need in state.get("final_needs", []) if need.get("theme")])),
                    },
                    "iteration_count": state.get("iteration_count", 0),
                    "workshop_results": state.get("workshop_results", {}),
                    "transcript_results": state.get("transcript_results", []),
                    "web_search_results": state.get("web_search_results", {}),
                    "messages": ["Phase 1 termin√©e - validation des use cases requise"]
                }
            else:
                # Autre cas
                print(f"‚ö†Ô∏è [API] √âtat inattendu: {next_nodes}")
                return {
                    "success": False,
                    "error": f"√âtat inattendu: {next_nodes}",
                    "final_needs": [],
                    "iteration_count": state.get("iteration_count", 0),
                    "messages": [f"√âtat inattendu: {next_nodes}"]
                }
        
        except Exception as e:
            print(f"‚ùå [API] Erreur dans resume_workflow_with_feedback(): {str(e)}")
            import traceback
            traceback.print_exc()
            return {
                "success": False,
                "error": str(e),
                "final_needs": [],
                "iteration_count": 0,
                "messages": [f"Erreur reprise workflow: {str(e)}"]
            }
    
    def resume_use_case_workflow_with_feedback(self, validated_quick_wins: List[Dict[str, Any]],
                                                validated_structuration_ia: List[Dict[str, Any]],
                                                rejected_quick_wins: List[Dict[str, Any]],
                                                rejected_structuration_ia: List[Dict[str, Any]],
                                                user_feedback: str,
                                                thread_id: str) -> Dict[str, Any]:
        """
        Reprend le workflow apr√®s validation des use cases avec le feedback.
        NOUVELLE VERSION pour architecture API avec LangGraph checkpointer.
        
        Args:
            validated_quick_wins: Quick Wins valid√©s
            validated_structuration_ia: Structuration IA valid√©s
            rejected_quick_wins: Quick Wins rejet√©s
            rejected_structuration_ia: Structuration IA rejet√©s
            user_feedback: Commentaires de l'utilisateur
            thread_id: ID du thread pour r√©cup√©rer l'√©tat depuis le checkpointer
        
        Returns:
            R√©sultats finaux du workflow
        """
        print(f"\nüîÑ [API] resume_use_case_workflow_with_feedback() appel√©")
        print(f"‚úÖ Quick Wins valid√©s: {len(validated_quick_wins)}")
        print(f"‚úÖ Structuration IA valid√©s: {len(validated_structuration_ia)}")
        print(f"üîë Thread ID: {thread_id}")
        
        try:
            # Configuration pour r√©cup√©rer l'√©tat depuis le checkpointer
            config = {"configurable": {"thread_id": thread_id}}
            
            # R√©cup√©rer l'√©tat actuel depuis le checkpointer
            snapshot = self.graph.get_state(config)
            state = snapshot.values
            
            print(f"üìä [API] √âtat r√©cup√©r√© depuis le checkpointer")
            print(f"üìä [API] Quick Wins propos√©s: {len(state.get('proposed_quick_wins', []))}")
            print(f"üìä [API] Structuration IA propos√©s: {len(state.get('proposed_structuration_ia', []))}")
            print(f"üìä [API] Quick Wins d√©j√† valid√©s: {len(state.get('validated_quick_wins', []))}")
            print(f"üìä [API] Structuration IA d√©j√† valid√©s: {len(state.get('validated_structuration_ia', []))}")
            
            # Cr√©er le r√©sultat de validation
            validation_result = {
                "validated_quick_wins": validated_quick_wins,
                "validated_structuration_ia": validated_structuration_ia,
                "rejected_quick_wins": rejected_quick_wins,
                "rejected_structuration_ia": rejected_structuration_ia,
                "user_feedback": user_feedback
            }
            
            # Mettre √† jour l'√©tat avec le feedback de validation
            self.graph.update_state(
                config,
                {
                    "use_case_validation_result": validation_result
                }
            )
            
            print(f"‚úÖ [API] √âtat mis √† jour avec le feedback de validation use cases")
            
            # Reprendre l'ex√©cution du workflow
            print(f"‚ñ∂Ô∏è [API] Reprise du workflow use cases...")
            
            final_state = None
            for chunk in self.graph.stream(None, config):
                print(f"üìä [API] Chunk re√ßu: {list(chunk.keys())}")
                for node_name, node_state in chunk.items():
                    print(f"  ‚Ä¢ N≈ìud '{node_name}' ex√©cut√©")
                    final_state = node_state
            
            # R√©cup√©rer l'√©tat final depuis le checkpointer
            snapshot = self.graph.get_state(config)
            state = snapshot.values
            
            print(f"üìä [API] Workflow use cases termin√© ou en pause")
            print(f"üìä [API] Next nodes: {snapshot.next}")
            
            # V√©rifier si le workflow est termin√© ou en pause
            # Note: snapshot.next peut √™tre une liste ou un tuple
            next_nodes = list(snapshot.next) if snapshot.next else []
            
            if len(next_nodes) == 0:
                # Workflow termin√©
                print(f"‚úÖ [API] Workflow use cases termin√© avec succ√®s")
                
                # Affichage du rapport final des co√ªts
                print("\n" + "="*70)
                print("üìä RAPPORT FINAL DES CO√õTS")
                print("="*70)
                self.tracker.print_summary()
                
                # Sauvegarde du rapport de tracking
                report_path = self.tracker.save_report()
                print(f"üìÑ Rapport de co√ªts sauvegard√©: {report_path}\n")
                
                return {
                    "success": True,
                    "final_needs": state.get("final_needs", []),
                    "final_quick_wins": state.get("final_quick_wins", []),
                    "final_structuration_ia": state.get("final_structuration_ia", []),
                    "summary": {
                        "total_needs": len(state.get("final_needs", [])),
                        "total_quick_wins": len(state.get("final_quick_wins", [])),
                        "total_structuration_ia": len(state.get("final_structuration_ia", [])),
                        "themes": list(set([need.get("theme", "") for need in state.get("final_needs", []) if need.get("theme")])),
                    },
                    "iteration_count": state.get("iteration_count", 0),
                    "use_case_iteration": state.get("use_case_iteration", 0),
                    "workshop_results": state.get("workshop_results", {}),
                    "transcript_results": state.get("transcript_results", []),
                    "web_search_results": state.get("web_search_results", {}),
                    "messages": ["Workflow termin√© avec succ√®s !"]
                }
            elif "validate_use_cases" in next_nodes:
                # En attente d'une nouvelle validation use cases
                print(f"‚è∏Ô∏è [API] Workflow en pause - nouvelle validation use cases requise")
                return {
                    "success": False,
                    "use_case_workflow_paused": True,
                    "final_needs": state.get("final_needs", []),
                    "proposed_quick_wins": state.get("proposed_quick_wins", []),
                    "proposed_structuration_ia": state.get("proposed_structuration_ia", []),
                    "validated_quick_wins": state.get("validated_quick_wins", []),
                    "validated_structuration_ia": state.get("validated_structuration_ia", []),
                    "summary": {
                        "total_needs": len(state.get("final_needs", [])),
                        "themes": list(set([need.get("theme", "") for need in state.get("final_needs", []) if need.get("theme")])),
                    },
                    "iteration_count": state.get("iteration_count", 0),
                    "use_case_iteration": state.get("use_case_iteration", 0),
                    "workshop_results": state.get("workshop_results", {}),
                    "transcript_results": state.get("transcript_results", []),
                    "web_search_results": state.get("web_search_results", {}),
                    "messages": ["Nouvelle validation use cases requise"]
                }
            else:
                # Autre cas
                print(f"‚ö†Ô∏è [API] √âtat inattendu: {next_nodes}")
                return {
                    "success": False,
                    "error": f"√âtat inattendu: {next_nodes}",
                    "final_needs": [],
                    "final_quick_wins": [],
                    "final_structuration_ia": [],
                    "iteration_count": state.get("iteration_count", 0),
                    "use_case_iteration": state.get("use_case_iteration", 0),
                    "messages": [f"√âtat inattendu: {next_nodes}"]
                }
        
        except Exception as e:
            print(f"‚ùå [API] Erreur dans resume_use_case_workflow_with_feedback(): {str(e)}")
            import traceback
            traceback.print_exc()
            return {
                "success": False,
                "error": str(e),
                "final_needs": [],
                "final_quick_wins": [],
                "final_structuration_ia": [],
                "iteration_count": 0,
                "use_case_iteration": 0,
                "messages": [f"Erreur reprise workflow use cases: {str(e)}"]
            }
    
    # Fonction resume_use_case_workflow supprim√©e - √©tait sp√©cifique √† Streamlit
    def resume_use_case_workflow_removed(self) -> Dict[str, Any]:
        """
        FONCTION SUPPRIM√âE - √©tait sp√©cifique √† Streamlit.
        La validation humaine se fait maintenant via l'API FastAPI.
        """
        return {
            "success": False,
            "error": "Fonction supprim√©e - utilisez l'API FastAPI pour la validation",
            "final_quick_wins": [],
            "final_structuration_ia": [],
            "messages": ["Fonction obsol√®te"]
        }
    
    # ==================== FIN DU NETTOYAGE STREAMLIT ====================
