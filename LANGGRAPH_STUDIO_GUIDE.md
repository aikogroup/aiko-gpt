# Guide LangGraph Studio

## üöÄ D√©marrage rapide

### 1. Pr√©parer l'environnement
```bash
./setup_langgraph.sh
```

### 2. Lancer LangGraph Studio
```bash
uv run langgraph dev --allow-blocking
```

### 3. Ouvrir l'interface
Ouvrez votre navigateur : **http://127.0.0.1:2024**

> **Note** : Votre API FastAPI utilise le port 2025, LangGraph Studio utilise le port 2024

---

## üìä Utilisation avec vos documents

### Option A : Chemins de fichiers (recommand√©)

Dans l'interface LangGraph Studio, configurez l'√©tat initial avec :

```json
{
  "workshop_files": [
    "/home/addeche/aiko/aikoGPT/inputs/atelier_exemple.xlsx"
  ],
  "transcript_files": [
    "/home/addeche/aiko/aikoGPT/inputs/-Cousin-Biotech-x-aiko-Echange-Production-b04e9caa-d79c.pdf",
    "/home/addeche/aiko/aikoGPT/inputs/-Cousin-x-aiko-Echange-Equipe-Technique-64264037-0daa.pdf"
  ],
  "company_info": {
    "company_name": "Cousin Biotech",
    "sector": "M√©dical",
    "size": "50-100 employ√©s"
  }
}
```

### Option B : Donn√©es pr√©-trait√©es (d√©mo rapide)

Si vous avez d√©j√† ex√©cut√© le workflow une fois, vous pouvez passer directement les r√©sultats :

```json
{
  "workshop_results": {...},
  "transcript_results": [...],
  "web_search_results": {...}
}
```

---

## üîç Fonctionnalit√©s de LangGraph Studio

### Visualisation du workflow
- Graph interactif montrant tous les n≈ìuds
- Fl√®ches indiquant le flux de donn√©es
- N≈ìuds conditionnels avec leurs branches

### Inspection des donn√©es
- **Par n≈ìud** : Cliquez sur un n≈ìud pour voir son √©tat
- **Input/Output** : Voyez ce qui entre et sort de chaque n≈ìud
- **Tokens** : Compteurs de tokens affich√©s par n≈ìud (si tracker activ√©)

### Debugging
- **Points d'interruption** : Pause entre les n≈ìuds
- **Time travel** : Revenez √† un √©tat pr√©c√©dent
- **Replay** : Rejouez le workflow depuis n'importe quel point

### Logs en temps r√©el
- Chaque n≈ìud affiche ses logs
- Progression visible
- Erreurs mises en √©vidence

---

## üéØ Structure du workflow

```
start_agents (parall√®le)
‚îú‚îÄ Workshop Agent (Excel)    ‚Üí‚îê
‚îú‚îÄ Transcript Agent (PDFs)    ‚Üí‚îú‚Üí collect_data
‚îî‚îÄ Web Search Agent (API)     ‚Üí‚îò
                                 ‚Üì
                          analyze_needs
                                 ‚Üì
                          human_validation
                                 ‚Üì
                          check_success
                          /     |      \
                    continue  success  max_iterations
                       ‚Üì        ‚Üì          ‚Üì
                analyze_needs  finalize   END
```

---

## ‚öôÔ∏è Configuration avanc√©e

### Modifier les points d'interruption

Dans `workflow/need_analysis_workflow.py` ligne 237 :

```python
compile_kwargs["interrupt_before"] = ["analyze_needs", "human_validation"]
compile_kwargs["interrupt_after"] = ["start_agents", "collect_data"]
```

### D√©sactiver le mode debug

Dans `graph_factory.py` ligne 29 :

```python
workflow = NeedAnalysisWorkflow(
    api_key=api_key,
    dev_mode=False,    # Mode production
    debug_mode=False   # Pas de checkpointing
)
```

---

## ‚ùì FAQ

### Pourquoi `--allow-blocking` ?

Le projet utilise des op√©rations de fichiers (mkdir, save_report) qui sont bloquantes dans un contexte ASGI. Le flag permet de les utiliser en d√©veloppement.

**Solutions alternatives :**
1. Convertir en async (meilleure approche long terme)
2. Utiliser `asyncio.to_thread()` pour les I/O
3. D√©sactiver le token tracking en mode debug

### Les fichiers doivent-ils √™tre sur le serveur ?

Oui, pour l'instant les chemins de fichiers doivent √™tre accessibles depuis le serveur LangGraph. Une future am√©lioration pourrait ajouter un upload via l'interface.

### Comment voir les tokens consomm√©s ?

Les statistiques de tokens s'affichent :
1. Dans les logs du terminal
2. Dans l'√©tat du workflow (cl√© `tracker_stats`)
3. Dans les fichiers `outputs/token_tracking/*.json`

### Puis-je tester sans fichiers ?

Oui ! Activez le mode `dev_mode=True` qui utilise des donn√©es mock√©es. Les r√©sultats viennent de `need_analysis_results_mock.json`.

---

## üêõ D√©pannage

### Le serveur ne d√©marre pas
```bash
# V√©rifier que le port 2024 est libre
lsof -i :2024

# Si occup√©, tuer le processus
kill -9 <PID>
```

**Architecture des ports :**
- Port **2024** : LangGraph Studio (visualisation/debug)
- Port **2025** : Votre API FastAPI (Streamlit/production)

### Erreur "Blocking call"
V√©rifiez que vous utilisez bien `--allow-blocking` :
```bash
uv run langgraph dev --allow-blocking
```

### Erreur "OPENAI_API_KEY not found"
Cr√©ez un fichier `.env` :
```bash
echo "OPENAI_API_KEY=votre_cle_api" > .env
```

---

## üìö Ressources

- [Documentation LangGraph](https://langchain-ai.github.io/langgraph/)
- [LangGraph Studio](https://github.com/langchain-ai/langgraph-studio)
- [Documentation LangChain](https://python.langchain.com/)

