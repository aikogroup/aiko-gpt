"""
Agent pour extraire la chaÃ®ne de valeur de l'entreprise
"""
import logging
from typing import List, Dict, Any
import openai
import os
from dotenv import load_dotenv

from models.value_chain_models import (
    TeamsResponse,
    ActivitiesResponse,
    FrictionPointsResponse,
    Team,
    Activity,
    FrictionPoint
)
from prompts.value_chain_prompts import (
    VALUE_CHAIN_TEAMS_SYSTEM_PROMPT,
    VALUE_CHAIN_TEAMS_PROMPT,
    VALUE_CHAIN_ACTIVITIES_SYSTEM_PROMPT,
    VALUE_CHAIN_ACTIVITIES_PROMPT,
    VALUE_CHAIN_FRICTION_POINTS_SYSTEM_PROMPT,
    VALUE_CHAIN_FRICTION_POINTS_PROMPT
)

# Charger les variables d'environnement
load_dotenv()

logger = logging.getLogger(__name__)


class ValueChainAgent:
    """Agent pour extraire la chaÃ®ne de valeur depuis les transcriptions et web search"""
    
    def __init__(self, api_key: str = None):
        """Initialise l'agent avec la clÃ© API OpenAI"""
        if api_key:
            openai.api_key = api_key
        else:
            openai.api_key = os.getenv("OPENAI_API_KEY")
        
        self.model = 'gpt-4.1-nano-2025-04-14'
    
    def extract_teams(
        self,
        interventions: List[Dict[str, Any]],
        company_info: Dict[str, Any]
    ) -> TeamsResponse:
        """
        Extrait les Ã©quipes (mÃ©tier et support) depuis les interventions
        
        Args:
            interventions: Liste des interventions enrichies depuis la DB
            company_info: Informations sur l'entreprise depuis web search (pour contexte uniquement)
            
        Returns:
            TeamsResponse avec les Ã©quipes identifiÃ©es
        """
        if not interventions:
            logger.warning("Aucune intervention fournie")
            return TeamsResponse(teams=[])
        
        # PrÃ©parer le texte pour l'analyse
        transcript_text = self._format_interventions(interventions)
        company_info_text = self._format_company_info(company_info)
        
        # Appeler le LLM pour extraire les Ã©quipes
        prompt = VALUE_CHAIN_TEAMS_PROMPT.format(
            transcript_text=transcript_text,
            company_info=company_info_text
        )
        
        try:
            response = openai.responses.parse(
                model=self.model,
                instructions=VALUE_CHAIN_TEAMS_SYSTEM_PROMPT,
                input=[
                    {
                        "role": "user",
                        "content": [
                            {
                                "type": "input_text",
                                "text": prompt
                            }
                        ]
                    }
                ],
                text_format=TeamsResponse
            )
            
            teams_response = response.output_parsed
            logger.info(f"Extrait {len(teams_response.teams)} Ã©quipes")
            return teams_response
            
        except Exception as e:
            logger.error(f"Erreur lors de l'extraction des Ã©quipes: {e}")
            return TeamsResponse(teams=[])
    
    def extract_activities(
        self,
        interventions: List[Dict[str, Any]],
        teams: List[Team]
    ) -> ActivitiesResponse:
        """
        Extrait les activitÃ©s pour chaque Ã©quipe validÃ©e
        
        Args:
            interventions: Liste des interventions enrichies depuis la DB
            teams: Liste des Ã©quipes validÃ©es
            
        Returns:
            ActivitiesResponse avec une phrase rÃ©sumÃ© par Ã©quipe
        """
        if not interventions or not teams:
            logger.warning("Aucune intervention ou Ã©quipe fournie")
            return ActivitiesResponse(activities=[])
        
        # PrÃ©parer le texte pour l'analyse
        transcript_text = self._format_interventions(interventions)
        teams_text = self._format_teams(teams)
        
        # Appeler le LLM pour extraire les activitÃ©s
        prompt = VALUE_CHAIN_ACTIVITIES_PROMPT.format(
            transcript_text=transcript_text,
            teams=teams_text
        )
        
        try:
            response = openai.responses.parse(
                model=self.model,
                instructions=VALUE_CHAIN_ACTIVITIES_SYSTEM_PROMPT,
                input=[
                    {
                        "role": "user",
                        "content": [
                            {
                                "type": "input_text",
                                "text": prompt
                            }
                        ]
                    }
                ],
                text_format=ActivitiesResponse
            )
            
            activities_response = response.output_parsed
            logger.info(f"Extrait {len(activities_response.activities)} activitÃ©s")
            return activities_response
            
        except Exception as e:
            logger.error(f"Erreur lors de l'extraction des activitÃ©s: {e}")
            return ActivitiesResponse(activities=[])
    
    def extract_friction_points(
        self,
        interventions: List[Dict[str, Any]],
        teams: List[Team]
    ) -> FrictionPointsResponse:
        """
        Extrait les points de friction liÃ©s Ã  la gestion des donnÃ©es pour chaque Ã©quipe
        
        Args:
            interventions: Liste des interventions enrichies depuis la DB
            teams: Liste des Ã©quipes validÃ©es
            
        Returns:
            FrictionPointsResponse avec les points de friction identifiÃ©s
        """
        if not interventions or not teams:
            logger.warning("Aucune intervention ou Ã©quipe fournie")
            return FrictionPointsResponse(friction_points=[])
        
        # LOGS DÃ‰TAILLÃ‰S - DÃ©but
        logger.info(f"ðŸ” [FRICTION] DÃ©but extraction points de friction")
        logger.info(f"ðŸ” [FRICTION] Nombre d'interventions: {len(interventions)}")
        logger.info(f"ðŸ” [FRICTION] Nombre d'Ã©quipes validÃ©es: {len(teams)}")
        
        # Afficher les noms des Ã©quipes
        team_names = [team.nom for team in teams]
        logger.info(f"ðŸ” [FRICTION] Noms des Ã©quipes validÃ©es: {team_names}")
        
        # Statistiques sur les interventions
        if interventions:
            interventions_with_role = sum(1 for i in interventions if i.get("speaker_role"))
            interventions_with_level = sum(1 for i in interventions if i.get("speaker_level"))
            logger.info(f"ðŸ” [FRICTION] Interventions avec rÃ´le: {interventions_with_role}/{len(interventions)}")
            logger.info(f"ðŸ” [FRICTION] Interventions avec niveau: {interventions_with_level}/{len(interventions)}")
            
            # AperÃ§u des premiÃ¨res interventions
            logger.info(f"ðŸ” [FRICTION] AperÃ§u des 3 premiÃ¨res interventions:")
            for i, interv in enumerate(interventions[:3], 1):
                text_preview = interv.get("text", "")[:100] + "..." if len(interv.get("text", "")) > 100 else interv.get("text", "")
                role = interv.get("speaker_role", "N/A")
                level = interv.get("speaker_level", "N/A")
                logger.info(f"   {i}. [niveau={level}|rÃ´le={role}] {text_preview}")
        
        # PrÃ©parer le texte pour l'analyse
        transcript_text = self._format_interventions(interventions)
        teams_text = self._format_teams(teams)
        
        # Logs sur les donnÃ©es formatÃ©es
        logger.info(f"ðŸ” [FRICTION] Longueur transcript_text formatÃ©: {len(transcript_text)} caractÃ¨res")
        logger.info(f"ðŸ” [FRICTION] AperÃ§u transcript_text (premiers 500 caractÃ¨res): {transcript_text[:500]}...")
        logger.info(f"ðŸ” [FRICTION] Teams_text formatÃ©:\n{teams_text}")
        
        # Appeler le LLM pour extraire les points de friction
        prompt = VALUE_CHAIN_FRICTION_POINTS_PROMPT.format(
            transcript_text=transcript_text,
            teams=teams_text
        )
        
        logger.info(f"ðŸ” [FRICTION] Longueur prompt final: {len(prompt)} caractÃ¨res")
        logger.info(f"ðŸ” [FRICTION] ModÃ¨le utilisÃ©: {self.model}")
        # LOGS DÃ‰TAILLÃ‰S - Fin
        
        try:
            response = openai.responses.parse(
                model=self.model,
                instructions=VALUE_CHAIN_FRICTION_POINTS_SYSTEM_PROMPT,
                input=[
                    {
                        "role": "user",
                        "content": [
                            {
                                "type": "input_text",
                                "text": prompt
                            }
                        ]
                    }
                ],
                text_format=FrictionPointsResponse
            )
            
            friction_points_response = response.output_parsed
            logger.info(f"Extrait {len(friction_points_response.friction_points)} points de friction")
            
            # Log dÃ©taillÃ© des points de friction extraits
            if friction_points_response.friction_points:
                logger.info(f"ðŸ” [FRICTION] DÃ©tail des points de friction extraits:")
                for fp in friction_points_response.friction_points:
                    logger.info(f"   - ID: {fp.id}, Team: {fp.team_nom}, Citation: {fp.citation[:100]}...")
            else:
                logger.warning(f"ðŸ” [FRICTION] âš ï¸ Aucun point de friction extrait par le LLM")
            
            return friction_points_response
            
        except Exception as e:
            logger.error(f"Erreur lors de l'extraction des points de friction: {e}")
            logger.error(f"ðŸ” [FRICTION] âŒ Exception dÃ©taillÃ©e: {type(e).__name__}: {str(e)}")
            return FrictionPointsResponse(friction_points=[])
    
    def _format_interventions(self, interventions: List[Dict[str, Any]]) -> str:
        """Formate les interventions pour l'analyse LLM avec mÃ©tadonnÃ©es enrichies"""
        formatted = []
        
        for intervention in interventions:
            text = intervention.get("text", "")
            speaker_level = intervention.get("speaker_level", "")
            speaker_role = intervention.get("speaker_role", "")
            
            # Construire un prÃ©fixe informatif avec role et level
            metadata_parts = []
            if speaker_level:
                metadata_parts.append(f"niveau={speaker_level}")
            if speaker_role:
                metadata_parts.append(f"rÃ´le={speaker_role}")
            
            if metadata_parts:
                prefix = "[" + "|".join(metadata_parts) + "]"
                formatted.append(f"{prefix} {text}")
            else:
                formatted.append(text)
        
        return "\n\n".join(formatted)
    
    def _format_company_info(self, company_info: Dict[str, Any]) -> str:
        """Formate les informations de l'entreprise"""
        if not company_info:
            return "Aucune information disponible."
        
        formatted = []
        
        # Nom de l'entreprise
        if "nom" in company_info:
            formatted.append(f"**Nom**: {company_info['nom']}")
        
        # Description
        if "description" in company_info:
            formatted.append(f"**Description**: {company_info['description']}")
        
        # Secteur
        if "secteur" in company_info:
            formatted.append(f"**Secteur**: {company_info['secteur']}")
        
        # Chiffre d'affaires
        if "chiffre_affaires" in company_info:
            formatted.append(f"**Chiffre d'affaires**: {company_info['chiffre_affaires']}")
        
        # Nombre d'employÃ©s
        if "nombre_employes" in company_info:
            formatted.append(f"**Nombre d'employÃ©s**: {company_info['nombre_employes']}")
        
        return "\n".join(formatted) if formatted else "Aucune information disponible."
    
    def _format_teams(self, teams: List[Team]) -> str:
        """Formate les Ã©quipes pour l'analyse"""
        if not teams:
            return "Aucune Ã©quipe disponible."
        
        formatted = []
        for team in teams:
            formatted.append(
                f"- **ID: {team.id}** - **{team.nom}** ({team.type}): {team.description}"
            )
        
        return "\n".join(formatted)

