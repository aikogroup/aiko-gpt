# üß† Projet ‚Äì Refonte LangGraph SDK

---

# üìñ 1. CONTEXTE

## üéØ Objectif g√©n√©ral

Nous repartons **de z√©ro** pour reconstruire un projet propre, modulaire et document√©, bas√© sur **LangGraph SDK** comme moteur d'orchestration et d'analyse.

### Pourquoi ce projet ?

Le projet pr√©c√©dent utilisait une **API maison** complexe et difficile √† maintenir. Nous voulons :
- Remplacer cette API par **LangGraph SDK**, un framework moderne et puissant pour orchestrer des agents IA
- Cr√©er un **frontend Next.js** moderne, r√©actif et intuitif
- Structurer un **backend Python** clair o√π **LangGraph g√®re toute la logique m√©tier**
- Faciliter la maintenance et l'√©volution future du code

> ‚ö†Ô∏è L'ancien code sera d√©plac√© dans un dossier `/OLD` pour r√©f√©rence temporaire, puis supprim√© √† la fin du projet.

## üß© Logique m√©tier du projet

### Donn√©es d'entr√©e

L'application prend en entr√©e trois types de sources :

1. **Fichier Excel** (ateliers)
   - Colonne A : nom de l'atelier
   - Colonne B : cas d'usage
   - Colonne C : objectif ou gain

2. **Fichiers PDF et/ou JSON** (transcriptions, feedbacks)
   - Citations des utilisateurs
   - Frustrations exprim√©es
   - Besoins identifi√©s

3. **Nom d'entreprise**
   - Pour recherche contextuelle via Perplexity
   - Informations sur le secteur, la taille, les actualit√©s

### Traitement

Ces sources sont analys√©es par **LangGraph** √† travers un workflow orchestr√© d'agents IA qui :
- Parsent et structurent les donn√©es
- Extraient les informations cl√©s
- G√©n√®rent du contenu analytique

### Donn√©es de sortie

Le syst√®me produit :

1. **10 besoins** par it√©ration
   - Titre clair r√©sumant l'apport
   - 5 citations issues des fichiers sources (Excel + PDF/JSON)
   - √âditables et s√©lectionnables par l'utilisateur

2. **Cas d'usage** en deux cat√©gories
   - **Quick Wins** : projets simples, ROI rapide (< 3 mois)
   - **Structuration IA** : projets ambitieux, ROI moyen/long terme (3-12 mois)
   - Chaque cas d'usage contient : titre, description, technologies IA

3. **Rapport Word final**
   - Compile les besoins et cas d'usage s√©lectionn√©s
   - T√©l√©chargeable depuis l'interface

---

# ‚öôÔ∏è 2. STACK TECHNIQUE

| Composant | Technologie | Version / D√©tails |
| --- | --- | --- |
| **Frontend** | Next.js + TypeScript | Framework React moderne |
| **Backend** | Python | Langage principal backend |
| **Orchestration** | **LangGraph SDK** | ‚≠ê C≈ìur du projet - gestion des agents |
| **LLM** | OpenAI API | Mod√®le configurable via `.env` |
| **Web Search** | Perplexity API | Recherche contextuelle entreprise |
| **Environnement Python** | UV | Gestionnaire de d√©pendances moderne |
| **Variables d'environnement** | `.env` | Cl√©s API, configuration |
| **Conteneurisation** | Docker Desktop + Docker Compose | D√©ploiement et ex√©cution |
| **Langue du code** | Anglais | Conventions internationales |
| **Commentaires** | Fran√ßais | Pour faciliter la collaboration |

### Choix technologiques cl√©s

- **LangGraph SDK** : obligatoire, g√®re 100% de la logique m√©tier
- **Next.js** : interface moderne avec routing int√©gr√©
- **UV** : environnement Python plus rapide que pip/venv
- **Docker** : garantit la reproductibilit√© et facilite le d√©ploiement

# üõ†Ô∏è 3. OUTILS

## LangGraph SDK ‚≠ê

**LangGraph SDK** est le moteur central du backend et le c≈ìur de l'intelligence du projet.

### R√¥le principal

LangGraph permet de :
- **Orchestrer** plusieurs agents (Workshop, Transcript, WebSearch, NeedAnalysis, UseCase, Report)
- **G√©rer le flux de donn√©es** entre les agents (cha√Ænage automatique des entr√©es/sorties)
- **D√©finir des workflows** logiques d'analyse pilot√©s par le LLM
- **Centraliser la logique m√©tier** sans d√©pendre d'un framework API classique

### Pourquoi LangGraph ?

‚úÖ **Modularit√©** : chaque agent est isol√© et testable  
‚úÖ **Maintenabilit√©** : la logique m√©tier est s√©par√©e de l'API  
‚úÖ **√âvolutivit√©** : facile d'ajouter de nouveaux agents  
‚úÖ **Tra√ßabilit√©** : suivi du flux de donn√©es entre agents

> üìö **Ressource** : Utiliser DeepWiki pour approfondir la ma√Ætrise de LangGraph SDK

## OpenAI API

- **Mod√®le** : Configurable via `.env` (ex: `gpt-4`, `gpt-5-nano`)
- **Usage** : Analyse des documents, g√©n√©ration de besoins et cas d'usage
- **R√®gles** : Toujours utiliser l'**OpenAI Response API**, jamais `chat.completion`

## Perplexity API

- **Usage** : Recherche contextuelle sur l'entreprise
- **Donn√©es r√©cup√©r√©es** : secteur, taille, actualit√©s
- **R√®gle importante** : ‚ö†Ô∏è Fournit uniquement le **contexte**, ne g√©n√®re **jamais** de besoins

## Outils de d√©veloppement

| Outil | Usage |
| --- | --- |
| **UV** | Gestionnaire d'environnement Python moderne |
| **Docker Desktop** | Conteneurisation et ex√©cution locale |
| **ESLint + Prettier** | Linting et formatage frontend |
| **mypy** | Typage strict Python (PEP8) |

---

# üìä 4. DATA

## Structure des donn√©es

### Fichier Excel (Workshop)

**Format d'entr√©e :**
```
| Colonne A          | Colonne B           | Colonne C              |
|--------------------|---------------------|------------------------|
| Nom de l'atelier   | Cas d'usage         | Objectif ou gain       |
```

**Traitement :**
- Parsing des 3 colonnes
- Extraction des cas d'usage initiaux
- Analyse LLM pour structuration

**R√©f√©rences code existant :**
- `process_atelier/workshop_agent.py` (lignes 56-94 parsing, 134-181 analyse)
- Prompts : `prompts/workshop_agent_prompts.py`
- Workflow : `workflow/need_analysis_workflow.py` ligne 332

### Fichiers PDF/JSON (Transcripts)

**Contenu :**
- Citations d'utilisateurs
- Frustrations exprim√©es
- Besoins identifi√©s lors d'ateliers

**Traitement :**
- Parsing PDF et JSON
- Extraction de citations cl√©s
- Filtrage s√©mantique via LLM

**R√©f√©rences code existant :**
- Fichier principal : `process_transcript/transcript_agent.py`
- Parsers : `pdf_parser.py` et `json_parser.py`
- Analyse LLM : `semantic_filter_agent.py` (ligne 80)
- Prompts : `prompts/transcript_agent_prompts.py`
- Workflow : `workflow/need_analysis_workflow.py` ligne 356

### Nom d'entreprise (Web Search)

**Entr√©e :** Nom de l'entreprise (texte libre)

**Traitement :**
- Recherche Perplexity (lignes 69-75)
- Contexte additionnel OpenAI (lignes 121-137)

**Sortie :**
- Secteur d'activit√©
- Taille de l'entreprise
- Actualit√©s r√©centes

**R√©f√©rences code existant :**
- `web_search/web_search_agent.py`
- Prompts : `prompts/web_search_agent_prompts.py`
- Workflow : `workflow/need_analysis_workflow.py` ligne 375

‚ö†Ô∏è **R√àGLE CRITIQUE** : Web Search = **CONTEXTE uniquement**, ne g√©n√®re **JAMAIS** de besoins

### Besoins g√©n√©r√©s (Needs)

**Structure d'un besoin :**
```json
{
  "id": "need_001",
  "title": "Titre clair r√©sumant l'apport",
  "citations": [
    "Citation 1 - Source: Atelier X",
    "Citation 2 - Source: Transcript Y",
    "Citation 3 - Source: Atelier Z",
    "Citation 4 - Source: Transcript W",
    "Citation 5 - Source: Atelier V"
  ],
  "selected": false,
  "edited": false
}
```

**R√®gles de g√©n√©ration :**
- **10 besoins** par it√©ration
- Citations issues de **Workshop + Transcript** (sources principales)
- Web Search = contexte uniquement
- Pas de citations sans source (√©viter "- Transcript" g√©n√©rique)
- Th√®mes uniques (pas de doublons)

**Prompts associ√©s :**
- System Prompt : `prompts/need_analysis_agent_prompts.py` lignes 5-74
- User Prompt initial : lignes 76-101
- User Prompt r√©g√©n√©ration : lignes 113-179

**Agent responsable :** `NeedAnalysisAgent`

**Entr√©es :**
- `workshop_data` (Excel) ‚Üí cas d'usage, objectifs, b√©n√©fices
- `transcript_data` (PDF/JSON) ‚Üí besoins exprim√©s, frustrations, citations
- `web_search_data` (Perplexity) ‚Üí ‚ö†Ô∏è CONTEXTE uniquement

### Cas d'usage g√©n√©r√©s (Use Cases)

**Deux cat√©gories :**

#### 1. Quick Wins (8 g√©n√©r√©s)
- Projets simples √† mettre en ≈ìuvre
- Automatisation rapide
- ROI imm√©diat (< 3 mois)

#### 2. Structuration IA (10 g√©n√©r√©s)
- Solutions avanc√©es et ambitieuses
- Projets structurants
- ROI moyen/long terme (3-12 mois)

**Structure d'un cas d'usage :**
```json
{
  "id": "uc_qw_001",
  "category": "quick_win",
  "title": "Titre clair et concis",
  "description": "Description du projet",
  "ai_technologies": ["LLM", "RAG", "OCR", "ML supervis√©"],
  "selected": false
}
```

**R√®gles de g√©n√©ration :**
- Technologies IA concr√®tes et pertinentes
- Titres uniques (pas de doublons)
- Si ‚â• 5 valid√©s dans une cat√©gorie ‚Üí ne r√©g√©n√®re rien pour cette cat√©gorie

**Prompts associ√©s :**
- System Prompt : `prompts/use_case_analysis_prompts.py` lignes 5-50
- User Prompt initial : lignes 52-77
- User Prompt r√©g√©n√©ration : lignes 79-127

**Agent responsable :** `UseCaseAnalysisAgent`

**Entr√©es :**
- `validated_needs` ‚Üí Besoins valid√©s √† la page 2 (minimum 5)
- `workshop_data`, `transcript_data`, `web_search_data` ‚Üí Contexte

### Rapport Word final

**Contenu :**
- Besoins s√©lectionn√©s (titre + citations)
- Cas d'usage retenus (titre + description + technologies IA)
- Mise en forme professionnelle

**R√©f√©rences code existant :**
- `utils/report_generator.py` (lignes 163-189)

---

# üìÅ 5. FICHIERS

## Arborescence compl√®te

```
root/
‚îÇ
‚îú‚îÄ‚îÄ .env                          # Variables d'environnement (cl√©s API, mod√®le LLM)
‚îú‚îÄ‚îÄ .env.example                  # Template pour .env
‚îú‚îÄ‚îÄ .gitignore                    # Fichiers √† exclure du repo
‚îú‚îÄ‚îÄ docker-compose.yml            # Configuration Docker
‚îú‚îÄ‚îÄ README.md                     # Documentation principale du projet
‚îÇ
‚îú‚îÄ‚îÄ OLD/                          # üì¶ Code de l'ancien projet (temporaire)
‚îÇ   ‚îî‚îÄ‚îÄ [ancien code √† d√©placer]
‚îÇ
‚îú‚îÄ‚îÄ backend/                      # üêç Backend Python + LangGraph
‚îÇ   ‚îú‚îÄ‚îÄ main.py                   # Point d'entr√©e, initialisation LangGraph
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ api/                      # Routes HTTP (couche technique uniquement)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ routes.py             # /upload, /run, /report
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ process_atelier/          # Module : analyse fichier Excel
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ workshop_agent.py     # Agent LangGraph pour Excel
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ process_transcript/       # Module : analyse PDF/JSON
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ transcript_agent.py   # Agent principal
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ pdf_parser.py         # Parser PDF
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ json_parser.py        # Parser JSON
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ semantic_filter_agent.py  # Filtrage LLM
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ web_search/               # Module : recherche entreprise
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ web_search_agent.py   # Perplexity + OpenAI
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ need_analysis/            # Module : g√©n√©ration besoins
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ need_analysis_agent.py
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ use_case_analysis/        # Module : g√©n√©ration cas d'usage
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ use_case_analysis_agent.py
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ prompts/                  # üìù Tous les prompts LLM
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ workshop_agent_prompts.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ transcript_agent_prompts.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ web_search_agent_prompts.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ need_analysis_agent_prompts.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ use_case_analysis_prompts.py
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ workflow/                 # üîÑ Workflows LangGraph
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ need_analysis_workflow.py  # Graphe d'ex√©cution principal
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ utils/                    # üõ†Ô∏è Utilitaires
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ report_generator.py   # G√©n√©ration Word
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ token_tracker.py      # Suivi tokens (optionnel)
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ models/                   # üìê Mod√®les de donn√©es (Pydantic)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ need_analysis_models.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ use_case_analysis_models.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ web_search_models.py
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt          # D√©pendances Python (ou pyproject.toml avec UV)
‚îÇ
‚îî‚îÄ‚îÄ frontend/                     # üíª Frontend Next.js + TypeScript
    ‚îú‚îÄ‚îÄ package.json              # D√©pendances Node.js
    ‚îú‚îÄ‚îÄ tsconfig.json             # Configuration TypeScript
    ‚îú‚îÄ‚îÄ next.config.js            # Configuration Next.js
    ‚îú‚îÄ‚îÄ .eslintrc.json            # Configuration ESLint
    ‚îÇ
    ‚îú‚îÄ‚îÄ public/                   # Assets statiques
    ‚îÇ   ‚îî‚îÄ‚îÄ logoAiko.jpeg         # Logo entreprise
    ‚îÇ
    ‚îî‚îÄ‚îÄ src/
        ‚îú‚îÄ‚îÄ app/                  # Pages Next.js (App Router)
        ‚îÇ   ‚îú‚îÄ‚îÄ layout.tsx        # Layout principal
        ‚îÇ   ‚îú‚îÄ‚îÄ page.tsx          # Page 1 : Accueil (upload)
        ‚îÇ   ‚îÇ
        ‚îÇ   ‚îú‚îÄ‚îÄ needs/            # Page 2 : Besoins
        ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ page.tsx
        ‚îÇ   ‚îÇ
        ‚îÇ   ‚îú‚îÄ‚îÄ usecases/         # Page 3 : Cas d'usage
        ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ page.tsx
        ‚îÇ   ‚îÇ
        ‚îÇ   ‚îî‚îÄ‚îÄ results/          # Page 4 : R√©sultats
        ‚îÇ       ‚îî‚îÄ‚îÄ page.tsx
        ‚îÇ
        ‚îú‚îÄ‚îÄ components/           # Composants r√©utilisables
        ‚îÇ   ‚îú‚îÄ‚îÄ UploadZone.tsx    # Zone d'upload fichiers
        ‚îÇ   ‚îú‚îÄ‚îÄ NeedCard.tsx      # Carte besoin
        ‚îÇ   ‚îú‚îÄ‚îÄ UseCaseCard.tsx   # Carte cas d'usage
        ‚îÇ   ‚îú‚îÄ‚îÄ SideNav.tsx       # Navigation lat√©rale
        ‚îÇ   ‚îî‚îÄ‚îÄ Spinner.tsx       # Loader
        ‚îÇ
        ‚îú‚îÄ‚îÄ lib/                  # Logique m√©tier frontend
        ‚îÇ   ‚îú‚îÄ‚îÄ api-client.ts     # Appels API backend
        ‚îÇ   ‚îú‚îÄ‚îÄ store.ts          # State management (Zustand)
        ‚îÇ   ‚îî‚îÄ‚îÄ schemas.ts        # Types TypeScript
        ‚îÇ
        ‚îî‚îÄ‚îÄ styles/               # Styles globaux
            ‚îî‚îÄ‚îÄ globals.css
```

## Description des modules backend

### `backend/main.py` ‚≠ê

**R√¥le :** Point d'entr√©e du backend, initialise LangGraph

```python
# TODO (FR):
# Initialiser LangGraph ici
# - Charger les agents et leurs prompts
# - D√©finir les connexions :
#   Workshop ‚Üí Transcript ‚Üí WebSearch ‚Üí NeedAnalysis ‚Üí UseCase ‚Üí Report
# - (Optionnel) Exposer 3 routes techniques :
#   /api/upload, /api/run, /api/report
# - Ne pas inclure de logique m√©tier dans ces routes
```

### `process_atelier/workshop_agent.py`

**R√¥le :** Agent LangGraph pour analyser le fichier Excel

**Entr√©e :** Fichier Excel (ateliers)
- Colonne A : nom de l'atelier
- Colonne B : cas d'usage
- Colonne C : objectif ou gain

**Traitement :**
- Parsing des 3 colonnes
- Extraction et structuration via LLM

**R√©f√©rences code existant :**
- Lignes 56-94 : parsing Excel
- Lignes 134-181 : analyse LLM

**Prompts :** `prompts/workshop_agent_prompts.py`

**Workflow :** `workflow/need_analysis_workflow.py` ligne 332

### `process_transcript/`

**R√¥le :** Module pour analyser fichiers PDF/JSON (transcriptions)

**Fichiers :**
- `transcript_agent.py` : agent principal
- `pdf_parser.py` : extraction texte PDF
- `json_parser.py` : parsing JSON
- `semantic_filter_agent.py` : filtrage LLM (ligne 80)

**Entr√©e :** Fichiers PDF et/ou JSON

**Traitement :**
- Extraction de citations
- Identification des frustrations
- Filtrage s√©mantique

**Prompts :** `prompts/transcript_agent_prompts.py`

**Workflow :** `workflow/need_analysis_workflow.py` ligne 356

### `web_search/web_search_agent.py`

**R√¥le :** Recherche contextuelle sur l'entreprise

**Entr√©e :** Nom de l'entreprise

**Traitement :**
- Recherche Perplexity (lignes 69-75)
- Contexte additionnel OpenAI (lignes 121-137)

**Sortie :**
- Secteur d'activit√©
- Taille de l'entreprise
- Actualit√©s r√©centes

‚ö†Ô∏è **R√àGLE CRITIQUE :** Fournit uniquement le **CONTEXTE**, ne g√©n√®re **JAMAIS** de besoins

**Prompts :** `prompts/web_search_agent_prompts.py`

**Workflow :** `workflow/need_analysis_workflow.py` ligne 375

### `need_analysis/need_analysis_agent.py`

**R√¥le :** Agent LangGraph pour g√©n√©rer les besoins

**Entr√©es :**
- `workshop_data` ‚Üí cas d'usage, objectifs, b√©n√©fices
- `transcript_data` ‚Üí besoins exprim√©s, frustrations, citations
- `web_search_data` ‚Üí contexte (secteur, taille) ‚ö†Ô∏è PAS de besoins

**Sortie :** 10 besoins (titre + 5 citations)

**R√®gles :**
- Citations issues de Workshop + Transcript (sources PRINCIPALES)
- Web Search = contexte uniquement
- Pas de citations sans source
- Th√®mes uniques (pas de doublons)

**Prompts :** `prompts/need_analysis_agent_prompts.py`
- Lignes 5-74 : System Prompt (toujours utilis√©)
- Lignes 76-101 : User Prompt (1√®re it√©ration)
- Lignes 113-179 : User Prompt (r√©g√©n√©ration)

### `use_case_analysis/use_case_analysis_agent.py`

**R√¥le :** Agent LangGraph pour g√©n√©rer les cas d'usage

**Entr√©es :**
- `validated_needs` ‚Üí Besoins valid√©s page 2 (minimum 5)
- `workshop_data`, `transcript_data`, `web_search_data` ‚Üí Contexte

**Sortie :**
- 8 Quick Wins (ROI < 3 mois)
- 10 Structuration IA (ROI 3-12 mois)

**R√®gles :**
- Technologies IA concr√®tes (LLM, RAG, OCR, ML, etc.)
- Titres uniques
- Si ‚â• 5 valid√©s dans une cat√©gorie ‚Üí ne r√©g√©n√®re rien

**Prompts :** `prompts/use_case_analysis_prompts.py`
- Lignes 5-50 : System Prompt
- Lignes 52-77 : User Prompt (1√®re it√©ration)
- Lignes 79-127 : User Prompt (r√©g√©n√©ration)

### `workflow/need_analysis_workflow.py`

**R√¥le :** D√©finit la s√©quence d'ex√©cution LangGraph

**Workflow :**
1. Combine `workshop_data`, `transcript_data`, `web_search_data`
2. Produit `needs` ‚Üí `use_cases` ‚Üí `report`

### `utils/report_generator.py`

**R√¥le :** G√©n√®re le document Word final

**Contenu :**
- Besoins s√©lectionn√©s (titre + citations)
- Cas d'usage retenus (titre + description + technologies)
- Mise en forme professionnelle

**R√©f√©rences code existant :** lignes 163-189

### `prompts/` (Dossier)

**Contenu :** Tous les prompts LLM versionn√©s

**Fichiers :**
- `workshop_agent_prompts.py`
- `transcript_agent_prompts.py`
- `web_search_agent_prompts.py`
- `need_analysis_agent_prompts.py`
- `use_case_analysis_prompts.py`

**Avantages :**
- Centralisation
- Versioning facile
- It√©ration rapide sur les prompts

## Description des pages frontend

### Page 1 : Accueil (Upload) - `app/page.tsx`

**Objectif :** Collecter toutes les donn√©es d'entr√©e

**√âl√©ments :**
- Logo entreprise (en haut √† gauche)
- Navbar (pages du site)
- Zone d'upload fichier Excel
- Zone d'upload fichiers PDF/JSON (multi-fichiers)
- Champ texte : nom de l'entreprise
- Bouton "Analyser" ‚Üí lance `/api/run`

**TODOs :**
- Cr√©er composant `UploadZone` multi-fichiers
- Validation formats (`.xlsx`, `.pdf`, `.json`)
- Loader pendant l'analyse
- Appel API `/api/run` pour lancer le graphe LangGraph
- Stocker r√©sultats dans state global (Context API ou Zustand)

### Page 2 : Besoins - `app/needs/page.tsx`

**Objectif :** Afficher, √©diter et s√©lectionner les 10 besoins g√©n√©r√©s

**√âl√©ments :**
- Liste de 10 besoins (cartes)
- Chaque besoin :
  - Checkbox (s√©lection)
  - Titre √©ditable
  - 5 citations (Excel + PDF/JSON)
- Besoins s√©lectionn√©s remontent en haut
- Champ commentaire (consignes pour r√©g√©n√©ration)
- Bouton "G√©n√©rer" ‚Üí g√©n√®re de nouveaux besoins diff√©rents
- Bouton "Valider" ‚Üí passe √† page 3 (cas d'usage)

**TODOs :**
- Composant `NeedCard` (titre, citations, checkbox)
- Mise √† jour temps r√©el du state
- Bouton G√©n√©rer ‚Üí POST `/api/run` (exclusion besoins pr√©c√©dents)
- Bouton Valider ‚Üí navigation `/usecases`

**Prompts associ√©s :** `prompts/need_analysis_agent_prompts.py`

### Page 3 : Cas d'usage - `app/usecases/page.tsx`

**Objectif :** G√©n√©rer et s√©lectionner les cas d'usage

**√âl√©ments :**
- Section **Quick Wins** (8 cas d'usage)
- Section **Structuration IA** (10 cas d'usage)
- Chaque cas d'usage :
  - Bouton s√©lection
  - Titre
  - Description
  - Technologies IA (LLM, RAG, OCR, etc.)
- Champ commentaire
- Bouton "G√©n√©rer" ‚Üí compl√®te cat√©gories manquantes
- Bouton "Valider" ‚Üí passe √† page 4 (r√©sultats)

**R√®gle intelligente :** Si ‚â• 5 valid√©s dans une cat√©gorie ‚Üí ne r√©g√©n√®re rien

**TODOs :**
- Composants `QuickWinCard` et `StructurationCard`
- Gestion √©tat s√©lectionn√©
- Appel `/api/run` pour r√©g√©n√©ration
- Navigation `/results` apr√®s validation

**Prompts associ√©s :** `prompts/use_case_analysis_prompts.py`

### Page 4 : R√©sultats - `app/results/page.tsx`

**Objectif :** Synth√®se et t√©l√©chargement rapport Word

**√âl√©ments :**
- Liste besoins valid√©s
- Liste cas d'usage retenus
- Bouton "T√©l√©charger" ‚Üí appel `/api/report`

**TODOs :**
- Affichage dynamique √©l√©ments s√©lectionn√©s
- Feedback visuel t√©l√©chargement
- Relier √† `utils/report_generator.py`

**R√©f√©rences code existant :**
- `utils/report_generator.py` (lignes 163-189)
- `frontend/src/app/results/page.tsx` (lignes 89-104)

## Fichiers de configuration

### `.env`

**Contenu obligatoire :**
```bash
# OpenAI API
OPENAI_API_KEY=sk-...
OPENAI_MODEL=gpt-4  # ou gpt-5-nano selon les r√®gles

# Perplexity API
PERPLEXITY_API_KEY=pplx-...

# LangGraph configuration
LANGGRAPH_API_URL=...

# Autres variables
ENVIRONMENT=development
```

### `.env.example`

Template du fichier `.env` sans valeurs sensibles, √† versionner dans Git.

### `.gitignore`

**Doit exclure :**
```gitignore
# Environnement
.env
.venv/
venv/
*.pyc
__pycache__/

# Node modules
node_modules/
.next/

# Logs
*.log

# Docker volumes
volumes/

# IDE
.vscode/
.idea/

# OS
.DS_Store
Thumbs.db

# Outputs temporaires
outputs/
temp/
```

### `docker-compose.yml`

**Structure :**
- Service `backend` (Python + LangGraph)
- Service `frontend` (Next.js)
- Volumes pour persistance si n√©cessaire
- Network pour communication inter-services

### `README.md`

**Sections obligatoires :**
1. Description du projet
2. Pr√©requis (Docker Desktop, UV)
3. Installation
4. Commande de lancement : `docker compose up --build`
5. Architecture g√©n√©rale
6. Flux LangGraph
7. Conventions de qualit√© (code anglais, commentaires fran√ßais, typage)

---

# üèóÔ∏è 6. ARCHITECTURE

## Vue d'ensemble

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                         FRONTEND                            ‚îÇ
‚îÇ                      Next.js + TypeScript                   ‚îÇ
‚îÇ                                                             ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ  Upload  ‚îÇ‚Üí‚îÇ  Besoins ‚îÇ‚Üí‚îÇ Use Cases‚îÇ‚Üí‚îÇ R√©sultats‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  (Page1) ‚îÇ  ‚îÇ (Page2)  ‚îÇ  ‚îÇ (Page3)  ‚îÇ  ‚îÇ (Page4)  ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                                                             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                          ‚îÇ HTTP API
                          ‚îÇ /api/upload, /api/run, /api/report
                          ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                         BACKEND                             ‚îÇ
‚îÇ                   Python + LangGraph SDK                    ‚îÇ
‚îÇ                                                             ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ              LANGGRAPH WORKFLOW                      ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                                                       ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê             ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ Workshop    ‚îÇ      ‚îÇ Transcript   ‚îÇ             ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ Agent       ‚îÇ      ‚îÇ Agent        ‚îÇ             ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ (Excel)     ‚îÇ      ‚îÇ (PDF/JSON)   ‚îÇ             ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò             ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ         ‚îÇ                    ‚îÇ                      ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                      ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                  ‚îÇ                                   ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                        ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ         ‚îÇ  Web Search      ‚îÇ                        ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ         ‚îÇ  Agent           ‚îÇ                        ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ         ‚îÇ  (Perplexity)    ‚îÇ                        ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                        ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                  ‚îÇ                                   ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                       ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ         ‚îÇ  Need Analysis    ‚îÇ                       ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ         ‚îÇ  Agent            ‚îÇ                       ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ         ‚îÇ  (10 besoins)     ‚îÇ                       ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                       ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                  ‚îÇ                                   ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                       ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ         ‚îÇ  UseCase Analysis ‚îÇ                       ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ         ‚îÇ  Agent            ‚îÇ                       ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ         ‚îÇ  (QW + SIA)       ‚îÇ                       ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                       ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                  ‚îÇ                                   ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                       ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ         ‚îÇ  Report Agent     ‚îÇ                       ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ         ‚îÇ  (Word doc)       ‚îÇ                       ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                       ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                                                             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                          ‚îÇ
                          ‚Üì
                  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                  ‚îÇ   EXTERNAL    ‚îÇ
                  ‚îÇ   SERVICES    ‚îÇ
                  ‚îÇ               ‚îÇ
                  ‚îÇ - OpenAI API  ‚îÇ
                  ‚îÇ - Perplexity  ‚îÇ
                  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## Flux de donn√©es d√©taill√©

### √âtape 1 : Upload (Frontend ‚Üí Backend)

1. Utilisateur upload fichiers (Excel, PDF/JSON) + nom entreprise
2. Frontend envoie √† `/api/upload`
3. Backend stocke temporairement les fichiers
4. Retourne confirmation au frontend

### √âtape 2 : Analyse initiale (Backend LangGraph)

Frontend appelle `/api/run` avec param√®tres :
- `action: "generate_needs"`
- `files_ids: [...]`
- `company_name: "..."`

**LangGraph execute :**

```
WorkshopAgent (Excel)
    ‚Üì
    Extrait : ateliers, cas d'usage, objectifs
    ‚Üì
TranscriptAgent (PDF/JSON)
    ‚Üì
    Extrait : citations, frustrations
    ‚Üì
WebSearchAgent (Perplexity)
    ‚Üì
    R√©cup√®re : secteur, taille, actualit√©s
    ‚Üì
NeedAnalysisAgent
    ‚Üì
    G√©n√®re : 10 besoins (titre + 5 citations)
    ‚Üì
Retour Frontend : { needs: [...] }
```

### √âtape 3 : R√©g√©n√©ration besoins (optionnel)

Frontend appelle `/api/run` avec :
- `action: "regenerate_needs"`
- `excluded_needs: [...]`  (besoins non retenus)
- `comment: "..."`  (instructions utilisateur)

**LangGraph execute :**
- Utilise le prompt de r√©g√©n√©ration
- G√©n√®re 10 nouveaux besoins **diff√©rents** des pr√©c√©dents

### √âtape 4 : G√©n√©ration cas d'usage

Frontend appelle `/api/run` avec :
- `action: "generate_use_cases"`
- `validated_needs: [...]`  (minimum 5)

**LangGraph execute :**

```
UseCaseAnalysisAgent
    ‚Üì
    Input : validated_needs + workshop_data + transcript_data + web_search_data
    ‚Üì
    G√©n√®re : 8 Quick Wins + 10 Structuration IA
    ‚Üì
Retour Frontend : { quick_wins: [...], structuration_ia: [...] }
```

### √âtape 5 : R√©g√©n√©ration cas d'usage (optionnel)

Frontend appelle `/api/run` avec :
- `action: "regenerate_use_cases"`
- `validated_quick_wins: [...]`
- `validated_structuration_ia: [...]`
- `comment: "..."`

**R√®gle intelligente :**
- Si `validated_quick_wins.length >= 5` ‚Üí ne r√©g√©n√®re **rien** pour QW
- Si `validated_structuration_ia.length >= 5` ‚Üí ne r√©g√©n√®re **rien** pour SIA
- Sinon, g√©n√®re pour compl√©ter

### √âtape 6 : G√©n√©ration rapport Word

Frontend appelle `/api/report` avec :
- `validated_needs: [...]`
- `validated_use_cases: [...]`

**Backend execute :**

```
ReportAgent
    ‚Üì
    Input : needs + use_cases
    ‚Üì
    G√©n√®re document Word format√©
    ‚Üì
Retour Frontend : fichier .docx en t√©l√©chargement
```

## Principes architecturaux

### S√©paration des responsabilit√©s

| Composant | Responsabilit√© |
| --- | --- |
| **Frontend** | Interface utilisateur, validation inputs, navigation |
| **API Backend** | Routes HTTP, upload/download fichiers |
| **LangGraph** | **100% de la logique m√©tier** (analyse, g√©n√©ration) |
| **Prompts** | Instructions LLM, versionn√©es et isol√©es |

### Architecture LangGraph

**LangGraph** g√®re :
- ‚úÖ Orchestration des agents
- ‚úÖ Flux de donn√©es entre agents
- ‚úÖ Logique conditionnelle (r√©g√©n√©ration, etc.)
- ‚úÖ Gestion des erreurs

**API Backend** g√®re :
- ‚úÖ Upload de fichiers
- ‚úÖ D√©clenchement du graphe LangGraph
- ‚úÖ T√©l√©chargement du rapport

‚ö†Ô∏è **R√àGLE IMPORTANTE** : L'API ne contient **AUCUNE** logique m√©tier, seulement des appels √† LangGraph

### Agents LangGraph

| Agent | Input | Output | LLM ? |
| --- | --- | --- | --- |
| **WorkshopAgent** | Fichier Excel | `workshop_data` (dict) | ‚úÖ |
| **TranscriptAgent** | Fichiers PDF/JSON | `transcript_data` (list) | ‚úÖ |
| **WebSearchAgent** | Nom entreprise | `web_search_data` (dict) | ‚úÖ |
| **NeedAnalysisAgent** | `workshop_data` + `transcript_data` + `web_search_data` | `needs` (list[10]) | ‚úÖ |
| **UseCaseAnalysisAgent** | `validated_needs` + contexte | `use_cases` (dict) | ‚úÖ |
| **ReportAgent** | `needs` + `use_cases` | Fichier `.docx` | ‚ùå |

### Bonnes pratiques LangGraph

1. **Chaque agent = une responsabilit√©**
   - Parsing OU analyse, pas les deux

2. **Input/Output explicites**
   - Utiliser Pydantic pour typage strict

3. **Prompts versionn√©s**
   - Fichiers s√©par√©s dans `/prompts`
   - Commentaires fran√ßais explicites

4. **Testabilit√©**
   - Chaque agent doit √™tre testable isol√©ment

---

# üîß 7. STRUCTURE (√âtapes de d√©veloppement)

## √âtape 1 : Mise en place initiale ‚úÖ

**Objectif :** Cr√©er la structure compl√®te du projet vide avec TODOs

**Actions :**
1. D√©placer ancien code dans `/OLD`
2. Cr√©er arborescence compl√®te (dossiers backend + frontend)
3. Cr√©er fichiers vides avec TODOs en fran√ßais
4. Cr√©er fichiers de configuration :
   - `.gitignore`
   - `.env.example`
   - `docker-compose.yml`
   - `README.md`

**Validation :** Structure compl√®te visible, projet s'ouvre dans IDE

---

## √âtape 2 : Configuration Docker

**Objectif :** Projet lance avec `docker compose up --build`

**Actions :**
1. Dockerfile backend (Python + UV)
2. Dockerfile frontend (Next.js)
3. docker-compose.yml fonctionnel
4. Variables `.env` charg√©es correctement

**Validation :** `docker compose up` lance sans erreur

---

## √âtape 3 : Frontend initial (pages vides)

**Objectif :** Navigation entre les 4 pages fonctionne

**Actions :**
1. Page 1 : Accueil (layout + logo + navbar)
2. Page 2 : Besoins (vide)
3. Page 3 : Cas d'usage (vide)
4. Page 4 : R√©sultats (vide)
5. Composant `SideNav` fonctionnel

**Validation :** Navigation fluide entre pages

---

## √âtape 4 : LangGraph - Agents de base

**Objectif :** Agents LangGraph fonctionnels (sans logique)

**Actions :**
1. Initialiser LangGraph dans `main.py`
2. Cr√©er agents vides :
   - WorkshopAgent
   - TranscriptAgent
   - WebSearchAgent
   - NeedAnalysisAgent
   - UseCaseAnalysisAgent
   - ReportAgent
3. D√©finir workflow de base
4. Tester appel simple

**Validation :** Workflow s'execute sans erreur

---

## √âtape 5 : Parsers (Excel, PDF, JSON)

**Objectif :** Extraire donn√©es des fichiers

**Actions :**
1. Impl√©menter `workshop_agent.py` (parser Excel)
2. Impl√©menter `pdf_parser.py`
3. Impl√©menter `json_parser.py`
4. Tester avec fichiers exemples

**Validation :** Donn√©es extraites correctement

---

## √âtape 6 : Web Search Agent

**Objectif :** R√©cup√©rer contexte entreprise

**Actions :**
1. Int√©grer API Perplexity
2. Int√©grer OpenAI pour contexte additionnel
3. Tester avec noms d'entreprises r√©elles

**Validation :** Donn√©es pertinentes r√©cup√©r√©es

---

## √âtape 7 : Need Analysis Agent

**Objectif :** G√©n√©rer 10 besoins avec citations

**Actions :**
1. Impl√©menter prompts (System, User initial, User r√©g√©n√©ration)
2. Connecter aux donn√©es (workshop, transcript, web_search)
3. Tester g√©n√©ration initiale
4. Tester r√©g√©n√©ration avec exclusions

**Validation :** 10 besoins g√©n√©r√©s avec citations valides

---

## √âtape 8 : Frontend Page 2 (Besoins)

**Objectif :** Interface compl√®te pour besoins

**Actions :**
1. Composant `NeedCard`
2. √âtat global (Zustand)
3. Boutons G√©n√©rer / Valider
4. Champ commentaire

**Validation :** Interaction fluide, r√©g√©n√©ration fonctionne

---

## √âtape 9 : UseCase Analysis Agent

**Objectif :** G√©n√©rer Quick Wins + Structuration IA

**Actions :**
1. Impl√©menter prompts
2. Logique r√©g√©n√©ration intelligente (>= 5 valid√©s)
3. Tester g√©n√©ration et r√©g√©n√©ration

**Validation :** Cas d'usage pertinents g√©n√©r√©s

---

## √âtape 10 : Frontend Page 3 (Use Cases)

**Objectif :** Interface compl√®te pour cas d'usage

**Actions :**
1. Composants `QuickWinCard` et `StructurationCard`
2. Gestion √©tat s√©lectionn√©
3. Boutons G√©n√©rer / Valider

**Validation :** S√©lection et r√©g√©n√©ration fonctionnent

---

## √âtape 11 : Report Generator

**Objectif :** G√©n√©ration document Word final

**Actions :**
1. Impl√©menter `report_generator.py`
2. Template Word professionnel
3. Int√©grer besoins et cas d'usage s√©lectionn√©s

**Validation :** Document Word t√©l√©chargeable et bien format√©

---

## √âtape 12 : Frontend Page 4 (R√©sultats)

**Objectif :** Synth√®se et t√©l√©chargement

**Actions :**
1. Affichage besoins valid√©s
2. Affichage cas d'usage retenus
3. Bouton t√©l√©chargement rapport

**Validation :** Rapport se t√©l√©charge correctement

---

## √âtape 13 : Polissage et tests

**Objectif :** Projet production-ready

**Actions :**
1. Gestion des erreurs
2. Feedbacks visuels (loaders, messages)
3. Tests unitaires agents
4. Documentation README compl√®te

**Validation :** Projet stable et document√©

---

# ‚úÖ 8. QUALIT√â ET STANDARDS

## Principes g√©n√©raux

### üåç Conventions linguistiques

| √âl√©ment | Langue |
| --- | --- |
| **Code** (variables, fonctions, classes) | üá¨üáß **Anglais** |
| **Commentaires** | üá´üá∑ **Fran√ßais** |
| **Documentation** (README, TODO) | üá´üá∑ **Fran√ßais** |
| **Messages de commit** | üá´üá∑ **Fran√ßais** |

**Exemple :**
```python
# FR: Fonction qui g√©n√®re des besoins √† partir des donn√©es d'atelier
def generate_needs_from_workshop(workshop_data: dict) -> list:
    """
    FR: G√©n√®re une liste de besoins √† partir des donn√©es d'atelier
    
    Args:
        workshop_data: Dictionnaire contenant les donn√©es pars√©es du fichier Excel
        
    Returns:
        Liste de 10 besoins avec titre et citations
    """
    # FR: Extraction des cas d'usage de la colonne B
    use_cases = workshop_data.get("use_cases", [])
    
    # FR: TODO - Impl√©menter la logique de g√©n√©ration
    pass
```

---

## Standards Backend (Python)

### üêç PEP8 et Typage

‚úÖ **Obligatoire :**
- Respect strict de la **PEP8** (formatage, nommage, structure)
- **Typage strict** avec `mypy` pour toutes les fonctions
- Utilisation de **Pydantic** pour les mod√®les de donn√©es

**Exemple :**
```python
from pydantic import BaseModel
from typing import List, Dict, Optional

# FR: Mod√®le pour un besoin g√©n√©r√©
class Need(BaseModel):
    id: str
    title: str
    citations: List[str]
    selected: bool = False
    edited: bool = False

# FR: Fonction typ√©e strictement
def parse_excel_file(file_path: str) -> Dict[str, any]:
    """FR: Parse un fichier Excel et retourne les donn√©es structur√©es"""
    # FR: Logique de parsing
    pass
```

### üì¶ Structure des modules

‚úÖ **R√®gles :**
- Un module = une responsabilit√© claire
- Fichiers `__init__.py` avec exports explicites
- Maximum 300 lignes par fichier (si plus, d√©couper)

### üîß Gestion des erreurs

‚úÖ **Obligatoire :**
```python
import logging

logger = logging.getLogger(__name__)

# FR: Gestion des erreurs avec contexte clair
try:
    result = parse_pdf(file_path)
except FileNotFoundError:
    logger.error(f"FR: Fichier PDF introuvable : {file_path}")
    raise
except Exception as e:
    logger.error(f"FR: Erreur lors du parsing PDF : {str(e)}")
    raise
```

### üß™ Tests

‚úÖ **Recommand√© :**
- Tests unitaires pour chaque agent
- Tests des parsers avec fichiers exemples
- Tests d'int√©gration du workflow LangGraph

---

## Standards Frontend (Next.js + TypeScript)

### üìê TypeScript strict

‚úÖ **Obligatoire :**
```typescript
// FR: Interface pour un besoin
interface Need {
  id: string;
  title: string;
  citations: string[];
  selected: boolean;
  edited: boolean;
}

// FR: Props typ√©es pour composant
interface NeedCardProps {
  need: Need;
  onSelect: (id: string) => void;
  onEdit: (id: string, newTitle: string) => void;
}

// FR: Composant avec typage strict
const NeedCard: React.FC<NeedCardProps> = ({ need, onSelect, onEdit }) => {
  // FR: Logique du composant
};
```

### üé® ESLint + Prettier

‚úÖ **Configuration :**
- ESLint avec r√®gles React/Next.js
- Prettier pour formatage automatique
- Pre-commit hooks (optionnel)

### üß© Structure des composants

‚úÖ **R√®gles :**
- Composants fonctionnels avec Hooks
- Props clairement typ√©es
- Composants r√©utilisables dans `/components`
- Logique m√©tier dans `/lib`

**Exemple :**
```typescript
// FR: Composant r√©utilisable pour carte de besoin
export const NeedCard: React.FC<NeedCardProps> = ({ need, onSelect }) => {
  // FR: √âtat local pour √©dition
  const [isEditing, setIsEditing] = useState(false);
  
  // FR: Gestion de la s√©lection
  const handleSelect = () => {
    onSelect(need.id);
  };
  
  return (
    <div className="need-card">
      {/* FR: Interface carte besoin */}
    </div>
  );
};
```

---

## Standards LangGraph

### üß† Agents

‚úÖ **Chaque agent doit avoir :**

1. **Un r√¥le unique et clair**
   ```python
   # FR: Agent responsable uniquement de la g√©n√©ration de besoins
   class NeedAnalysisAgent:
       """FR: G√©n√®re 10 besoins √† partir des donn√©es combin√©es"""
       pass
   ```

2. **Input/Output explicites**
   ```python
   # FR: Input typ√© avec Pydantic
   class NeedAnalysisInput(BaseModel):
       workshop_data: Dict[str, any]
       transcript_data: List[Dict[str, any]]
       web_search_data: Dict[str, any]
   
   # FR: Output typ√©
   class NeedAnalysisOutput(BaseModel):
       needs: List[Need]
   ```

3. **Prompts versionn√©s**
   - Fichiers s√©par√©s dans `/prompts`
   - Commentaires fran√ßais explicites
   - Historique des modifications

4. **Logging complet**
   ```python
   logger.info("FR: D√©but g√©n√©ration besoins")
   logger.debug(f"FR: Donn√©es workshop : {len(workshop_data)} ateliers")
   logger.info("FR: G√©n√©ration besoins termin√©e : 10 besoins cr√©√©s")
   ```

### üîÑ Workflows

‚úÖ **R√®gles :**
- Workflow centralis√© dans `/workflow`
- Cha√Ænage explicite des agents
- Gestion des erreurs √† chaque √©tape
- √âtat partag√© clair entre agents

---

## Standards Docker

### üê≥ Dockerfile

‚úÖ **Bonnes pratiques :**
- Images officielles l√©g√®res (`python:3.11-slim`, `node:20-alpine`)
- Multi-stage builds si possible
- `.dockerignore` pour exclure fichiers inutiles
- Variables d'environnement via `.env`

**Exemple Backend :**
```dockerfile
# FR: Image de base Python
FROM python:3.11-slim

# FR: Installation UV
RUN pip install uv

# FR: Copie des d√©pendances
COPY requirements.txt .
RUN uv pip install -r requirements.txt

# FR: Copie du code source
COPY . /app
WORKDIR /app

# FR: Commande de d√©marrage
CMD ["python", "main.py"]
```

### üîß docker-compose.yml

‚úÖ **Structure :**
```yaml
version: '3.8'

services:
  # FR: Service backend Python + LangGraph
  backend:
    build: ./backend
    ports:
      - "8000:8000"
    env_file:
      - .env
    volumes:
      - ./backend:/app
    networks:
      - app-network

  # FR: Service frontend Next.js
  frontend:
    build: ./frontend
    ports:
      - "3000:3000"
    env_file:
      - .env
    depends_on:
      - backend
    networks:
      - app-network

networks:
  app-network:
    driver: bridge
```

---

## Standards Git

### üìù Messages de commit

‚úÖ **Format :**
```
[TYPE] Description courte en fran√ßais

Description d√©taill√©e si n√©cessaire
```

**Types :**
- `[FEAT]` : Nouvelle fonctionnalit√©
- `[FIX]` : Correction de bug
- `[REFACTOR]` : Refactorisation
- `[DOCS]` : Documentation
- `[STYLE]` : Formatage, style
- `[TEST]` : Tests

**Exemples :**
```
[FEAT] Ajout du NeedAnalysisAgent avec prompts de r√©g√©n√©ration
[FIX] Correction du parsing Excel pour colonnes vides
[REFACTOR] S√©paration du code de parsing et d'analyse dans WorkshopAgent
```

### üåø Branches

‚úÖ **Convention :**
- `main` : code stable
- `develop` : d√©veloppement actif
- `feature/nom-feature` : nouvelle fonctionnalit√©
- `fix/nom-bug` : correction bug

---

## Checklist Qualit√©

### ‚úÖ Backend

- [ ] Code en anglais, commentaires en fran√ßais
- [ ] Typage strict avec mypy
- [ ] PEP8 respect√©
- [ ] Mod√®les Pydantic pour donn√©es
- [ ] Logging complet
- [ ] Gestion erreurs explicite
- [ ] Tests unitaires agents
- [ ] Prompts versionn√©s

### ‚úÖ Frontend

- [ ] Code TypeScript strict
- [ ] Props typ√©es
- [ ] ESLint + Prettier configur√©s
- [ ] Composants r√©utilisables
- [ ] State management clair (Zustand)
- [ ] Gestion erreurs API
- [ ] Feedbacks visuels (loaders, messages)

### ‚úÖ Docker

- [ ] Dockerfiles optimis√©s
- [ ] docker-compose.yml fonctionnel
- [ ] `.env` non versionn√©
- [ ] `.env.example` pr√©sent
- [ ] `.dockerignore` configur√©

### ‚úÖ Documentation

- [ ] README.md complet
- [ ] Installation claire
- [ ] Commande lancement : `docker compose up --build`
- [ ] Architecture expliqu√©e
- [ ] Flux LangGraph document√©
- [ ] Conventions de code pr√©cis√©es

### ‚úÖ S√©curit√©

- [ ] Aucune cl√© API hardcod√©e
- [ ] `.env` dans `.gitignore`
- [ ] Variables sensibles via environnement
- [ ] Validation inputs utilisateur

---

## üéØ Mission Imm√©diate

### Objectif √âtape 1 ‚úÖ

**Cr√©er la structure compl√®te du projet** avec :

1. **Dossiers :**
   - `/backend` avec tous les modules
   - `/frontend` avec structure Next.js
   - `/OLD` pour ancien code

2. **Fichiers de configuration :**
   - `.gitignore`
   - `.env.example`
   - `docker-compose.yml`
   - `README.md`

3. **Fichiers Python/TypeScript vides avec TODOs d√©taill√©s en fran√ßais**

4. **Documentation initiale**

### Validation

- ‚úÖ Structure visible dans l'IDE
- ‚úÖ Fichiers de config pr√©sents
- ‚úÖ TODOs clairs et actionnables
- ‚úÖ README avec instructions de d√©marrage

---

> üéØ **Mission pour Cursor**  
> 
> G√©n√©rer la **structure compl√®te du projet** selon les directives ci-dessus.  
> 
> **R√®gles imp√©ratives :**
> - Code en **anglais**, commentaires en **fran√ßais**
> - **LangGraph SDK** obligatoire, g√®re 100% de la logique m√©tier
> - Fichiers avec **TODOs explicites** en fran√ßais
> - Architecture **modulaire** et **testable**
> - Documentation **compl√®te** d√®s le d√©part
> 
> **Prochaines √©tapes :**
> 1. Valider la structure
> 2. Impl√©menter Docker
> 3. Cr√©er le frontend (pages vides)
> 4. Impl√©menter les agents LangGraph √©tape par √©tape
> 
> L'objectif est de poser une **base solide** et pr√™te √† √™tre d√©velopp√©e **progressivement**.




