"""
Extracteur de donn√©es depuis un rapport Word g√©n√©r√©
"""

import logging
from typing import Dict, List, Any, Optional
from pathlib import Path
from docx import Document
from openai import OpenAI
import os
from dotenv import load_dotenv
import json
import re
from models.executive_summary_models import WordReportExtraction
from prompts.executive_summary_prompts import WORD_REPORT_EXTRACTION_PROMPT

load_dotenv()

logger = logging.getLogger(__name__)


class WordReportExtractor:
    """Extracteur de donn√©es depuis un rapport Word"""
    
    def __init__(self, api_key: str = None):
        """
        Initialise l'extracteur.
        
        Args:
            api_key: Cl√© API OpenAI (optionnel, utilise OPENAI_API_KEY par d√©faut)
        """
        api_key = api_key or os.getenv("OPENAI_API_KEY")
        if not api_key:
            raise ValueError("OPENAI_API_KEY doit √™tre d√©finie")
        
        self.client = OpenAI(api_key=api_key)
        self.model = os.getenv('OPENAI_MODEL', 'gpt-5-nano')
    
    def extract_from_word(self, word_path: str) -> Dict[str, List[Dict[str, Any]]]:
        """
        Extrait les donn√©es depuis un fichier Word.
        
        Strat√©gie :
        1. Tentative d'extraction JSON directe (m√©tadonn√©es ou structure cach√©e)
        2. Si √©chec : extraction via LLM avec structured output
        
        Args:
            word_path: Chemin vers le fichier Word (.docx)
            
        Returns:
            Dict avec keys: 'final_needs', 'final_use_cases'
        """
        logger.info(f"Extraction depuis Word: {word_path}")
        
        # √âtape 1 : Tentative d'extraction structur√©e (parsing du document)
        extracted_data = self._try_extract_json(word_path)
        if extracted_data:
            logger.info("‚úÖ Extraction structur√©e r√©ussie (parsing direct)")
            return extracted_data
        
        # √âtape 2 : Extraction via LLM (si le parsing √©choue)
        logger.info("‚ö†Ô∏è Extraction structur√©e √©chou√©e, utilisation LLM")
        return self._extract_with_llm(word_path)
    
    def _try_extract_json(self, word_path: str) -> Optional[Dict[str, List[Dict[str, Any]]]]:
        """
        Parse le document Word pour extraire les donn√©es structur√©es.
        
        Cette m√©thode parse le document Word et extrait les besoins et cas d'usage
        bas√©s sur la structure du document :
        - Besoins : lignes commen√ßant par üîπ, avec citations entre ¬´ et ¬ª
        - Cas d'usage : section "LES CAS D'USAGES IA PRIORITAIRES"
          La famille (si pr√©sente) est extraite des titres de famille (style FamilyHeading)
        
        Si l'extraction √©choue ou ne trouve rien, on utilise l'extraction LLM.
        
        Args:
            word_path: Chemin vers le fichier Word
            
        Returns:
            Dict avec 'final_needs', 'final_use_cases'
            ou None si √©chec (on utilisera alors LLM)
        """
        try:
            doc = Document(word_path)
            
            needs = []
            use_cases = []
            
            current_need = None
            current_section = "needs"  # "needs" ou "use_cases"
            current_use_case = None
            current_family = None  # Famille courante pour les use cases
            
            for para in doc.paragraphs:
                text = para.text.strip()
                
                if not text:
                    continue
                
                # --- D√©tection de section ---
                if "LES CAS D'USAGES IA PRIORITAIRES" in text.upper() or "CAS D'USAGES" in text.upper():
                    current_section = "use_cases"
                    current_family = None  # R√©initialiser la famille au d√©but de la section
                    logger.debug("Section 'Cas d'usage' d√©tect√©e")
                    continue
                
                # --- Extraction des besoins ---
                if current_section == "needs":
                    if text.startswith("üîπ"):
                        if current_need:
                            needs.append(current_need)
                        current_need = {"title": text.replace("üîπ", "").strip(), "quotes": []}
                    elif ("‚Ä¢" in text or text.startswith("-")) and current_need:
                        # Retire la puce et espaces
                        clean_text = re.sub(r"^[‚Ä¢\-\s]+", "", text).strip()
                        # Extrait le contenu entre guillemets si pr√©sent
                        match = re.search(r"¬´(.*?)¬ª", clean_text)
                        if match:
                            quote = match.group(1).strip()
                        else:
                            quote = clean_text
                        current_need["quotes"].append(quote)
                    print(f"current_need dans _try_extract_json : {current_need}")
                # --- Extraction des cas d'usage ---
                elif current_section == "use_cases":
                    # D√©tection d'un titre de famille
                    # V√©rifier si c'est un titre de famille (style FamilyHeading ou format sp√©cifique)
                    is_family_heading = False
                    try:
                        # V√©rifier le style du paragraphe
                        style_name = para.style.name if para.style else None
                        if style_name == "FamilyHeading":
                            is_family_heading = True
                    except:
                        pass
                    
                    # V√©rifier aussi si c'est "Autres cas d'usage" (titre de section sans famille)
                    if text == "Autres cas d'usage":
                        current_family = None
                        continue
                    
                    # Si c'est un titre de famille, mettre √† jour current_family
                    if is_family_heading:
                        current_family = text.strip()
                        logger.debug(f"Titre de famille d√©tect√©: {current_family}")
                        continue
                    
                    # Nouveau cas d'usage (num√©ro suivi de titre)
                    if re.match(r"^\d+[\.\)]\s*", text):
                        # Sauvegarder le cas d'usage pr√©c√©dent
                        if current_use_case:
                            use_cases.append(current_use_case)
                        
                        # Extraire le titre
                        title = re.sub(r"^\d+[\.\)]\s*", "", text).strip()
                        current_use_case = {
                            "titre": title,
                            "description": "",
                            "famille": current_family  # Associer la famille courante
                        }
                    # Description du cas d'usage
                    elif (text.startswith("Description :") or text.startswith("Description:")) and current_use_case:
                        description = re.sub(r"^Description\s*:\s*", "", text, flags=re.IGNORECASE).strip()
                        current_use_case["description"] = description
                    # Autre texte pour le cas d'usage actuel
                    elif current_use_case:
                        if current_use_case["description"]:
                            current_use_case["description"] += " " + text
                        else:
                            current_use_case["description"] = text
            
            # Ajouter le dernier besoin et cas d'usage
            if current_need:
                needs.append(current_need)
            if current_use_case:
                use_cases.append(current_use_case)
            
            # Convertir les besoins au format attendu
            final_needs = []
            for need in needs:
                # Construire la description √† partir des quotes et description
                description_parts = []
                if need.get("quotes"):
                    description_parts.extend(need["quotes"])
                if need.get("description"):
                    description_parts.append(need["description"])
                
                final_needs.append({
                    "titre": need.get("title", ""),
                    "description": " ".join(description_parts) if description_parts else ""
                })
            print(f"Final needs de l'extractor : {final_needs}")
            
            # Convertir les cas d'usage (la famille est d√©j√† extraite depuis les titres)
            final_use_cases = []
            for uc in use_cases:
                titre = uc.get("titre", "")
                description = uc.get("description", "")
                famille = uc.get("famille")  # La famille a d√©j√† √©t√© extraite depuis le titre
                
                final_use_cases.append({
                    "titre": titre,
                    "description": description,
                    "famille": famille
                })
            
            # V√©rifier si on a extrait quelque chose
            if final_needs or final_use_cases:
                logger.info(f"‚úÖ Extraction structur√©e r√©ussie: {len(final_needs)} besoins, "
                           f"{len(final_use_cases)} cas d'usage")
                return {
                    "final_needs": final_needs,
                    "final_use_cases": final_use_cases
                }
            else:
                logger.debug("Aucune donn√©e structur√©e trouv√©e, utilisation de l'extraction LLM")
                return None
            
        except Exception as e:
            logger.warning(f"Erreur lors de l'extraction structur√©e: {e}", exc_info=True)
            return None
    
    def _extract_with_llm(self, word_path: str) -> Dict[str, List[Dict[str, Any]]]:
        """
        Extrait les donn√©es via LLM avec structured output.
        
        Args:
            word_path: Chemin vers le fichier Word
            
        Returns:
            Dict avec les donn√©es extraites
        """
        try:
            # Extraire le texte brut du Word
            doc = Document(word_path)
            word_text = "\n".join([paragraph.text for paragraph in doc.paragraphs])
            
            if not word_text.strip():
                logger.warning("Document Word vide")
                return {
                    "final_needs": [],
                    "final_use_cases": []
                }
            
            # Pr√©parer le prompt
            prompt = WORD_REPORT_EXTRACTION_PROMPT.format(word_text=word_text)
            
            # Appel √† l'API avec structured output
            response = self.client.responses.parse(
                model=self.model,
                instructions="Tu es un expert en extraction de donn√©es structur√©es depuis des documents Word.",
                input=[
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                text_format=WordReportExtraction
            )
            
            # Extraire les donn√©es
            extracted_data = response.output_parsed.model_dump()
            
            logger.info(f"‚úÖ Extraction LLM r√©ussie: {len(extracted_data.get('final_needs', []))} besoins, "
                       f"{len(extracted_data.get('final_use_cases', []))} cas d'usage")
            
            return {
                "final_needs": extracted_data.get("final_needs", []),
                "final_use_cases": extracted_data.get("final_use_cases", [])
            }
            
        except Exception as e:
            logger.error(f"Erreur lors de l'extraction LLM: {e}", exc_info=True)
            # Retourner une structure vide en cas d'erreur
            return {
                "final_needs": [],
                "final_use_cases": []
            }

