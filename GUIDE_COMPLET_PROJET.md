# ğŸ“– Guide Complet du Projet aikoGPT

> **Guide technique complet** pour comprendre l'architecture, LangGraph, les agents, et le flux de donnÃ©es

---

## ğŸ“‹ Table des matiÃ¨res

1. [Vue d'ensemble](#vue-densemble)
2. [Architecture GÃ©nÃ©rale](#architecture-gÃ©nÃ©rale)
3. [LangGraph : Le CÅ“ur du Projet](#langgraph--le-cÅ“ur-du-projet)
4. [Les 6 Agents du Workflow](#les-6-agents-du-workflow)
5. [Le State PartagÃ©](#le-state-partagÃ©)
6. [Flux de DonnÃ©es Complet](#flux-de-donnÃ©es-complet)
7. [API Backend](#api-backend)
8. [Frontend Next.js](#frontend-nextjs)
9. [Fichiers ClÃ©s et leur RÃ´le](#fichiers-clÃ©s-et-leur-rÃ´le)

---

## ğŸ¯ Vue d'ensemble

### Objectif du projet

aikoGPT est un **outil d'analyse automatisÃ©e** qui :
1. **Analyse** des fichiers Excel (ateliers) et PDF/JSON (transcriptions)
2. **Recherche** le contexte de l'entreprise via Perplexity
3. **GÃ©nÃ¨re** 10 besoins mÃ©tier avec citations
4. **Propose** des cas d'usage IA (Quick Wins + Structuration)
5. **Produit** un rapport Word tÃ©lÃ©chargeable

### Technologies principales

| Technologie | Version | RÃ´le |
|------------|---------|------|
| **LangGraph SDK** | 0.4.44 | â­ **Orchestration des agents** |
| **OpenAI API** | GPT-4o-mini | Analyse et gÃ©nÃ©ration |
| **Perplexity API** | - | Recherche contextuelle |
| **FastAPI** | - | Serveur HTTP backend |
| **Next.js** | 14.2.33 | Interface utilisateur |
| **Docker** | - | Conteneurisation |

---

## ğŸ—ï¸ Architecture GÃ©nÃ©rale

### SchÃ©ma global

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    FRONTEND (Next.js)                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚  Upload  â”‚â†’ â”‚  Besoins â”‚â†’ â”‚Use Cases â”‚â†’ â”‚RÃ©sultatsâ”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚ HTTP API
                         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              BACKEND (LangGraph Server)                 â”‚
â”‚                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚         LANGGRAPH WORKFLOW (Graphe)             â”‚  â”‚
â”‚  â”‚                                                  â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚  â”‚
â”‚  â”‚  â”‚Workshop  â”‚      â”‚Transcriptâ”‚                â”‚  â”‚
â”‚  â”‚  â”‚Agent     â”‚      â”‚Agent     â”‚                â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜                â”‚  â”‚
â”‚  â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                      â”‚  â”‚
â”‚  â”‚                â†“                                 â”‚  â”‚
â”‚  â”‚       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                        â”‚  â”‚
â”‚  â”‚       â”‚ WebSearch      â”‚                        â”‚  â”‚
â”‚  â”‚       â”‚ Agent          â”‚                        â”‚  â”‚
â”‚  â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                        â”‚  â”‚
â”‚  â”‚                â†“                                 â”‚  â”‚
â”‚  â”‚       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                        â”‚  â”‚
â”‚  â”‚       â”‚ NeedAnalysis   â”‚                        â”‚  â”‚
â”‚  â”‚       â”‚ Agent          â”‚                        â”‚  â”‚
â”‚  â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                        â”‚  â”‚
â”‚  â”‚                â†“                                 â”‚  â”‚
â”‚  â”‚       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                        â”‚  â”‚
â”‚  â”‚       â”‚ UseCaseAnalysisâ”‚                        â”‚  â”‚
â”‚  â”‚       â”‚ Agent          â”‚                        â”‚  â”‚
â”‚  â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                        â”‚  â”‚
â”‚  â”‚                â†“                                 â”‚  â”‚
â”‚  â”‚       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                        â”‚  â”‚
â”‚  â”‚       â”‚ Report         â”‚                        â”‚  â”‚
â”‚  â”‚       â”‚ Agent          â”‚                        â”‚  â”‚
â”‚  â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â†“
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚  SERVICES IA     â”‚
              â”‚  - OpenAI        â”‚
              â”‚  - Perplexity    â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Principe fondamental

ğŸ”‘ **LangGraph gÃ¨re 100% de la logique mÃ©tier**
- L'API backend est **uniquement technique** (upload fichiers, dÃ©clenchement)
- **Toute l'intelligence** est dans le workflow LangGraph
- Les agents sont **autonomes et orchestrÃ©s** automatiquement

---

## âš¡ LangGraph : Le CÅ“ur du Projet

### Qu'est-ce que LangGraph ?

**LangGraph** est un framework pour crÃ©er des **workflows d'agents IA**. Il permet de :
- âœ… DÃ©finir un **graphe de tÃ¢ches** (nodes + edges)
- âœ… Orchestrer plusieurs **agents autonomes**
- âœ… Partager un **Ã©tat commun** entre agents
- âœ… GÃ©rer les **flux conditionnels**
- âœ… Tracer et dÃ©bugger facilement

### APIs LangGraph utilisÃ©es dans le projet

#### 1. **StateGraph** - CrÃ©ation du graphe

```python
from langgraph.graph import StateGraph, END

# FR: CrÃ©ation du graphe avec un Ã©tat typÃ©
workflow = StateGraph(NeedAnalysisState)
```

**Fichier :** `backend/graph_factory.py` ligne 57

**RÃ´le :** 
- CrÃ©e le conteneur du workflow
- DÃ©finit le type d'Ã©tat partagÃ© (`NeedAnalysisState`)

#### 2. **add_node()** - Ajouter des agents

```python
# FR: Ajouter les agents comme nodes
workflow.add_node("workshop", workshop_agent)
workflow.add_node("transcript", transcript_agent)
workflow.add_node("web_search", web_search_agent)
workflow.add_node("need_analysis", need_analysis_agent)
workflow.add_node("use_case_analysis", use_case_analysis_agent)
workflow.add_node("report", report_agent)
```

**Fichier :** `backend/graph_factory.py` lignes 60-65

**RÃ´le :**
- Chaque agent devient un **nÅ“ud** du graphe
- Nom du nÅ“ud (ex: `"workshop"`) + fonction Python

#### 3. **add_edge()** - DÃ©finir le flux

```python
# FR: DÃ©finir le flux d'exÃ©cution (edges)
workflow.set_entry_point("workshop")  # Point d'entrÃ©e
workflow.add_edge("workshop", "transcript")  # workshop â†’ transcript
workflow.add_edge("transcript", "web_search")
workflow.add_edge("web_search", "need_analysis")
workflow.add_edge("need_analysis", "use_case_analysis")
workflow.add_edge("use_case_analysis", "report")
workflow.add_edge("report", END)  # Fin du workflow
```

**Fichier :** `backend/graph_factory.py` lignes 69-82

**RÃ´le :**
- DÃ©finit l'**ordre d'exÃ©cution** des agents
- Les donnÃ©es **circulent automatiquement** entre les nÅ“uds via le State

#### 4. **compile()** - Compiler le graphe

```python
# FR: Compiler le graphe pour le rendre exÃ©cutable
graph = workflow.compile()
```

**Fichier :** `backend/graph_factory.py` ligne 103

**RÃ´le :**
- Transforme la dÃ©finition en **graphe exÃ©cutable**
- Valide la structure (pas de boucles infinies, etc.)
- PrÃ©pare pour l'exÃ©cution

#### 5. **LangGraph Server** - DÃ©ploiement

Le serveur LangGraph est lancÃ© via la commande :
```bash
uv run langgraph dev
```

**Configuration :** `langgraph.json`
```json
{
  "dependencies": ["./backend"],
  "graphs": {
    "need_analysis": "graph_factory:need_analysis"
  },
  "http": {
    "app": "api.app:app"
  }
}
```

**RÃ´le du serveur :**
- âœ… Expose le graphe via **API HTTP**
- âœ… GÃ¨re la **persistance** automatique
- âœ… Fournit un **endpoint** `/runs` pour exÃ©cuter
- âœ… Permet le **streaming** des rÃ©sultats
- âœ… IntÃ¨gre les **routes custom** FastAPI

### Comment LangGraph orchestre le workflow

#### Ã‰tape 1 : Initialisation du State

```python
initial_state = {
    "excel_file_path": "/uploads/atelier.xlsx",
    "pdf_json_file_paths": ["/uploads/doc1.pdf"],
    "company_name": "ACME Corp"
}
```

#### Ã‰tape 2 : ExÃ©cution sÃ©quentielle

```
START
  â†“
workshop_agent(state) 
  â†’ Lit excel_file_path
  â†’ Parse Excel
  â†’ Appelle OpenAI
  â†’ Retourne {"workshop_data": {...}}
  â†’ LangGraph MERGE automatiquement dans state
  â†“
transcript_agent(state)
  â†’ Lit pdf_json_file_paths
  â†’ Parse PDF/JSON
  â†’ Retourne {"transcript_data": [...]}
  â†’ MERGE dans state
  â†“
web_search_agent(state)
  â†’ Lit company_name
  â†’ Appelle Perplexity
  â†’ Retourne {"web_search_data": {...}}
  â†’ MERGE dans state
  â†“
need_analysis_agent(state)
  â†’ Lit workshop_data, transcript_data, web_search_data
  â†’ GÃ©nÃ¨re 10 besoins
  â†’ Retourne {"needs": [...]}
  â†’ MERGE dans state
  â†“
use_case_analysis_agent(state)
  â†’ Lit needs (validÃ©s)
  â†’ GÃ©nÃ¨re Quick Wins + Structuration IA
  â†’ Retourne {"quick_wins": [...], "structuration_ia": [...]}
  â†’ MERGE dans state
  â†“
report_agent(state)
  â†’ Lit needs, quick_wins, structuration_ia
  â†’ GÃ©nÃ¨re rapport Word
  â†’ Retourne {"report_path": "/outputs/rapport.docx"}
  â†’ MERGE dans state
  â†“
END
```

#### Ã‰tape 3 : State final

Ã€ la fin, le State contient **toutes les donnÃ©es** :
```python
{
    "excel_file_path": "...",
    "company_name": "...",
    "workshop_data": {...},
    "transcript_data": [...],
    "web_search_data": {...},
    "needs": [...],
    "quick_wins": [...],
    "structuration_ia": [...],
    "report_path": "/outputs/rapport.docx"
}
```

---

## ğŸ¤– Les 6 Agents du Workflow

### 1. WorkshopAgent ğŸ­

**Fichier implÃ©mentation :** `backend/agents/workshop_agent_impl.py`
**Fichier node :** `backend/agents/nodes.py` lignes 22-44
**Prompts :** `backend/prompts/workshop_agent_prompts.py`

**RÃ´le :**
- Parse le fichier **Excel** (ateliers)
- Extrait 3 colonnes : nom_atelier, cas_usage, objectif_gain
- Analyse via **OpenAI** pour structurer

**Input (du State) :**
```python
{
    "excel_file_path": "/uploads/atelier.xlsx"
}
```

**Traitement :**
1. **Parsing Excel** (lignes 24-73)
   - Utilise `openpyxl`
   - Ignore les lignes vides
   - Extrait colonnes A, B, C

2. **Analyse OpenAI** (lignes 76-126)
   - Appelle GPT-4o-mini
   - Utilise `WORKSHOP_ANALYSIS_SYSTEM_PROMPT`
   - Force rÃ©ponse JSON avec `response_format={"type": "json_object"}`

**Output (ajoutÃ© au State) :**
```python
{
    "workshop_data": {
        "workshop_name": "Atelier Innovation IA",
        "use_cases": ["Automatiser la saisie", "Analyser les feedbacks"],
        "objectives": ["Gagner du temps", "AmÃ©liorer la qualitÃ©"],
        "gains": ["30% de temps Ã©conomisÃ©"],
        "main_themes": ["Automatisation", "Analyse"],
        "summary": "RÃ©sumÃ© de l'atelier...",
        "raw_data": [...]  # DonnÃ©es brutes Excel
    },
    "current_step": "workshop_completed"
}
```

**Technologies :**
- `openpyxl` : parsing Excel
- `OpenAI API` : analyse LLM

---

### 2. TranscriptAgent ğŸ“„

**Fichier implÃ©mentation :** `backend/agents/transcript_agent_impl.py`
**Fichier node :** `backend/agents/nodes.py` lignes 47-69
**Parsers :** 
- `backend/process_transcript/pdf_parser.py`
- `backend/process_transcript/json_parser.py`
**Prompts :** `backend/prompts/transcript_agent_prompts.py`

**RÃ´le :**
- Parse les fichiers **PDF** et **JSON** (transcriptions)
- Extrait citations, frustrations, besoins exprimÃ©s
- Filtre via **OpenAI** (sÃ©mantique)

**Input (du State) :**
```python
{
    "pdf_json_file_paths": [
        "/uploads/transcript1.pdf",
        "/uploads/feedback.json"
    ]
}
```

**Traitement :**
1. **Parsing PDF** (avec PyPDF2)
2. **Parsing JSON** (extraction citations)
3. **Filtrage sÃ©mantique** (OpenAI)

**Output (ajoutÃ© au State) :**
```python
{
    "transcript_data": [
        {
            "source": "transcript1.pdf",
            "citations": [
                "On perd trop de temps sur la saisie manuelle",
                "Les erreurs sont frÃ©quentes dans les rapports"
            ],
            "frustrations": [
                "Processus rÃ©pÃ©titif et chronophage"
            ],
            "expressed_needs": [
                "Automatisation de la saisie"
            ]
        },
        {
            "source": "feedback.json",
            "citations": [...],
            ...
        }
    ],
    "current_step": "transcript_completed"
}
```

**Technologies :**
- `PyPDF2` : parsing PDF
- `json` : parsing JSON
- `OpenAI API` : filtrage sÃ©mantique

---

### 3. WebSearchAgent ğŸŒ

**Fichier implÃ©mentation :** `backend/agents/web_search_agent_impl.py`
**Fichier node :** `backend/agents/nodes.py` lignes 72-98
**Prompts :** `backend/prompts/web_search_agent_prompts.py`

**RÃ´le :**
- Recherche contexte entreprise via **Perplexity**
- Enrichit avec **OpenAI** pour structurer
- âš ï¸ **CONTEXTE UNIQUEMENT** - ne gÃ©nÃ¨re PAS de besoins

**Input (du State) :**
```python
{
    "company_name": "ACME Corporation"
}
```

**Traitement :**
1. **Recherche Perplexity** (API Sonar)
2. **Structuration OpenAI** (secteur, taille, actualitÃ©s)

**Output (ajoutÃ© au State) :**
```python
{
    "web_search_data": {
        "company_name": "ACME Corporation",
        "sector": "Industrie manufacturiÃ¨re",
        "size": "PME (150 employÃ©s)",
        "location": "France, Lyon",
        "recent_news": [
            "Lancement nouvelle gamme de produits",
            "Investissement dans la transformation digitale"
        ],
        "sector_challenges": [
            "Concurrence internationale accrue",
            "Besoin d'optimisation des processus"
        ],
        "context_summary": "ACME est une PME industrielle...",
        "fetched": true
    },
    "current_step": "web_search_completed"
}
```

**Technologies :**
- `Perplexity API` : recherche contextuelle
- `OpenAI API` : structuration

---

### 4. NeedAnalysisAgent ğŸ’¡ (AGENT CRITIQUE)

**Fichier implÃ©mentation :** `backend/agents/need_analysis_agent_impl.py`
**Fichier node :** `backend/agents/nodes.py` lignes 101-132
**Prompts :** `backend/prompts/need_analysis_agent_prompts.py`

**RÃ´le :**
- **GÃ©nÃ¨re 10 besoins mÃ©tier** avec 5 citations chacun
- GÃ¨re la **rÃ©gÃ©nÃ©ration** (exclusion de besoins)
- â­ **CÅ“ur de la valeur mÃ©tier**

**Input (du State) :**
```python
{
    "workshop_data": {...},       # DonnÃ©es Excel
    "transcript_data": [...],     # DonnÃ©es PDF/JSON
    "web_search_data": {...},     # Contexte entreprise
    "action": "generate_needs",   # ou "regenerate_needs"
    "excluded_needs": [],         # Titres Ã  exclure
    "user_comment": ""            # Instructions utilisateur
}
```

**Traitement :**

1. **Formatage des donnÃ©es** (lignes 23-136)
   - Convertit workshop_data en texte lisible
   - Convertit transcript_data en citations
   - Convertit web_search_data en contexte

2. **Appel OpenAI** (lignes 139-239)
   - **Si gÃ©nÃ©ration initiale :** `NEED_ANALYSIS_INITIAL_USER_PROMPT`
   - **Si rÃ©gÃ©nÃ©ration :** `NEED_ANALYSIS_REGENERATION_USER_PROMPT` + excluded_needs
   - Temperature 0.7 (crÃ©ativitÃ©)
   - Force rÃ©ponse JSON

3. **Validation** (lignes 207-216)
   - Max 10 besoins
   - Max 5 citations par besoin
   - Normalisation IDs

**Output (ajoutÃ© au State) :**
```python
{
    "needs": [
        {
            "id": "need_001",
            "title": "Automatiser la saisie des donnÃ©es produit",
            "citations": [
                "On passe 2h par jour sur la saisie manuelle - Atelier Innovation",
                "Les erreurs de saisie coÃ»tent cher - transcript1.pdf",
                "Besoin d'un systÃ¨me intelligent - feedback.json",
                "La saisie est rÃ©pÃ©titive et source d'erreurs - Atelier",
                "Automatisation prioritaire selon l'Ã©quipe - transcript2.pdf"
            ],
            "selected": false,
            "edited": false
        },
        // ... 9 autres besoins
    ],
    "current_step": "needs_generated"
}
```

**RÃ¨gles mÃ©tier critiques :**
- âœ… Citations issues de **workshop_data + transcript_data** (sources PRINCIPALES)
- âœ… web_search_data = **CONTEXTE uniquement**
- âœ… Pas de citations sans source
- âœ… ThÃ¨mes uniques (pas de doublons)

**Technologies :**
- `OpenAI API` : gÃ©nÃ©ration intelligente

---

### 5. UseCaseAnalysisAgent ğŸš€

**Fichier implÃ©mentation :** `backend/agents/use_case_analysis_agent_impl.py`
**Fichier node :** `backend/agents/nodes.py` lignes 135-178
**Prompts :** `backend/prompts/use_case_analysis_prompts.py`

**RÃ´le :**
- GÃ©nÃ¨re **8 Quick Wins** (ROI < 3 mois)
- GÃ©nÃ¨re **10 Structuration IA** (ROI 3-12 mois)
- GÃ¨re la **rÃ©gÃ©nÃ©ration intelligente**

**Input (du State) :**
```python
{
    "validated_needs": [...],     # Besoins validÃ©s (min 5)
    "workshop_data": {...},
    "transcript_data": [...],
    "web_search_data": {...},
    "action": "generate_use_cases",
    "validated_quick_wins": [],
    "validated_structuration_ia": []
}
```

**Traitement :**

1. **VÃ©rification minimale** (au moins 5 besoins validÃ©s)

2. **Appel OpenAI**
   - GÃ©nÃ¨re 8 Quick Wins
   - GÃ©nÃ¨re 10 Structuration IA
   - Technologies IA concrÃ¨tes (LLM, RAG, OCR, ML, NLP, etc.)

3. **Logique de rÃ©gÃ©nÃ©ration intelligente**
   ```python
   if len(validated_quick_wins) >= 5:
       # Ne rÃ©gÃ©nÃ¨re RIEN pour Quick Wins
       pass
   else:
       # RÃ©gÃ©nÃ¨re Quick Wins manquants
   ```

**Output (ajoutÃ© au State) :**
```python
{
    "quick_wins": [
        {
            "id": "uc_qw_001",
            "category": "quick_win",
            "title": "Chatbot FAQ automatisÃ©",
            "description": "ImplÃ©menter un chatbot pour rÃ©pondre...",
            "ai_technologies": ["LLM", "RAG", "Embeddings"],
            "selected": false
        },
        // ... 7 autres Quick Wins
    ],
    "structuration_ia": [
        {
            "id": "uc_sia_001",
            "category": "structuration_ia",
            "title": "Plateforme de knowledge management IA",
            "description": "CrÃ©er une plateforme centralisÃ©e...",
            "ai_technologies": ["RAG", "Vector Database", "LLM"],
            "selected": false
        },
        // ... 9 autres Structuration IA
    ],
    "current_step": "use_cases_generated"
}
```

**Technologies :**
- `OpenAI API` : gÃ©nÃ©ration cas d'usage

---

### 6. ReportAgent ğŸ“

**Fichier implÃ©mentation :** `backend/agents/report_agent_impl.py`
**Fichier node :** `backend/agents/nodes.py` lignes 181-203
**Utilitaire :** `backend/utils/report_generator.py`

**RÃ´le :**
- GÃ©nÃ¨re le **rapport Word final**
- Formate professionnellement
- Inclut besoins + cas d'usage sÃ©lectionnÃ©s

**Input (du State) :**
```python
{
    "needs": [...],              # Besoins sÃ©lectionnÃ©s
    "quick_wins": [...],         # QW sÃ©lectionnÃ©s
    "structuration_ia": [...]    # SIA sÃ©lectionnÃ©s
}
```

**Traitement :**

1. **Filtrage** (besoins/UC sÃ©lectionnÃ©s uniquement)
2. **GÃ©nÃ©ration Word** avec `python-docx`
3. **Sauvegarde** dans `/outputs`

**Output (ajoutÃ© au State) :**
```python
{
    "report_path": "/outputs/Rapport_Besoins_IA_Entreprise_20251022_143919.docx",
    "current_step": "report_generated"
}
```

**Technologies :**
- `python-docx` : gÃ©nÃ©ration Word

---

## ğŸ“¦ Le State PartagÃ©

**Fichier :** `backend/models/graph_state.py`

### Structure complÃ¨te

```python
class NeedAnalysisState(TypedDict):
    # FR: Inputs initiaux
    excel_file_path: Optional[str]
    pdf_json_file_paths: Annotated[List[str], add]
    company_name: Optional[str]
    
    # FR: DonnÃ©es parsÃ©es
    workshop_data: Optional[Dict]
    transcript_data: Optional[List[Dict]]
    web_search_data: Optional[Dict]
    
    # FR: Besoins
    needs: Optional[List[Dict]]
    validated_needs: Annotated[List[Dict], add]
    excluded_needs: Annotated[List[str], add]
    
    # FR: Cas d'usage
    quick_wins: Optional[List[Dict]]
    structuration_ia: Optional[List[Dict]]
    validated_quick_wins: Annotated[List[Dict], add]
    validated_structuration_ia: Annotated[List[Dict], add]
    
    # FR: Rapport
    report_path: Optional[str]
    
    # FR: MÃ©tadonnÃ©es
    user_comment: Optional[str]
    action: Optional[str]
    errors: Annotated[List[str], add]
    current_step: Optional[str]
```

### Annotations importantes

**`Annotated[List[...], add]`** :
- Indique Ã  LangGraph de **fusionner** les listes (ne pas Ã©craser)
- Exemple : `excluded_needs` s'accumule entre les exÃ©cutions

**`Optional[...]`** :
- Champ peut Ãªtre vide initialement
- Rempli progressivement par les agents

---

## ğŸŒŠ Flux de DonnÃ©es Complet

### ScÃ©nario 1 : GÃ©nÃ©ration initiale

```
USER (Frontend)
  â†“ Upload fichiers + nom entreprise
  â†“ POST /api/upload
API Backend
  â†“ Sauvegarde fichiers â†’ /uploads/xxx
  â†“ Retourne file_paths
  â†“
USER (Frontend)  
  â†“ POST /threads/{thread_id}/runs
  â†“ Body: { 
      "assistant_id": "need_analysis",
      "input": {
        "excel_file_path": "/uploads/atelier.xlsx",
        "pdf_json_file_paths": ["/uploads/doc1.pdf"],
        "company_name": "ACME",
        "action": "generate_needs"
      }
    }
LangGraph Server
  â†“ Initialise State
  â†“ ExÃ©cute workflow :
  â†“   1. WorkshopAgent â†’ workshop_data
  â†“   2. TranscriptAgent â†’ transcript_data
  â†“   3. WebSearchAgent â†’ web_search_data
  â†“   4. NeedAnalysisAgent â†’ needs (10)
  â†“   5. UseCaseAnalysisAgent â†’ quick_wins + structuration_ia
  â†“   6. ReportAgent â†’ report_path
  â†“ Retourne State final
  â†“
Frontend
  â†“ Affiche les 10 besoins
  â†“ Page /needs
```

### ScÃ©nario 2 : RÃ©gÃ©nÃ©ration besoins

```
USER (Frontend)
  â†“ SÃ©lectionne 5 besoins
  â†“ Clique "GÃ©nÃ©rer" avec commentaire
  â†“ POST /threads/{thread_id}/runs
  â†“ Body: {
      "assistant_id": "need_analysis",
      "input": {
        "action": "regenerate_needs",
        "excluded_needs": ["Titre besoin 1", "Titre besoin 2", ...],
        "user_comment": "Plus axÃ© sur l'automatisation"
      }
    }
LangGraph Server
  â†“ Reprend State existant (workshop_data, transcript_data dÃ©jÃ  lÃ )
  â†“ ExÃ©cute NeedAnalysisAgent
  â†“   â†’ Utilise REGENERATION_PROMPT
  â†“   â†’ Exclut les besoins listÃ©s
  â†“   â†’ GÃ©nÃ¨re 10 NOUVEAUX besoins
  â†“ Retourne State mis Ã  jour
  â†“
Frontend
  â†“ Affiche 10 nouveaux besoins
  â†“ L'utilisateur peut recommencer ou valider
```

### ScÃ©nario 3 : GÃ©nÃ©ration cas d'usage

```
USER (Frontend)
  â†“ Valide 5+ besoins
  â†“ Navigue vers /usecases
  â†“ POST /threads/{thread_id}/runs
  â†“ Body: {
      "assistant_id": "need_analysis",
      "input": {
        "action": "generate_use_cases",
        "validated_needs": [...]  # 5+ besoins
      }
    }
LangGraph Server
  â†“ ExÃ©cute UseCaseAnalysisAgent
  â†“   â†’ GÃ©nÃ¨re 8 Quick Wins
  â†“   â†’ GÃ©nÃ¨re 10 Structuration IA
  â†“ Retourne quick_wins + structuration_ia
  â†“
Frontend
  â†“ Affiche les cas d'usage
  â†“ Page /usecases
```

---

## ğŸ”Œ API Backend

### Architecture API

```
backend/api/
â”œâ”€â”€ app.py              # Application FastAPI principale
â”œâ”€â”€ upload_routes.py    # Routes d'upload de fichiers
â””â”€â”€ routes.py           # (vide - Ã  implÃ©menter si besoin)
```

### Routes disponibles

#### 1. GET `/health`

**Fichier :** `backend/api/app.py` ligne 36

```python
@app.get("/health")
async def health_check():
    return {"status": "healthy", "service": "aikoGPT"}
```

**Utilisation :** VÃ©rifier que le serveur fonctionne

#### 2. POST `/api/upload`

**Fichier :** `backend/api/upload_routes.py`

**RÃ´le :** Upload de fichiers Excel, PDF, JSON

**Body (multipart/form-data) :**
```
excel_file: File
pdf_json_files: File[]
```

**RÃ©ponse :**
```json
{
  "excel_file_path": "/uploads/atelier_20251022_143919.xlsx",
  "pdf_json_file_paths": [
    "/uploads/doc1_20251022_143919.pdf",
    "/uploads/feedback_20251022_143919.json"
  ]
}
```

#### 3. LangGraph Routes (auto-gÃ©nÃ©rÃ©es)

LangGraph Server ajoute automatiquement :

**POST `/threads`**
- CrÃ©er un nouveau thread (session)

**POST `/threads/{thread_id}/runs`**
- ExÃ©cuter le workflow

**GET `/threads/{thread_id}/runs/{run_id}`**
- RÃ©cupÃ©rer le statut d'une exÃ©cution

**GET `/threads/{thread_id}/state`**
- RÃ©cupÃ©rer l'Ã©tat actuel du thread

**Voir documentation complÃ¨te :** http://localhost:2024/docs

---

## ğŸ’» Frontend Next.js

### Structure

```
frontend/src/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ page.tsx           # Page 1 : Upload
â”‚   â”œâ”€â”€ needs/page.tsx     # Page 2 : Besoins
â”‚   â”œâ”€â”€ usecases/page.tsx  # Page 3 : Cas d'usage
â”‚   â””â”€â”€ results/page.tsx   # Page 4 : RÃ©sultats
â”œâ”€â”€ components/
â”‚   â”œâ”€â”€ SideNav.tsx        # Navigation latÃ©rale
â”‚   â”œâ”€â”€ NeedCard.tsx       # (Ã  crÃ©er) Carte besoin
â”‚   â””â”€â”€ UseCaseCard.tsx    # (Ã  crÃ©er) Carte cas d'usage
â””â”€â”€ lib/
    â”œâ”€â”€ api-client.ts      # Appels API
    â”œâ”€â”€ store.ts           # State management (Zustand)
    â””â”€â”€ schemas.ts         # Types TypeScript
```

### Communication Frontend â†” Backend

**Fichier :** `frontend/src/lib/api-client.ts`

```typescript
// FR: Upload de fichiers
export async function uploadFiles(
  excelFile: File,
  pdfJsonFiles: File[]
): Promise<UploadResponse> {
  // POST /api/upload
}

// FR: ExÃ©cuter le workflow LangGraph
export async function runWorkflow(
  threadId: string,
  input: WorkflowInput
): Promise<WorkflowOutput> {
  // POST /threads/{threadId}/runs
}
```

---

## ğŸ“‚ Fichiers ClÃ©s et leur RÃ´le

### Backend

| Fichier | RÃ´le | Lignes importantes |
|---------|------|-------------------|
| `backend/graph_factory.py` | **CrÃ©er le graphe LangGraph** | 57: StateGraph<br>60-65: add_node<br>69-82: add_edge<br>103: compile |
| `backend/agents/nodes.py` | **Wrapper des agents** (entry points) | 22-44: workshop<br>47-69: transcript<br>72-98: web_search<br>101-132: need_analysis<br>135-178: use_case<br>181-203: report |
| `backend/agents/workshop_agent_impl.py` | **ImplÃ©mentation WorkshopAgent** | 24-73: parse_excel<br>76-126: analyze_openai<br>129-204: workshop_agent |
| `backend/agents/need_analysis_agent_impl.py` | **ImplÃ©mentation NeedAnalysisAgent** â­ | 139-239: generate_needs_with_openai<br>242-305: need_analysis_agent |
| `backend/models/graph_state.py` | **DÃ©finition du State partagÃ©** | 12-49: NeedAnalysisState |
| `backend/prompts/need_analysis_agent_prompts.py` | **Prompts gÃ©nÃ©ration besoins** | Tous les prompts systÃ¨me et user |
| `backend/api/app.py` | **Application FastAPI** | 17-30: Configuration<br>36-39: Health check |
| `backend/api/upload_routes.py` | **Routes upload** | Upload fichiers |
| `langgraph.json` | **Configuration LangGraph Server** | 6: Graphe<br>9: App FastAPI custom |

### Frontend

| Fichier | RÃ´le |
|---------|------|
| `frontend/src/lib/api-client.ts` | Appels API vers backend |
| `frontend/src/lib/store.ts` | State management global (Zustand) |
| `frontend/src/app/page.tsx` | Page 1 : Upload fichiers |
| `frontend/src/app/needs/page.tsx` | Page 2 : Gestion besoins |
| `frontend/src/app/usecases/page.tsx` | Page 3 : Cas d'usage |
| `frontend/src/app/results/page.tsx` | Page 4 : TÃ©lÃ©chargement rapport |

### Configuration

| Fichier | RÃ´le |
|---------|------|
| `.env` | ClÃ©s API (OPENAI_API_KEY, PERPLEXITY_API_KEY) |
| `docker-compose.yml` | Configuration Docker (backend + frontend) |
| `Dockerfile.backend` | Image Docker backend |
| `Dockerfile.frontend` | Image Docker frontend |
| `backend/pyproject.toml` | DÃ©pendances Python (uv) |
| `frontend/package.json` | DÃ©pendances Node.js |

---

## ğŸ¯ Points ClÃ©s Ã  Retenir

### 1. LangGraph = Cerveau du projet

- âœ… **100% de la logique mÃ©tier** dans le workflow
- âœ… Les agents sont **autonomes et orchestrÃ©s**
- âœ… Le State est **partagÃ© automatiquement**
- âœ… L'API backend est **minimaliste** (upload + dÃ©clenchement)

### 2. Le State est central

- âœ… Chaque agent **lit** et **Ã©crit** dans le State
- âœ… LangGraph **merge** automatiquement les updates
- âœ… Le State **persiste** entre les exÃ©cutions (threads)

### 3. Les prompts sont critiques

- âœ… Tous dans `/prompts` (versionnÃ©s)
- âœ… **System Prompt** : rÃ´le et rÃ¨gles
- âœ… **User Prompt** : donnÃ©es + instructions
- âœ… DiffÃ©rents prompts pour gÃ©nÃ©ration vs rÃ©gÃ©nÃ©ration

### 4. Architecture modulaire

- âœ… Chaque agent = **1 responsabilitÃ©**
- âœ… Agents **testables isolÃ©ment**
- âœ… Facile d'**ajouter de nouveaux agents**

### 5. Flux asynchrone

- âœ… Frontend â†’ Upload fichiers
- âœ… Frontend â†’ DÃ©clenche workflow (thread)
- âœ… LangGraph â†’ ExÃ©cute agents sÃ©quentiellement
- âœ… Frontend â†’ RÃ©cupÃ¨re rÃ©sultats (polling ou streaming)

---

## ğŸ“š Ressources

- **Documentation LangGraph :** https://langchain-ai.github.io/langgraph/
- **API LangGraph Server :** http://localhost:2024/docs (quand lancÃ©)
- **DeepWiki LangGraph :** Utiliser l'outil MCP pour approfondir

---

## ğŸš€ Prochaines Ã‰tapes

1. âœ… **Projet lancÃ©** - Backend + Frontend opÃ©rationnels
2. ğŸ”„ **Tester le workflow complet** avec fichiers d'exemple
3. ğŸ“ **Ajuster les prompts** si nÃ©cessaire
4. ğŸ¨ **AmÃ©liorer l'UI** (NeedCard, UseCaseCard)
5. ğŸ§ª **Tests unitaires** des agents
6. ğŸ“Š **Monitoring** et logs dÃ©taillÃ©s

---

**CrÃ©Ã© le :** 22 octobre 2025
**Auteur :** Guide gÃ©nÃ©rÃ© pour comprendre aikoGPT
**Version :** 1.0

