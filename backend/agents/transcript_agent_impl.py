"""
TranscriptAgent Implementation - Parsing PDF/JSON et filtrage s√©mantique

FR: Impl√©mentation compl√®te du TranscriptAgent avec parsing PDF/JSON et appel OpenAI
"""

import logging
import json
from typing import Dict, Any, List
from pathlib import Path
from openai import OpenAI

# FR: Imports pour parsing PDF
try:
    import pypdfium2 as pdfium
    PDF_PARSER = "pypdfium2"
except ImportError:
    try:
        import PyPDF2
        PDF_PARSER = "PyPDF2"
    except ImportError:
        PDF_PARSER = None

from models.graph_state import NeedAnalysisState
from prompts.transcript_agent_prompts import (
    TRANSCRIPT_SEMANTIC_FILTER_SYSTEM_PROMPT,
    TRANSCRIPT_EXTRACTION_USER_PROMPT
)

logger = logging.getLogger(__name__)


def parse_pdf_file(file_path: str) -> str:
    """
    FR: Parse un fichier PDF et extrait son contenu texte
    
    Args:
        file_path: Chemin vers le fichier PDF
        
    Returns:
        str: Contenu texte du PDF
        
    Raises:
        ImportError: Si aucune biblioth√®que PDF n'est disponible
        FileNotFoundError: Si le fichier n'existe pas
    """
    logger.info(f"üìÑ Parsing fichier PDF: {file_path}")
    
    if not Path(file_path).exists():
        raise FileNotFoundError(f"Fichier PDF introuvable: {file_path}")
    
    if PDF_PARSER is None:
        raise ImportError("Aucune biblioth√®que PDF disponible (pypdfium2 ou PyPDF2)")
    
    try:
        if PDF_PARSER == "pypdfium2":
            # FR: Utiliser pypdfium2 (pr√©f√©r√©)
            pdf = pdfium.PdfDocument(file_path)
            text_parts = []
            for page_num in range(len(pdf)):
                page = pdf[page_num]
                textpage = page.get_textpage()
                text = textpage.get_text_range()
                text_parts.append(text)
            full_text = "\n\n".join(text_parts)
            
        else:  # PyPDF2
            # FR: Fallback vers PyPDF2
            with open(file_path, 'rb') as file:
                pdf_reader = PyPDF2.PdfReader(file)
                text_parts = []
                for page in pdf_reader.pages:
                    text_parts.append(page.extract_text())
                full_text = "\n\n".join(text_parts)
        
        logger.info(f"‚úÖ PDF pars√© : {len(full_text)} caract√®res extraits")
        return full_text
        
    except Exception as e:
        logger.error(f"‚ùå Erreur lors du parsing PDF: {e}")
        raise


def parse_json_file(file_path: str) -> str:
    """
    FR: Parse un fichier JSON et le convertit en texte structur√©
    
    Args:
        file_path: Chemin vers le fichier JSON
        
    Returns:
        str: Contenu JSON format√© en texte
        
    Raises:
        FileNotFoundError: Si le fichier n'existe pas
        json.JSONDecodeError: Si le JSON est invalide
    """
    logger.info(f"üìÑ Parsing fichier JSON: {file_path}")
    
    if not Path(file_path).exists():
        raise FileNotFoundError(f"Fichier JSON introuvable: {file_path}")
    
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        # FR: Convertir en texte format√©
        formatted_text = json.dumps(data, indent=2, ensure_ascii=False)
        
        logger.info(f"‚úÖ JSON pars√© : {len(formatted_text)} caract√®res")
        return formatted_text
        
    except json.JSONDecodeError as e:
        logger.error(f"‚ùå Erreur JSON invalide: {e}")
        raise
    except Exception as e:
        logger.error(f"‚ùå Erreur lors du parsing JSON: {e}")
        raise


def filter_with_openai(text_content: str, source_file: str, config: Dict[str, Any]) -> Dict[str, Any]:
    """
    FR: Filtre s√©mantique du contenu avec OpenAI pour extraire citations, frustrations, besoins
    
    Args:
        text_content: Contenu texte √† analyser
        source_file: Nom du fichier source (pour tra√ßabilit√©)
        config: Configuration (contient model, etc.)
        
    Returns:
        Dict: Donn√©es filtr√©es (citations, frustrations, expressed_needs)
    """
    logger.info(f"ü§ñ Filtrage s√©mantique avec OpenAI pour {source_file}...")
    
    try:
        # FR: Limiter la taille du texte si trop long (max ~15k tokens pour le contexte)
        max_chars = 50000  # ~12k tokens approximativement
        if len(text_content) > max_chars:
            logger.warning(f"‚ö†Ô∏è Texte trop long ({len(text_content)} chars), troncature √† {max_chars}")
            text_content = text_content[:max_chars] + "\n\n[... TEXTE TRONQU√â ...]"
        
        # FR: Cr√©er le client OpenAI
        client = OpenAI()
        
        # FR: Appeler OpenAI avec les prompts
        response = client.chat.completions.create(
            model=config.get("configurable", {}).get("model", "gpt-4o-mini"),
            messages=[
                {"role": "system", "content": TRANSCRIPT_SEMANTIC_FILTER_SYSTEM_PROMPT},
                {"role": "user", "content": TRANSCRIPT_EXTRACTION_USER_PROMPT.format(
                    raw_content=text_content
                )}
            ],
            temperature=0.3,
            response_format={"type": "json_object"}
        )
        
        # FR: Parser la r√©ponse JSON
        result = json.loads(response.choices[0].message.content)
        
        # FR: Ajouter le nom du fichier source aux citations
        if "citations" in result:
            for citation in result["citations"]:
                if "source" not in citation or not citation["source"]:
                    citation["source"] = source_file
        
        logger.info(f"‚úÖ Filtrage termin√© - {len(result.get('citations', []))} citations extraites")
        
        return result
        
    except Exception as e:
        logger.error(f"‚ùå Erreur lors du filtrage OpenAI: {e}")
        # FR: Retourner structure vide en cas d'erreur
        return {
            "citations": [],
            "frustrations": [],
            "expressed_needs": []
        }


def transcript_agent(state: NeedAnalysisState, config: Dict[str, Any]) -> Dict[str, Any]:
    """
    FR: Agent LangGraph pour analyser les fichiers PDF/JSON (transcriptions)
    
    Args:
        state: √âtat actuel du workflow LangGraph
        config: Configuration LangGraph
        
    Returns:
        Dict: Mise √† jour de l'√©tat avec transcript_data
    """
    logger.info("üìù TranscriptAgent - D√©but analyse PDF/JSON")
    
    pdf_json_file_paths = state.get("pdf_json_file_paths", [])
    
    if not pdf_json_file_paths:
        logger.warning("‚ö†Ô∏è Aucun fichier PDF/JSON fourni, skip")
        return {
            "transcript_data": [],
            "current_step": "transcript_skipped",
            "errors": ["Aucun fichier PDF/JSON fourni"]
        }
    
    all_transcript_data = []
    errors = []
    
    for file_path in pdf_json_file_paths:
        try:
            logger.info(f"üìÑ Traitement de {file_path}...")
            
            # FR: D√©terminer le type de fichier
            file_extension = Path(file_path).suffix.lower()
            source_name = Path(file_path).name
            
            # FR: Parser le fichier selon son type
            if file_extension == ".pdf":
                if PDF_PARSER is None:
                    logger.error(f"‚ùå Aucune biblioth√®que PDF disponible pour {file_path}")
                    errors.append(f"Biblioth√®que PDF manquante pour {source_name}")
                    continue
                text_content = parse_pdf_file(file_path)
                
            elif file_extension == ".json":
                text_content = parse_json_file(file_path)
                
            else:
                logger.warning(f"‚ö†Ô∏è Type de fichier non support√©: {file_extension}")
                errors.append(f"Type de fichier non support√©: {source_name}")
                continue
            
            # FR: Filtrage s√©mantique avec OpenAI
            filtered_data = filter_with_openai(text_content, source_name, config)
            
            # FR: Ajouter les donn√©es filtr√©es
            all_transcript_data.append({
                "source": source_name,
                "file_path": file_path,
                "citations": filtered_data.get("citations", []),
                "frustrations": filtered_data.get("frustrations", []),
                "expressed_needs": filtered_data.get("expressed_needs", []),
                "parsed": True
            })
            
            logger.info(f"‚úÖ {source_name} trait√© avec succ√®s")
            
        except FileNotFoundError as e:
            logger.error(f"‚ùå Fichier introuvable: {e}")
            errors.append(f"Fichier introuvable: {Path(file_path).name}")
            
        except Exception as e:
            logger.error(f"‚ùå Erreur inattendue pour {file_path}: {e}")
            errors.append(f"Erreur lors du traitement de {Path(file_path).name}")
    
    # FR: R√©sum√©
    logger.info("‚úÖ TranscriptAgent - Analyse termin√©e")
    logger.info(f"üìä {len(all_transcript_data)} fichiers trait√©s, {len(errors)} erreurs")
    
    return {
        "transcript_data": all_transcript_data,
        "current_step": "transcript_completed",
        "errors": errors
    }

