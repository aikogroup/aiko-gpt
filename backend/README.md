# Backend aikoGPT - LangGraph

## ðŸ—ï¸ Architecture

Ce backend utilise **LangGraph** pour orchestrer tous les agents d'analyse.

### Pourquoi LangGraph ?

- âœ… **Pas de FastAPI nÃ©cessaire** : LangGraph Server gÃ¨re les APIs HTTP
- âœ… **Orchestration native** : Workflow dÃ©fini comme un graphe de nodes
- âœ… **State Management** : Ã‰tat partagÃ© entre tous les agents
- âœ… **Streaming support** : Ã‰vÃ©nements en temps rÃ©el
- âœ… **Human-in-the-loop** : Validation utilisateur intÃ©grÃ©e

## ðŸ“ Structure

```
backend/
â”œâ”€â”€ graph_factory.py          # DÃ©finition du graphe LangGraph
â”œâ”€â”€ main.py                   # Configuration et logging
â”œâ”€â”€ agents/
â”‚   â”œâ”€â”€ nodes.py              # Tous les agents (workshop, transcript, etc.)
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ graph_state.py        # Ã‰tat partagÃ© du workflow
â”‚   â”œâ”€â”€ need_analysis_models.py
â”‚   â”œâ”€â”€ use_case_analysis_models.py
â”‚   â””â”€â”€ ...
â”œâ”€â”€ prompts/                  # Prompts LLM versionnÃ©s
â”œâ”€â”€ utils/                    # Utilitaires (report_generator, etc.)
â””â”€â”€ ...
```

## ðŸ”„ Workflow du graphe

```
START
  â†“
WorkshopAgent (Parse Excel)
  â†“
TranscriptAgent (Parse PDF/JSON)
  â†“
WebSearchAgent (Contexte entreprise)
  â†“
NeedAnalysisAgent (GÃ©nÃ¨re 10 besoins)
  â†“
UseCaseAnalysisAgent (GÃ©nÃ¨re QW + SIA)
  â†“
ReportAgent (GÃ©nÃ¨re rapport Word)
  â†“
END
```

## ðŸš€ Lancer le serveur

### DÃ©veloppement local

```bash
# Depuis la racine du projet
langgraph dev
```

Le serveur LangGraph dÃ©marre sur `http://localhost:2024` par dÃ©faut.

### Avec Docker

```bash
# Lance LangGraph + Redis + PostgreSQL
langgraph up
```

## ðŸ§ª Tester le graphe

### 1. Via l'API HTTP (LangGraph Server)

```bash
# CrÃ©er un thread
curl -X POST http://localhost:2024/threads

# Lancer le workflow
curl -X POST http://localhost:2024/threads/{thread_id}/runs \
  -H "Content-Type: application/json" \
  -d '{
    "input": {
      "excel_file_path": "./documents/atelier_exemple.xlsx",
      "pdf_json_file_paths": ["./documents/test.pdf"],
      "company_name": "Cousin Biotech"
    }
  }'
```

### 2. Via Python

```python
from graph_factory import need_analysis

# Ã‰tat initial
initial_state = {
    "excel_file_path": "./documents/atelier_exemple.xlsx",
    "pdf_json_file_paths": ["./documents/test.pdf"],
    "company_name": "Cousin Biotech"
}

# ExÃ©cuter le graphe
result = need_analysis.invoke(initial_state)

print(result["needs"])  # 10 besoins gÃ©nÃ©rÃ©s
```

## ðŸ”‘ Variables d'environnement

CrÃ©ez un fichier `.env` Ã  la racine avec :

```bash
# OpenAI
OPENAI_API_KEY=sk-...
OPENAI_MODEL=gpt-4o-mini-2024-07-18

# Perplexity
PERPLEXITY_API_KEY=pplx-...

# LangSmith (optionnel, pour monitoring)
LANGSMITH_API_KEY=lsv2_pt_...

# Logging
LOG_LEVEL=INFO
```

## ðŸ“Š Monitoring avec LangSmith

Si vous avez configurÃ© `LANGSMITH_API_KEY`, vous pouvez suivre l'exÃ©cution du graphe sur :
https://smith.langchain.com/

## ðŸ› ï¸ DÃ©veloppement

### Ajouter un nouveau agent

1. CrÃ©er une fonction dans `agents/nodes.py`
2. Ajouter le node dans `graph_factory.py`
3. DÃ©finir les edges (transitions)

```python
# agents/nodes.py
def mon_nouvel_agent(state: NeedAnalysisState) -> Dict[str, Any]:
    logger.info("Mon agent s'exÃ©cute")
    return {"current_step": "completed"}

# graph_factory.py
workflow.add_node("mon_agent", mon_nouvel_agent)
workflow.add_edge("previous_agent", "mon_agent")
```

## ðŸ“š Ressources

- [LangGraph Documentation](https://langchain-ai.github.io/langgraph/)
- [DeepWiki LangGraph](https://deepwiki.com/langchain-ai/langgraph)
- [Agents.md du projet](../AGENTS.md)

