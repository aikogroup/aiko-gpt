# ğŸ—ï¸ Architecture LangGraph - aikoGPT

## âœ… Ce qui a Ã©tÃ© fait

### 1. **Suppression de FastAPI** âŒ
- FastAPI **n'est plus nÃ©cessaire**
- LangGraph Server gÃ¨re les APIs HTTP automatiquement
- `backend/main.py` est maintenant un simple fichier de configuration

### 2. **Ã‰tat partagÃ© (State)** âœ…
- **Fichier** : `backend/models/graph_state.py`
- **Type** : `NeedAnalysisState` (TypedDict)
- **Contenu** :
  - Inputs (excel, pdf/json, company_name)
  - DonnÃ©es parsÃ©es (workshop_data, transcript_data, web_search_data)
  - Besoins et cas d'usage gÃ©nÃ©rÃ©s
  - MÃ©tadonnÃ©es (action, errors, current_step)

### 3. **Agents comme Nodes** âœ…
- **Fichier** : `backend/agents/nodes.py`
- **Agents crÃ©Ã©s** :
  1. `workshop_agent` - Parse fichier Excel
  2. `transcript_agent` - Parse PDF/JSON
  3. `web_search_agent` - Recherche contexte (Perplexity)
  4. `need_analysis_agent` - GÃ©nÃ¨re 10 besoins
  5. `use_case_analysis_agent` - GÃ©nÃ¨re QW + SIA
  6. `report_agent` - GÃ©nÃ¨re rapport Word

**Note** : Pour l'instant, les agents retournent des donnÃ©es de test. La logique mÃ©tier sera implÃ©mentÃ©e progressivement.

### 4. **Graphe LangGraph** âœ…
- **Fichier** : `backend/graph_factory.py`
- **Type** : `StateGraph`
- **Workflow** :

```
START
  â†“
workshop (Parse Excel)
  â†“
transcript (Parse PDF/JSON)
  â†“
web_search (Contexte entreprise)
  â†“
need_analysis (GÃ©nÃ¨re 10 besoins)
  â†“
use_case_analysis (GÃ©nÃ¨re QW + SIA)
  â†“
report (GÃ©nÃ¨re rapport Word)
  â†“
END
```

### 5. **Configuration** âœ…
- **langgraph.json** : ConfigurÃ© pour pointer vers `backend/graph_factory.py:need_analysis`
- **pyproject.toml** : DÃ©pendances pour UV
- **.env** : Variables d'environnement dÃ©jÃ  configurÃ©es

### 6. **Documentation** âœ…
- `backend/README.md` - Guide backend
- `QUICKSTART.md` - Guide de dÃ©marrage rapide
- `test_graph.py` - Script de test

## ğŸ” Comment LangGraph fonctionne

### Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          langgraph.json                     â”‚
â”‚  {                                          â”‚
â”‚    "graphs": {                              â”‚
â”‚      "need_analysis": "backend/graph_factory.py:need_analysis"
â”‚    }                                        â”‚
â”‚  }                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â”‚ Charge le graphe
                  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚       LangGraph Server                      â”‚
â”‚                                             â”‚
â”‚  Expose automatiquement :                   â”‚
â”‚  - POST /threads (crÃ©er un thread)          â”‚
â”‚  - POST /threads/{id}/runs (lancer)         â”‚
â”‚  - GET /threads/{id}/runs/{id}/stream      â”‚
â”‚  - ...                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Flux d'exÃ©cution

1. **Client** (frontend ou curl) â†’ POST `/threads/{id}/runs`
2. **LangGraph Server** â†’ Charge le graphe `need_analysis`
3. **Graphe** â†’ ExÃ©cute les nodes dans l'ordre dÃ©fini
4. **Chaque node** :
   - ReÃ§oit le state actuel
   - Effectue son traitement
   - Retourne un dict de mise Ã  jour du state
5. **State** â†’ FusionnÃ© automatiquement par LangGraph
6. **RÃ©sultat** â†’ RetournÃ© au client

### Exemple de state entre nodes

```python
# AprÃ¨s workshop_agent
{
  "excel_file_path": "./documents/atelier.xlsx",
  "workshop_data": { ... },  # âœ… AjoutÃ© par workshop
  "current_step": "workshop_completed"
}

# AprÃ¨s transcript_agent
{
  "excel_file_path": "./documents/atelier.xlsx",
  "workshop_data": { ... },
  "transcript_data": [ ... ],  # âœ… AjoutÃ© par transcript
  "current_step": "transcript_completed"
}

# Et ainsi de suite...
```

## ğŸš€ Prochaines Ã©tapes

### Ã‰tape 4.1 : Tester le graphe localement

```bash
# Option 1 : Test Python direct
python test_graph.py

# Option 2 : Lancer LangGraph Server
langgraph dev
```

### Ã‰tape 4.2 : ImplÃ©menter la logique mÃ©tier des agents

Pour chaque agent, implÃ©menter :
1. **workshop_agent** : Parsing Excel rÃ©el (openpyxl)
2. **transcript_agent** : Parsing PDF/JSON rÃ©el (pypdfium2, json)
3. **web_search_agent** : Appels Perplexity API
4. **need_analysis_agent** : GÃ©nÃ©ration avec OpenAI (prompts/)
5. **use_case_analysis_agent** : GÃ©nÃ©ration avec OpenAI (prompts/)
6. **report_agent** : GÃ©nÃ©ration Word (python-docx)

### Ã‰tape 4.3 : Ajouter les interruptions humaines

Dans `langgraph.json` :
```json
{
  "graphs": {
    "need_analysis": {
      "path": "./backend/graph_factory.py:need_analysis",
      "interrupt_before": ["use_case_analysis"],
      "interrupt_after": ["need_analysis"]
    }
  }
}
```

Cela permettra :
- Pause aprÃ¨s `need_analysis` pour validation utilisateur
- Pause avant `use_case_analysis` pour sÃ©lection besoins

## ğŸ“Š DiffÃ©rences clÃ©s avec l'ancienne approche

| Aspect | Ancienne approche | Nouvelle approche LangGraph |
|--------|-------------------|----------------------------|
| **API HTTP** | FastAPI manuel | LangGraph Server automatique |
| **Orchestration** | Code custom | StateGraph dÃ©claratif |
| **State** | Variables locales | State partagÃ© typÃ© |
| **Streaming** | Ã€ implÃ©menter | Natif LangGraph |
| **Monitoring** | Ã€ implÃ©menter | LangSmith intÃ©grÃ© |
| **Human-in-the-loop** | Ã€ implÃ©menter | `interrupt_before/after` |
| **Retry** | Ã€ implÃ©menter | Natif LangGraph |
| **Persistance** | Ã€ implÃ©menter | Checkpointer natif |

## ğŸ¯ Avantages de l'architecture LangGraph

1. âœ… **Moins de code** : Pas besoin de FastAPI
2. âœ… **Plus maintenable** : Workflow dÃ©claratif
3. âœ… **Streaming natif** : Ã‰vÃ©nements en temps rÃ©el
4. âœ… **Monitoring gratuit** : LangSmith
5. âœ… **Human-in-the-loop** : Built-in
6. âœ… **Testable** : Chaque node isolÃ©
7. âœ… **Scalable** : DÃ©ploiement LangGraph Platform

## ğŸ”§ Commandes utiles

```bash
# DÃ©veloppement local avec hot reload
langgraph dev

# Production avec Docker
langgraph up

# Test du graphe Python
python test_graph.py

# VÃ©rifier la configuration
langgraph config show

# Voir les logs
tail -f .langgraph/logs/server.log
```

## ğŸ“š Ressources

- [LangGraph Documentation](https://langchain-ai.github.io/langgraph/)
- [DeepWiki LangGraph](https://deepwiki.com/langchain-ai/langgraph)
- [LangGraph Examples](https://github.com/langchain-ai/langgraph/tree/main/examples)
- [LangSmith (Monitoring)](https://smith.langchain.com/)

