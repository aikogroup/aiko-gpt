"""
Workshop Agent - Traitement des fichiers Excel d'ateliers IA
"""

import pandas as pd
import json
import logging
from typing import Dict, List, Any
from pathlib import Path
from pydantic import BaseModel, Field
from openai import OpenAI
from dotenv import load_dotenv
from concurrent.futures import ThreadPoolExecutor, as_completed
from prompts.workshop_agent_prompts import (
    WORKSHOP_ANALYSIS_PROMPT,
    USE_CASE_CONSOLIDATION_PROMPT
)

# Configuration du logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# Chargement des variables d'environnement
load_dotenv()

class UseCase(BaseModel):
    """Mod√®le pour un cas d'usage"""
    title: str = Field(description="Titre du cas d'usage")
    objective: str = Field(description="Objectif ou gain attendu")
    benefits: List[str] = Field(default_factory=list, description="Liste des b√©n√©fices")

class WorkshopAnalysisResponse(BaseModel):
    """Mod√®le pour la r√©ponse d'analyse d'un atelier"""
    theme: str = Field(description="Th√®me principal de l'atelier")
    use_cases: List[UseCase] = Field(description="Liste des cas d'usage consolid√©s")

class WorkshopData(BaseModel):
    """Mod√®le pour les donn√©es d'un atelier"""
    workshop_id: str = Field(description="Identifiant unique de l'atelier")
    theme: str = Field(description="Th√®me de l'atelier")
    use_cases: List[UseCase] = Field(description="Liste des cas d'usage")

class WorkshopAgent:
    """Agent de traitement des fichiers Excel d'ateliers"""
    
    def __init__(self, openai_api_key: str = None):
        """Initialise l'agent avec la cl√© API OpenAI"""
        # Utilisation de la cl√© API depuis les variables d'environnement
        import os
        api_key = openai_api_key or os.getenv('OPENAI_API_KEY')
        if not api_key:
            raise ValueError("OPENAI_API_KEY doit √™tre d√©finie dans les variables d'environnement ou pass√©e en param√®tre")
        self.client = OpenAI(api_key=api_key)
        self.model = os.getenv('OPENAI_MODEL', 'gpt-5-nano')
        
    def parse_excel(self, file_path: str) -> pd.DataFrame:
        """
        Parse un fichier Excel et retourne un DataFrame nettoy√©
        
        Args:
            file_path: Chemin vers le fichier Excel
            
        Returns:
            DataFrame nettoy√© avec les colonnes standardis√©es
        """
        logger.info(f"Parsing du fichier Excel: {file_path}")
        
        try:
            # Lecture du fichier Excel
            df = pd.read_excel(file_path)
            
            # Log des colonnes originales
            logger.info(f"Colonnes d√©tect√©es: {df.columns.tolist()}")
            logger.info(f"Nombre de lignes: {len(df)}")
            
            # Standardisation des noms de colonnes (premi√®re lettre de chaque colonne)
            if len(df.columns) >= 3:
                df.columns = ['Atelier', 'Use_Case', 'Objective']
            else:
                raise ValueError("Le fichier Excel doit contenir au moins 3 colonnes")
            
            # Nettoyage des donn√©es
            df = df.dropna(subset=['Atelier'])  # Supprimer les lignes sans atelier
            df = df.fillna('')  # Remplacer les NaN par des cha√Ænes vides
            
            logger.info(f"Donn√©es nettoy√©es - {len(df)} lignes restantes")
            logger.info("Premi√®res lignes du fichier pars√©:")
            logger.info(f"\n{df.head()}")
            
            return df
            
        except Exception as e:
            logger.error(f"Erreur lors du parsing du fichier Excel: {e}")
            raise
    
    def group_by_workshop(self, df: pd.DataFrame) -> Dict[str, pd.DataFrame]:
        """
        Groupe les donn√©es par atelier
        
        Args:
            df: DataFrame nettoy√©
            
        Returns:
            Dictionnaire avec les ateliers comme cl√©s
        """
        logger.info("Groupement des donn√©es par atelier")
        
        workshops = {}
        for atelier in df['Atelier'].unique():
            if atelier and atelier.strip():  # Ignorer les ateliers vides
                workshop_data = df[df['Atelier'] == atelier]
                workshops[atelier] = workshop_data
                logger.info(f"Atelier '{atelier}': {len(workshop_data)} cas d'usage")
        
        return workshops
    
    def _process_single_workshop(self, atelier_name: str, workshop_df: pd.DataFrame, workshop_id: str) -> WorkshopData:
        """
        Traite un seul atelier avec le LLM (fonction helper pour la parall√©lisation)
        
        Args:
            atelier_name: Nom de l'atelier
            workshop_df: DataFrame des cas d'usage de cet atelier
            workshop_id: Identifiant unique de l'atelier
            
        Returns:
            WorkshopData structur√©
        """
        logger.info(f"Traitement de l'atelier: {atelier_name}")
        
        # Pr√©paration des donn√©es pour le LLM
        use_cases_text = []
        for _, row in workshop_df.iterrows():
            use_case = row['Use_Case']
            objective = row['Objective']
            if use_case and use_case.strip():
                use_cases_text.append(f"- {use_case}: {objective}")
        
        # Utilisation du prompt depuis workshop_agent_prompts.py
        user_prompt = USE_CASE_CONSOLIDATION_PROMPT.format(
            atelier_name=atelier_name,
            use_cases_text=chr(10).join(use_cases_text)
        )
        
        try:
            # Appel √† l'API OpenAI Responses avec structured output
            # Utilisation du param√®tre 'instructions' pour le system prompt
            response = self.client.responses.parse(
                model=self.model,
                instructions=WORKSHOP_ANALYSIS_PROMPT,
                input=[
                    {
                        "role": "user",
                        "content": user_prompt
                    }
                ],
                text_format=WorkshopAnalysisResponse
            )
            
            # Extraction de la r√©ponse structur√©e
            parsed_response = response.output_parsed
            
            logger.info(f"R√©ponse structur√©e pour {atelier_name}:")
            logger.info(f"Th√®me: {parsed_response.theme}")
            logger.info(f"Nombre de cas d'usage: {len(parsed_response.use_cases)}")
            
            # Cr√©ation de l'objet WorkshopData
            workshop_result = WorkshopData(
                workshop_id=workshop_id,
                theme=parsed_response.theme,
                use_cases=parsed_response.use_cases
            )
            
            logger.info(f"Atelier {atelier_name} trait√© avec succ√®s avec structured output")
            return workshop_result
            
        except Exception as e:
            logger.error(f"Erreur lors du traitement LLM pour {atelier_name}: {e}", exc_info=True)
            # Fallback: cr√©ation d'un atelier basique
            workshop_result = WorkshopData(
                workshop_id=workshop_id,
                theme=atelier_name,
                use_cases=[]
            )
            return workshop_result
    
    def aggregate_use_cases_with_llm(self, workshops: Dict[str, pd.DataFrame]) -> List[WorkshopData]:
        """
        Utilise un LLM pour rassembler et structurer les cas d'usage par atelier
        PARALL√âLIS√â : Traite tous les ateliers en parall√®le pour gagner du temps
        
        Args:
            workshops: Dictionnaire des ateliers group√©s
            
        Returns:
            Liste des donn√©es d'ateliers structur√©es
        """
        logger.info(f"Agr√©gation des cas d'usage avec LLM (PARALL√âLIS√âE pour {len(workshops)} ateliers)")
        
        workshop_results = []
        
        # üöÄ PARALL√âLISATION : Traiter tous les ateliers en m√™me temps
        with ThreadPoolExecutor(max_workers=len(workshops)) as executor:
            # Soumettre tous les ateliers pour traitement parall√®le
            future_to_atelier = {}
            for idx, (atelier_name, workshop_df) in enumerate(workshops.items(), 1):
                workshop_id = f"W{idx:03d}"
                future = executor.submit(self._process_single_workshop, atelier_name, workshop_df, workshop_id)
                future_to_atelier[future] = atelier_name
            
            # R√©cup√©rer les r√©sultats au fur et √† mesure
            for future in as_completed(future_to_atelier):
                atelier_name = future_to_atelier[future]
                try:
                    workshop_result = future.result()
                    workshop_results.append(workshop_result)
                    logger.info(f"‚úì Atelier '{atelier_name}' termin√©")
                except Exception as e:
                    logger.error(f"‚ùå Erreur lors du traitement de '{atelier_name}': {e}")
                    # Cr√©er un r√©sultat fallback
                    workshop_results.append(WorkshopData(
                        workshop_id=f"W{len(workshop_results) + 1:03d}",
                        theme=atelier_name,
                        use_cases=[]
                    ))
        
        logger.info(f"‚úÖ Traitement parall√®le termin√©: {len(workshop_results)} ateliers trait√©s")
        return workshop_results
    
    def process_workshop_file(self, file_path: str) -> List[WorkshopData]:
        """
        Traite un fichier Excel d'atelier complet
        
        Args:
            file_path: Chemin vers le fichier Excel
            
        Returns:
            Liste des donn√©es d'ateliers structur√©es
        """
        logger.info(f"D√©but du traitement du fichier: {file_path}")
        
        # 1. Parsing du fichier Excel
        df = self.parse_excel(file_path)
        
        # 2. Groupement par atelier
        workshops = self.group_by_workshop(df)
        
        # 3. Agr√©gation avec LLM
        workshop_results = self.aggregate_use_cases_with_llm(workshops)
        
        logger.info(f"Traitement termin√©: {len(workshop_results)} ateliers trait√©s")
        
        return workshop_results
    
    def save_results(self, results: List[WorkshopData], output_path: str):
        """
        Sauvegarde les r√©sultats en JSON
        
        Args:
            results: Liste des donn√©es d'ateliers
            output_path: Chemin de sauvegarde
        """
        logger.info(f"Sauvegarde des r√©sultats vers: {output_path}")
        
        # Conversion en dictionnaire pour la s√©rialisation JSON
        results_dict = [result.model_dump() for result in results]
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(results_dict, f, ensure_ascii=False, indent=2)
        
        logger.info("R√©sultats sauvegard√©s avec succ√®s")

def main():
    """Fonction principale pour tester l'agent"""
    # Configuration
    input_file = "inputs/atelier_exemple.xlsx"
    output_file = "outputs/workshop_results.json"
    
    # Cr√©ation du dossier de sortie si n√©cessaire
    Path("outputs").mkdir(exist_ok=True)
    
    # Initialisation de l'agent
    agent = WorkshopAgent()
    
    try:
        # Traitement du fichier
        results = agent.process_workshop_file(input_file)
        
        # Sauvegarde des r√©sultats
        agent.save_results(results, output_file)
        
        # Affichage des r√©sultats
        print(f"\n=== R√âSULTATS DU TRAITEMENT ===")
        print(f"Nombre d'ateliers trait√©s: {len(results)}")
        
        for result in results:
            print(f"\n--- Atelier: {result.theme} (ID: {result.workshop_id}) ---")
            print(f"Nombre de cas d'usage: {len(result.use_cases)}")
            for i, use_case in enumerate(result.use_cases, 1):
                print(f"  {i}. {use_case.title}")
                print(f"     Objectif: {use_case.objective}")
                if use_case.benefits:
                    print(f"     B√©n√©fices: {', '.join(use_case.benefits)}")
        
        print(f"\nR√©sultats sauvegard√©s dans: {output_file}")
        
    except Exception as e:
        logger.error(f"Erreur lors du traitement: {e}")
        raise

if __name__ == "__main__":
    main()
