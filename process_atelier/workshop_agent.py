"""
Workshop Agent - Traitement des fichiers Excel d'ateliers IA
"""

import pandas as pd
import json
import logging
from typing import Dict, List, Any
from pathlib import Path
from pydantic import BaseModel, Field
from openai import OpenAI
from dotenv import load_dotenv
from concurrent.futures import ThreadPoolExecutor, as_completed
from prompts.workshop_agent_prompts import (
    WORKSHOP_ANALYSIS_PROMPT,
    USE_CASE_CONSOLIDATION_PROMPT
)

# Configuration du logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# Chargement des variables d'environnement
load_dotenv()

class UseCase(BaseModel):
    """Mod√®le pour un cas d'usage"""
    title: str = Field(description="Titre du cas d'usage")
    objective: str = Field(description="Objectif ou gain attendu")
    benefits: List[str] = Field(default_factory=list, description="Liste des b√©n√©fices")
    iteration_count: int = Field(
        description="Nombre de fois que ce besoin a √©t√© remont√© par diff√©rentes personnes (nombre de cas similaires regroup√©s)",
        ge=1,
        default=1
    )

class WorkshopAnalysisResponse(BaseModel):
    """Mod√®le pour la r√©ponse d'analyse d'un atelier"""
    theme: str = Field(description="Th√®me principal de l'atelier")
    use_cases: List[UseCase] = Field(description="Liste des cas d'usage consolid√©s")

class WorkshopData(BaseModel):
    """Mod√®le pour les donn√©es d'un atelier"""
    workshop_id: str = Field(description="Identifiant unique de l'atelier")
    theme: str = Field(description="Th√®me de l'atelier")
    use_cases: List[UseCase] = Field(description="Liste des cas d'usage")

class WorkshopAgent:
    """Agent de traitement des fichiers Excel d'ateliers"""
    
    def __init__(self, openai_api_key: str = None):
        """Initialise l'agent avec la cl√© API OpenAI"""
        # Utilisation de la cl√© API depuis les variables d'environnement
        import os
        api_key = openai_api_key or os.getenv('OPENAI_API_KEY')
        if not api_key:
            raise ValueError("OPENAI_API_KEY doit √™tre d√©finie dans les variables d'environnement ou pass√©e en param√®tre")
        self.client = OpenAI(api_key=api_key)
        self.model = os.getenv('OPENAI_MODEL', 'gpt-5-nano')
        
    def parse_excel(self, file_path: str) -> pd.DataFrame:
        """
        Parse un fichier Excel et retourne un DataFrame nettoy√©
        
        Args:
            file_path: Chemin vers le fichier Excel
            
        Returns:
            DataFrame nettoy√© avec les colonnes standardis√©es
        """
        logger.info(f"Parsing du fichier Excel: {file_path}")
        
        try:
            # Lecture du fichier Excel
            df = pd.read_excel(file_path)
            
            # Log des colonnes originales
            logger.info(f"Colonnes d√©tect√©es: {df.columns.tolist()}")
            logger.info(f"Nombre de lignes: {len(df)}")
            
            # Standardisation des noms de colonnes (premi√®re lettre de chaque colonne)
            if len(df.columns) >= 3:
                df.columns = ['Atelier', 'Use_Case', 'Objective']
            else:
                raise ValueError("Le fichier Excel doit contenir au moins 3 colonnes")
            
            # Nettoyage des donn√©es
            df = df.dropna(subset=['Atelier'])  # Supprimer les lignes sans atelier
            df = df.fillna('')  # Remplacer les NaN par des cha√Ænes vides
            
            logger.info(f"Donn√©es nettoy√©es - {len(df)} lignes restantes")
            logger.info("Premi√®res lignes du fichier pars√©:")
            logger.info(f"\n{df.head()}")
            
            return df
            
        except Exception as e:
            logger.error(f"Erreur lors du parsing du fichier Excel: {e}")
            raise
    
    def group_by_workshop(self, df: pd.DataFrame) -> Dict[str, pd.DataFrame]:
        """
        Groupe les donn√©es par atelier
        
        Args:
            df: DataFrame nettoy√©
            
        Returns:
            Dictionnaire avec les ateliers comme cl√©s
        """
        logger.info("Groupement des donn√©es par atelier")
        
        workshops = {}
        for atelier in df['Atelier'].unique():
            if atelier and atelier.strip():  # Ignorer les ateliers vides
                workshop_data = df[df['Atelier'] == atelier]
                workshops[atelier] = workshop_data
                logger.info(f"Atelier '{atelier}': {len(workshop_data)} cas d'usage")
        
        return workshops
    
    def _process_single_workshop(self, atelier_name: str, workshop_df: pd.DataFrame, workshop_id: str) -> WorkshopData:
        """
        Traite un seul atelier avec le LLM (fonction helper pour la parall√©lisation)
        
        Args:
            atelier_name: Nom de l'atelier
            workshop_df: DataFrame des cas d'usage de cet atelier
            workshop_id: Identifiant unique de l'atelier
            
        Returns:
            WorkshopData structur√©
        """
        logger.info(f"Traitement de l'atelier: {atelier_name}")
        
        # Pr√©paration des donn√©es pour le LLM
        use_cases_text = []
        for _, row in workshop_df.iterrows():
            use_case = row['Use_Case']
            objective = row['Objective']
            if use_case and use_case.strip():
                use_cases_text.append(f"- {use_case}: {objective}")
        
        # Utilisation du prompt depuis workshop_agent_prompts.py
        user_prompt = USE_CASE_CONSOLIDATION_PROMPT.format(
            atelier_name=atelier_name,
            use_cases_text=chr(10).join(use_cases_text)
        )
        
        response = None
        try:
            # Appel √† l'API OpenAI Responses avec structured output
            # Utilisation du param√®tre 'instructions' pour le system prompt
            response = self.client.responses.parse(
                model=self.model,
                instructions=WORKSHOP_ANALYSIS_PROMPT,
                input=[
                    {
                        "role": "user",
                        "content": user_prompt
                    }
                ],
                text_format=WorkshopAnalysisResponse,
            )
            
            # Extraction de la r√©ponse structur√©e
            parsed_response = response.output_parsed
            
            logger.info(f"R√©ponse structur√©e pour {atelier_name}:")
            logger.info(f"Th√®me: {parsed_response.theme}")
            logger.info(f"Nombre de cas d'usage: {len(parsed_response.use_cases)}")
            
            # Cr√©ation de l'objet WorkshopData
            workshop_result = WorkshopData(
                workshop_id=workshop_id,
                theme=parsed_response.theme,
                use_cases=parsed_response.use_cases
            )
            
            logger.info(f"Atelier {atelier_name} trait√© avec succ√®s avec structured output")
            return workshop_result
            
        except Exception as e:
            logger.error(f"Erreur lors du traitement LLM pour {atelier_name}: {e}", exc_info=True)
            
            # Tentative de r√©cup√©ration de la r√©ponse brute pour diagnostic et r√©paration
            if response is not None:
                try:
                    # Acc√©der √† la r√©ponse brute
                    raw_text = getattr(response, 'output_text', None)
                    if not raw_text:
                        # Essayer d'autres attributs possibles
                        raw_text = getattr(response, 'text', None)
                    
                    if raw_text:
                        logger.error(f"R√©ponse brute re√ßue (longueur: {len(raw_text)} caract√®res)")
                        logger.error(f"R√©ponse brute (premiers 1000 caract√®res): {raw_text[:1000]}")
                        logger.error(f"R√©ponse brute (derniers 500 caract√®res): {raw_text[-500:]}")
                        
                        # Tentative de parsing manuel du JSON tronqu√©
                        import json
                        import re
                        
                        # Chercher le JSON dans la r√©ponse (√©ventuellement tronqu√©)
                        json_match = re.search(r'\{.*', raw_text, re.DOTALL)
                        if json_match:
                            json_str = json_match.group(0)
                            logger.info(f"Tentative de r√©paration du JSON...")
                            
                            # Tenter de fermer les cha√Ænes et objets JSON ouverts
                            try:
                                # M√©thode am√©lior√©e : trouver la derni√®re cha√Æne non ferm√©e
                                # Chercher toutes les positions de guillemets non √©chapp√©s
                                quote_positions = []
                                i = 0
                                while i < len(json_str):
                                    if json_str[i] == '"' and (i == 0 or json_str[i-1] != '\\'):
                                        quote_positions.append(i)
                                    i += 1
                                
                                # Si nombre impair de guillemets, fermer la derni√®re cha√Æne
                                if len(quote_positions) % 2 != 0:
                                    # Trouver o√π se termine la derni√®re cha√Æne (avant le prochain caract√®re sp√©cial)
                                    last_quote = quote_positions[-1]
                                    # Chercher la fin de la cha√Æne (avant : ou , ou } ou ])
                                    end_pos = len(json_str)
                                    for char in [':', ',', '}', ']', '\n']:
                                        pos = json_str.find(char, last_quote + 1)
                                        if pos != -1 and pos < end_pos:
                                            end_pos = pos
                                    # Fermer la cha√Æne avant le caract√®re sp√©cial
                                    json_str = json_str[:end_pos] + '"' + json_str[end_pos:]
                                
                                # Fermer les objets/tableaux non ferm√©s
                                open_braces = json_str.count('{') - json_str.count('}')
                                open_brackets = json_str.count('[') - json_str.count(']')
                                
                                # Fermer d'abord les tableaux, puis les objets
                                if open_brackets > 0:
                                    json_str += ']' * open_brackets
                                if open_braces > 0:
                                    json_str += '}' * open_braces
                                
                                # Tenter de parser le JSON r√©par√©
                                repaired_data = json.loads(json_str)
                                
                                # Tenter de cr√©er l'objet WorkshopAnalysisResponse
                                try:
                                    repaired_response = WorkshopAnalysisResponse(**repaired_data)
                                    workshop_result = WorkshopData(
                                        workshop_id=workshop_id,
                                        theme=repaired_response.theme,
                                        use_cases=repaired_response.use_cases
                                    )
                                    logger.warning(f"‚úÖ JSON r√©par√© avec succ√®s pour {atelier_name}")
                                    return workshop_result
                                except Exception as repair_error:
                                    logger.error(f"‚ùå Impossible de cr√©er l'objet depuis le JSON r√©par√©: {repair_error}")
                                    # Essayer d'extraire au moins le th√®me
                                    theme_match = re.search(r'"theme"\s*:\s*"([^"]*)', json_str)
                                    if theme_match:
                                        extracted_theme = theme_match.group(1)
                                        logger.warning(f"‚ö†Ô∏è Extraction partielle du th√®me: {extracted_theme}")
                                        workshop_result = WorkshopData(
                                            workshop_id=workshop_id,
                                            theme=extracted_theme,
                                            use_cases=[]
                                        )
                                        return workshop_result
                            except json.JSONDecodeError as json_error:
                                logger.error(f"‚ùå JSON non r√©parable: {json_error}")
                                logger.error(f"JSON partiel (premiers 2000 caract√®res): {json_str[:2000]}")
                                # Essayer d'extraire au moins le th√®me
                                theme_match = re.search(r'"theme"\s*:\s*"([^"]*)', json_str)
                                if theme_match:
                                    extracted_theme = theme_match.group(1)
                                    logger.warning(f"‚ö†Ô∏è Extraction partielle du th√®me: {extracted_theme}")
                                    workshop_result = WorkshopData(
                                        workshop_id=workshop_id,
                                        theme=extracted_theme,
                                        use_cases=[]
                                    )
                                    return workshop_result
                    else:
                        logger.warning("Impossible d'acc√©der √† la r√©ponse brute pour diagnostic")
                except Exception as diagnostic_error:
                    logger.error(f"Erreur lors du diagnostic: {diagnostic_error}", exc_info=True)
            
            # Fallback: cr√©ation d'un atelier basique
            logger.warning(f"‚ö†Ô∏è Utilisation du fallback pour {atelier_name}")
            workshop_result = WorkshopData(
                workshop_id=workshop_id,
                theme=atelier_name,
                use_cases=[]
            )
            return workshop_result
    
    def aggregate_use_cases_with_llm(self, workshops: Dict[str, pd.DataFrame]) -> List[WorkshopData]:
        """
        Utilise un LLM pour rassembler et structurer les cas d'usage par atelier
        PARALL√âLIS√â : Traite tous les ateliers en parall√®le pour gagner du temps
        
        Args:
            workshops: Dictionnaire des ateliers group√©s
            
        Returns:
            Liste des donn√©es d'ateliers structur√©es
        """
        logger.info(f"Agr√©gation des cas d'usage avec LLM (PARALL√âLIS√âE pour {len(workshops)} ateliers)")
        
        workshop_results = []
        
        # üöÄ PARALL√âLISATION : Traiter tous les ateliers en m√™me temps
        with ThreadPoolExecutor(max_workers=len(workshops)) as executor:
            # Soumettre tous les ateliers pour traitement parall√®le
            future_to_atelier = {}
            for idx, (atelier_name, workshop_df) in enumerate(workshops.items(), 1):
                workshop_id = f"W{idx:03d}"
                future = executor.submit(self._process_single_workshop, atelier_name, workshop_df, workshop_id)
                future_to_atelier[future] = atelier_name
            
            # R√©cup√©rer les r√©sultats au fur et √† mesure
            for future in as_completed(future_to_atelier):
                atelier_name = future_to_atelier[future]
                try:
                    workshop_result = future.result()
                    workshop_results.append(workshop_result)
                    logger.info(f"‚úì Atelier '{atelier_name}' termin√©")
                except Exception as e:
                    logger.error(f"‚ùå Erreur lors du traitement de '{atelier_name}': {e}")
                    # Cr√©er un r√©sultat fallback
                    workshop_results.append(WorkshopData(
                        workshop_id=f"W{len(workshop_results) + 1:03d}",
                        theme=atelier_name,
                        use_cases=[]
                    ))
        
        logger.info(f"‚úÖ Traitement parall√®le termin√©: {len(workshop_results)} ateliers trait√©s")
        return workshop_results
    
    def process_workshop_file(self, file_path: str) -> List[WorkshopData]:
        """
        Traite un fichier Excel d'atelier complet
        
        Args:
            file_path: Chemin vers le fichier Excel
            
        Returns:
            Liste des donn√©es d'ateliers structur√©es
        """
        logger.info(f"D√©but du traitement du fichier: {file_path}")
        
        # 1. Parsing du fichier Excel
        df = self.parse_excel(file_path)
        
        # 2. Groupement par atelier
        workshops = self.group_by_workshop(df)
        
        # 3. Agr√©gation avec LLM
        workshop_results = self.aggregate_use_cases_with_llm(workshops)
        
        logger.info(f"Traitement termin√©: {len(workshop_results)} ateliers trait√©s")
        
        return workshop_results
    
    def save_results(self, results: List[WorkshopData], output_path: str):
        """
        Sauvegarde les r√©sultats en JSON
        
        Args:
            results: Liste des donn√©es d'ateliers
            output_path: Chemin de sauvegarde
        """
        logger.info(f"Sauvegarde des r√©sultats vers: {output_path}")
        
        # Conversion en dictionnaire pour la s√©rialisation JSON
        results_dict = [result.model_dump() for result in results]
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(results_dict, f, ensure_ascii=False, indent=2)
        
        logger.info("R√©sultats sauvegard√©s avec succ√®s")

def main():
    """Fonction principale pour tester l'agent"""
    # Configuration
    input_file = "inputs/atelier_exemple.xlsx"
    output_file = "outputs/workshop_results.json"
    
    # Cr√©ation du dossier de sortie si n√©cessaire
    Path("outputs").mkdir(exist_ok=True)
    
    # Initialisation de l'agent
    agent = WorkshopAgent()
    
    try:
        # Traitement du fichier
        results = agent.process_workshop_file(input_file)
        
        # Sauvegarde des r√©sultats
        agent.save_results(results, output_file)
        
        # Affichage des r√©sultats
        print(f"\n=== R√âSULTATS DU TRAITEMENT ===")
        print(f"Nombre d'ateliers trait√©s: {len(results)}")
        
        for result in results:
            print(f"\n--- Atelier: {result.theme} (ID: {result.workshop_id}) ---")
            print(f"Nombre de cas d'usage: {len(result.use_cases)}")
            for i, use_case in enumerate(result.use_cases, 1):
                print(f"  {i}. {use_case.title}")
                print(f"     Objectif: {use_case.objective}")
                print(f"     Nombre de personnes ayant remont√© ce besoin: {use_case.iteration_count}")
                if use_case.benefits:
                    print(f"     B√©n√©fices: {', '.join(use_case.benefits)}")
        
        print(f"\nR√©sultats sauvegard√©s dans: {output_file}")
        
    except Exception as e:
        logger.error(f"Erreur lors du traitement: {e}")
        raise

if __name__ == "__main__":
    main()
